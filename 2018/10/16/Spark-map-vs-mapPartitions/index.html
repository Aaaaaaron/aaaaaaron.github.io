<!doctype html>
<html lang="en">
    <head><meta name="generator" content="Hexo 3.8.0">
		
        <meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="Kyligence">
        <link rel="shortcut icon" href="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
        <link rel="canonical" href="http://guolinn.com/">
        <link rel="alternate" type="application/rss+xml" title="Aron Tao" href="/atom.xml">
        <title>Spark map vs mapPartitions | Jiatao Tao&#39;s blog</title>
        <meta name="description" content="{{meta_description}}">

        <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/styles/crisp.css">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

    </head>
    
		<body class="post-template">
	

        <header id="header">
            <a id="logo" href="/"><img src="https://gitee.com/Meldoy/image/raw/master/life/head.jpg" alt="Jiatao Tao's blog"></a>
            <h1><a href="/">Aron Tao</a></h1>
            <p></p>
            <div id="follow-icons">
                  <a href="/atom.xml"><i class="fa fa-rss-square fa-2x"></i></a>
  </div>
<h6><a href="/about">About</a></h6>
        </header>

        <main id="content">
        

<article class="post">
  October 16, 2018
  
    <span class="taglist">  &middot; 
    
    
      <a href="/tags/BigData/">BigData</a> 
    
      <a href="/tags/Spark/">Spark</a> 
    
    </span>
  

  <h1 class="post-title">Spark map vs mapPartitions</h1>
  <section class="post-content article-entry">
    <p>官方定义:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return a new RDD by applying a function to all elements of this RDD.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.map(cleanF))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return a new RDD by applying a function to each partition of this RDD.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * `preservesPartitioning` indicates whether the input function preserves the partitioner, which</span></span><br><span class="line"><span class="comment"> * should be `false` unless this is a pair RDD and the input function doesn't modify the keys.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartitions</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    f: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Iterator</span>[<span class="type">U</span>],</span><br><span class="line">    preservesPartitioning: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanedF = sc.clean(f)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>(</span><br><span class="line">    <span class="keyword">this</span>,</span><br><span class="line">    (context: <span class="type">TaskContext</span>, index: <span class="type">Int</span>, iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; cleanedF(iter),</span><br><span class="line">    preservesPartitioning)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到的是 mapPartitions 需要的函数参数传入的是一个 iter, 返回的也是一个 iter, 而 map 仅仅是一个元素.</p>
<p>假设我们有 10k 个元素, 10个 partitions, 数据均匀分布:</p>
<ol>
<li>map:调用10k 次 map 方法</li>
<li>mapPartitions:调用10次 mapPartitions 方法, 每次传入1k个(一个 partition 的数据量)进行计算. 结果先存到 memory 中, 直到可以返回.</li>
<li>flatMap在 单个元素(map)上工作，生成结果是多个元素(mapPartitions)</li>
</ol>
<p>结论:mapPartitions 转换比 map 快，因为它调用你的函数 一次/分区，而不是 一次/元素, 像有一些高开销的 init 的时候, 如数据库连接, 使用 mapPartitions, 每个分区就只需要一次 init.</p>
<p>来看一个使用 mapPartitions 报错的例子, 运行这段代码, 会报 already closed exception, 因为 spark 的计算都是 lazy 的, 下面的 partition.map 到真的触发计算的时候, conn 已经 close 了.解决方法就是 <code>val newPartition = partition.map(...}).toList</code> 触发计算.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> newDF = myDF.mapPartitions(</span><br><span class="line">  partition =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> conn = <span class="keyword">new</span> <span class="type">DbConnection</span></span><br><span class="line">    <span class="keyword">val</span> newPartition = partition.map(record =&gt; &#123; readMatchingFromDB(record, connection) &#125;)</span><br><span class="line">    conn.close()</span><br><span class="line">    newPartition</span><br><span class="line">  &#125;).toDF()</span><br></pre></td></tr></table></figure>
<p>map mapPartitions 对外部引用的更新都没法作用出来: 下面的 flag 还是0.<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> flag = <span class="number">0</span></span><br><span class="line"><span class="keyword">val</span> test = rdd.map &#123;</span><br><span class="line">  row =&gt; flag += <span class="number">1</span></span><br><span class="line">&#125;.collect()</span><br></pre></td></tr></table></figure></p>

  </section>
  <footer class="post-footer">
    <!--
    <section class="author">
      <h4>Aron Tao</h4>
      <p></p>
    </section>
    -->
  </footer>
</article>

<nav class="pagination" role="pagination">
    
    <a class="newer-posts" href="/2018/10/22/Spark-Parquet-file-split/">
        ← prev <!--Spark Parquet file split-->
    </a>
    
    <span class="page-number">•</span>
    
    <a class="older-posts" href="/2018/10/06/Druid-Storage-原理/">
        <!--Druid Storage 原理--> next →
    </a>
    
</nav>


        </main>
        <footer id="footer">
            <section id="footer-message">&copy; 2019 Aron Tao. All rights reserved. Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. <a href="https://github.com/guolin/crisp-hexo-theme" target="_blank">crisp</a> theme by <a href="guolin.github.io" target="_blank">Guo Lin</a>.</section>
        </footer>
    </body>
</html>


