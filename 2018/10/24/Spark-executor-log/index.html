<!DOCTYPE html>
<html lang="">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="寻找 Spark executor 日志">




  <meta name="keywords" content="BigData,Spark,">





  <link rel="alternate" href="/default" title="Jiatao Tao's blog">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1">



<link rel="canonical" href="https://aaaaaaron.github.io/2018/10/24/Spark-executor-log/">


<meta name="description" content="引言spark on yarn 应用在运行时和完成后日志的存放位置是不同的，一般运行时是存放在各个运行节点，完成后会归集到 hdfs。无论哪种情况，都可以通过 spark 的页面跳转找到 executor 的日志，但是在大多数的生产环境中，对端口的开放是有严格的限制，也就是说根本无法正常跳转到日志页面进行查看的，这种情况下，就需要通过后台查询。 运行时spark on yarn 模式下一个 exe">
<meta name="keywords" content="BigData,Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="寻找 Spark executor 日志">
<meta property="og:url" content="https://aaaaaaron.github.io/2018/10/24/Spark-executor-log/index.html">
<meta property="og:site_name" content="Jiatao Tao&#39;s blog">
<meta property="og:description" content="引言spark on yarn 应用在运行时和完成后日志的存放位置是不同的，一般运行时是存放在各个运行节点，完成后会归集到 hdfs。无论哪种情况，都可以通过 spark 的页面跳转找到 executor 的日志，但是在大多数的生产环境中，对端口的开放是有严格的限制，也就是说根本无法正常跳转到日志页面进行查看的，这种情况下，就需要通过后台查询。 运行时spark on yarn 模式下一个 exe">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-06-23T12:26:39.510Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="寻找 Spark executor 日志">
<meta name="twitter:description" content="引言spark on yarn 应用在运行时和完成后日志的存放位置是不同的，一般运行时是存放在各个运行节点，完成后会归集到 hdfs。无论哪种情况，都可以通过 spark 的页面跳转找到 executor 的日志，但是在大多数的生产环境中，对端口的开放是有严格的限制，也就是说根本无法正常跳转到日志页面进行查看的，这种情况下，就需要通过后台查询。 运行时spark on yarn 模式下一个 exe">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  





  


    <title> 寻找 Spark executor 日志 - Jiatao Tao's blog </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">Jiatao Tao's blog</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/tags">
                            
                            
                                Tags
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          寻找 Spark executor 日志
        
      </h1>

      <time class="post-time">
          Oct 24 2018
      </time>
    </header>



    
            <div class="post-content">
            <h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>spark on yarn 应用在运行时和完成后日志的存放位置是不同的，一般运行时是存放在各个运行节点，完成后会归集到 hdfs。无论哪种情况，都可以通过 spark 的页面跳转找到 executor 的日志，但是在大多数的生产环境中，对端口的开放是有严格的限制，也就是说根本无法正常跳转到日志页面进行查看的，这种情况下，就需要通过后台查询。</p>
<h2 id="运行时"><a href="#运行时" class="headerlink" title="运行时"></a>运行时</h2><p>spark on yarn 模式下一个 executor 对应 yarn 的一个 container，所以在 executor 的节点运行<code>ps -ef|grep spark.yarn.app.container.log.dir</code>，如果这个节点上可能运行多个 application，那么再通过 application id 进一步过滤。上面的命令会查到 executor 的进程信息，并且包含了日志路径，例如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> -Djava.io.tmpdir=/data1/hadoop/yarn/local/usercache/ocdp/appcache/application_1521424748238_0051/container_e07_1521424748238_0051_01_000002/tmp &apos;</span><br><span class="line">-Dspark.history.ui.port=18080&apos; &apos;-Dspark.driver.port=59555&apos; </span><br><span class="line">-Dspark.yarn.app.container.log.dir=/data1/hadoop/yarn/log/application_1521424748238_0051/container_e07_1521424748238_0051_01_000002</span><br></pre></td></tr></table></figure>
<p>也就是说这个 executor 的日志就在<code>/data1/hadoop/yarn/log/application_1521424748238_0051/container_e07_1521424748238_0051_01_000002</code>目录里。至此，我们就找到了运行时的 executor 日志。</p>
<h2 id="完成后"><a href="#完成后" class="headerlink" title="完成后"></a>完成后</h2><p>当这个 application 正常或者由于某种原因异常结束后，yarn 默认会将所有日志归集到 hdfs 上，所以 yarn 也提供了一个查询已结束 application 日志的方法，即<br> <code>yarn logs -applicationId application_1521424748238_0057</code>，结果里面会包含所有 executor 的日志，可能会比较多，建议将结果重定向到一个文件再详细查看。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>无论对于 spark 应用程序的开发者还是运维人员，日志对于排查问题是至关重要的，所以本文介绍了找到日志的方法。</p>
<h2 id="画外-log4j-配置-spark-on-yarn-client-mode"><a href="#画外-log4j-配置-spark-on-yarn-client-mode" class="headerlink" title="画外:log4j 配置 - spark on yarn client mode"></a>画外:log4j 配置 - spark on yarn client mode</h2><p>spark streaming 的程序如果运行方式是 yarn <strong><em>client</em></strong> mode，那么如何指定 driver 和 executor 的 log4j 配置文件？</p>
<h3 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h3><p>添加参数<code>--driver-java-options</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --driver-java-options &quot;-Dlog4j.configuration=file:/data1/conf/log4j-driver.properties&quot;</span><br></pre></td></tr></table></figure>
<h3 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h3><p>由于 executor 是运行在 yarn 的集群中的，所以先要将配置文件通过<code>--files</code>上传</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --files /data1/conf/log4j.properties --conf spark.executor.extraJavaOptions=&quot;-Dlog4j.configuration=log4j.properties&quot;</span><br></pre></td></tr></table></figure>
<p>在 log4j.properties 中要注意配置<code>spark.yarn.app.container.log.dir</code>例如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, file</span><br><span class="line">log4j.appender.file=org.apache.log4j.RollingFileAppender</span><br><span class="line">log4j.appender.file.append=true</span><br><span class="line">log4j.appender.file.file=$&#123;spark.yarn.app.container.log.dir&#125;/stdout</span><br><span class="line">log4j.appender.file.MaxFileSize=256MB</span><br><span class="line">log4j.appender.file.MaxBackupIndex=20</span><br><span class="line"></span><br><span class="line">log4j.appender.file.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.file.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %p [%t] %c&#123;1&#125;:%L - %m%n</span><br><span class="line"></span><br><span class="line"># Settings to quiet third party logs that are too verbose</span><br><span class="line">log4j.logger.org.spark-project.jetty=WARN</span><br><span class="line">log4j.logger.org.spark-project.jetty.util.component.AbstractLifeCycle=ERROR</span><br><span class="line">log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO</span><br><span class="line">log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO</span><br></pre></td></tr></table></figure>
<p>这样就可以在 spark 的 Web UI 中直接查看日志:executor tab 下的 Logs.</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>如果是通过<code>java -cp</code>命令运行自己的 jar 包，可以通过下面的方式添加 log4j 的配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -cp -Dlog4j.configuration=file:$&#123;APP_HOME&#125;/conf/log4j.properties</span><br></pre></td></tr></table></figure>
<p>作者：Woople, 链接：<a href="https://www.jianshu.com/p/06a630618f19" target="_blank" rel="noopener">https://www.jianshu.com/p/06a630618f19</a></p>

            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/BigData/">BigData</a>
          
            <a href="/tags/Spark/">Spark</a>
          
        </div>

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2018/10/26/Spark-submit/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">提交 Spark 应用</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2018/10/24/Spark-Shuffle/">
        <span class="next-text nav-default">Shuffle</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2012 -
    
    2019
    <span class="footer-author">陶加涛.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/henryhuang/hexo-theme-polarbearsimple">Polar Bear Simple</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
