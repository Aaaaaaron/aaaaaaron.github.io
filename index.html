<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Kyligence">
<meta property="og:type" content="website">
<meta property="og:title" content="Jiatao Tao&#39;s blog">
<meta property="og:url" content="https://tttmelody.github.io/index.html">
<meta property="og:site_name" content="Jiatao Tao&#39;s blog">
<meta property="og:description" content="Kyligence">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jiatao Tao&#39;s blog">
<meta name="twitter:description" content="Kyligence">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tttmelody.github.io/"/>





  <title>Jiatao Tao's blog</title>
  








  
  <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiatao Tao's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/09/12/Storage-different-strategies-about-high-cardinal-string/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/12/Storage-different-strategies-about-high-cardinal-string/" itemprop="url">Storage:different strategies about high cardinal string</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-12T17:03:14+08:00">
                2018-09-12
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/12/Storage-different-strategies-about-high-cardinal-string/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/09/12/Storage-different-strategies-about-high-cardinal-string/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/09/12/Storage-different-strategies-about-high-cardinal-string/" class="leancloud_visitors" data-flag-title="Storage:different strategies about high cardinal string">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/08/30/Spark-mapPartitions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/30/Spark-mapPartitions/" itemprop="url">Spark:mapPartitions</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-30T22:56:55+08:00">
                2018-08-30
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/30/Spark-mapPartitions/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/08/30/Spark-mapPartitions/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/30/Spark-mapPartitions/" class="leancloud_visitors" data-flag-title="Spark:mapPartitions">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/08/26/Designing-Data-Intensive-Applications-Storage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/26/Designing-Data-Intensive-Applications-Storage/" itemprop="url">Designing Data-Intensive Applications(Storage)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-26T19:30:40+08:00">
                2018-08-26
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/26/Designing-Data-Intensive-Applications-Storage/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/08/26/Designing-Data-Intensive-Applications-Storage/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/26/Designing-Data-Intensive-Applications-Storage/" class="leancloud_visitors" data-flag-title="Designing Data-Intensive Applications(Storage)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Index-基础"><a href="#Index-基础" class="headerlink" title="Index 基础"></a>Index 基础</h1><p>log:泛指 append only 的记录序列.不一定要人可读, 可以是 binary 的.</p>
<p>log 文件是 append only, 而且一旦生成就不可变, 所以对并发和崩溃恢复很友好. 如果用 update 方式来修改值的话, 崩溃时会有很多不可预期的行为.</p>
<p>核心, 就是要减少扫的数据量. full scan (O(n)) 肯定最慢, 扫的时间和数据量成正比.</p>
<p>index 的也就是存出一些额外的信息, 这样的话帮助你定位到你的数据. 管理额外的信息是有开销的:存储(写入) 管理(更新), 所以 db 不会索引所有值.</p>
<h2 id="Hash-Index"><a href="#Hash-Index" class="headerlink" title="Hash Index"></a>Hash Index</h2><p>要找 key 为123456的 content, 只需要先在内存 map 中找到它的 byte offset , 只要一次 seek 过去,读到和下一个 key 的 offset相减的 content. 读的很精准.</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/893370.jpg" alt=""></p>
<blockquote>
<p>Storing a log of key-value pairs in a CSV-like format, indexed with an in-memory hash map.</p>
</blockquote>
<p>通过追加的方式, 可能会造成一个文件太大了, 解决方案是把当 log 到一定 size, 就拆分一个新 segment 文件. 后面我们可以对这些 segments 进行 compaction. compact 会去除 dup 的 key, 留下最新的版本.</p>
<p>还可以对多个 seg 进行 merge.<br><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/39145451.jpg" alt=""></p>
<blockquote>
<p>对一个 seg 进行 compact</p>
</blockquote>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/13193271.jpg" alt=""></p>
<blockquote>
<p>对 seg 进行 compact, 同时进行 merge.</p>
</blockquote>
<h3 id="局限"><a href="#局限" class="headerlink" title="局限"></a>局限</h3><ol>
<li>散列表必须能放进内存. 原则上可以在磁盘上保留一个哈希映射, 但是磁盘哈希映射很难表现优秀, 它需要大量的随机访问I/O, 当它变满时增长也是很昂贵的,并且散列冲突需要很多的逻辑</li>
<li>范围查询效率不高, 必须在散列映射中单独查找每个键.</li>
</ol>
<h2 id="SSLTables-and-LSM-Trees"><a href="#SSLTables-and-LSM-Trees" class="headerlink" title="SSLTables and LSM-Trees"></a>SSLTables and LSM-Trees</h2><p>之前的 log 文件里 record 的顺序是他们写入的顺序.我们现在有个新的要求, 就是写入的 k-v 对要根据 key 排序, 且每个 key 在每个 seg 中只出现一次, 这种 format 叫做 Sorted String Table(SSTable)</p>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ol>
<li><p>可以 merge 比内存还大的多的 seg(使用 merge sort), 对于多个 seg 中都出现的值, 只需要留最新的 seg 中的值就可以了.<br><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/65990847.jpg" alt=""></p>
</li>
<li><p>index 不用保留所有的 key, 因为你所有的 key 都是保序的, 所以只要有几个作为base, 其他的可以在这几个 base 之间去找. 假设你正在内存中寻找键 handiwork，但是你不知道段文件中该关键字的确切偏移量. 然而，你知道 handbag 和 handsome 的偏移，而且由于排序特性，你知道 handiwork 必须出现在这两者之间. 这意味着您可以跳到 handbag 的偏移位置并从那里扫描，直到您找到 handiwork(或没找到，如果该文件中没有该键)</p>
</li>
</ol>
<p>这样, 你内存中的索引就可以很稀疏, 每几千字节的段文件就有一个键就足够了，因为几千字节可以很快被扫描.</p>
<p>如果所有的 k-v 都是 fix length 的, 你可以用 binary search. 这样可以省去整个内存中的索引.不过 in practice 一般都是变长的.</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/28391204.jpg" alt=""></p>
<h3 id="维护和构建-SSTables"><a href="#维护和构建-SSTables" class="headerlink" title="维护和构建 SSTables"></a>维护和构建 SSTables</h3><p>在磁盘上维护一个有序的数据结构是可能的(见 B Tree), 但是在内存中维护会更加简单.类似的结构有 red-black trees, AVL tress.</p>
<h4 id="工作流"><a href="#工作流" class="headerlink" title="工作流"></a>工作流</h4><ol>
<li>写入时将其添加到内存中的平衡树数据结构(例如, 红黑树). 这个内存树有时被称为内存表(mem table).</li>
<li>当内存表大于某个阈值(通常为几兆字节)时, 将其作为 SSTable 文件写入磁盘.新的 SSTable 文件成为数据库的最新部分.当 SSTable 被写入磁盘时, 写入可以继续到一个新的内存表实例.</li>
<li>当读的时候, 首先尝试在内存表中找到关键字, 然后在最近的磁盘段中, 然后在下一个较旧的段中找到该关键字.</li>
<li>可以在后台运行合并和压缩过程以组合段文件并丢弃覆盖或删除的值.</li>
</ol>
<p>基于这种合并和压缩排序文件原理的存储引擎通常被称为 LSM 存储引擎(LevelDB, RocksDB, HBase, BigTable)</p>
<h5 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h5><ol>
<li>当查找数据库中不存在的值时, LSM 会慢, 因为要找到最老的 seg, 解决方法是用 Bloom Filter(粗糙集理论也可以了解下). 节省为不存在的键浪费的 IO.</li>
<li>还有不同的策略来确定 SSTables 如何被压缩和合并的顺序和时间. 最常见的选择是 size-tiered 和 leveled compaction. LevelDB 和 RocksDB 使用平坦压缩(LevelDB 因此得名), HBase 使用size-tiered , Cassandra 同时支持.</li>
</ol>
<p>即使有很多可选优化, 但是 LSM-trees 的基本 idea:保存一系列在后台合并的 SSTables, 简单且有效. 即使数据集比可用内存大的多, 也可以支持高效的范围查询, 而且支持非常高的写入.</p>
<h5 id="问题-amp-解决"><a href="#问题-amp-解决" class="headerlink" title="问题&amp;解决"></a>问题&amp;解决</h5><p>如果数据库崩溃, 则最近的写入(在内存表中, 但尚未写入磁盘)将丢失, 解决方案: WAL(write ahead log), 和前面的一样, 这也是个 log 文件, 写入的时候先写到磁盘上. 但 mem table =&gt; SSTable 的时候, WAL 可以被丢弃.</p>
<h2 id="B-Trees"><a href="#B-Trees" class="headerlink" title="B-Trees"></a>B-Trees</h2><p>像 SSTables 一样, B 树保持按键排序的键值对, 这允许高效的键值查找和范围查询, 但B 树有着非常不同的设计理念.</p>
<p>我们前面看到的日志结构索引将数据库分解为可变大小的段, 通常是几兆字节或更大的大小; B 树将数据库分解成固定大小的块或页面, 传统上大小为 4KB.并且一次只能读取或写入一个页面. 这种设计更接近于底层硬件.因为磁盘也被安排在固定大小的块中.</p>
<p>每个页面都可以使用地址或位置来标识, 这允许一个页面引用另一个页面 —— 类似于指针, 但在磁盘而不是在内存中. 我们可以使用这些页面引用来构建一个页面树.</p>
<p>我们要找251, 于是在[200, 300] 中间找<br><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/89272936.jpg" alt=""></p>
<p>在 B 树的一个页面中对子页面的引用的数量称为分支因子, 在上面图中, 分支因子是6. 在实践中, 分支因子取决于存储页面参考和范围边界所需的空间量, 但通常是几百个</p>
<p>如果要更新 B 树中现有键的值, 则搜索包含该键的叶页, 更改该页中的值, 并将该页写回到磁盘(对该页的任何引用保持有效). 如果你想添加一个新的键, 你需要找到其范围包含新键的页面, 并将其添加到该页面.如果页面中没有足够的可用空间容纳新键, 则将其分成两个半满页面, 并更新父页面以解释键范围的新分区</p>
<p>该算法确保树保持平衡:具有 n 个键的 B 树总是具有 O(log n)的深度.大多数数据库可以放入一个三到四层的 B 树, 所以你不需要遵追踪多页面引用来找到你正在查找的页面. 分支因子为 500 的 4KB 页面的四级树可以存储多达 256TB.</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/30223544.jpg" alt=""></p>
<p>B 树的基本底层写操作是用新数据覆盖磁盘上的页面, 但是引用不变, 这个和 LSM Tree 正好相反(只附加, 从不修改文件).</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol>
<li>需要拆分页面的时候, 要更新父页面对两个子页面的引用. 因为数据库随时可能崩溃. 解决方案: WAL(redo log), 这个日志被用来使 B 树恢复到一致的状态.</li>
<li>如果多个线程要同时访问 B 树, 则需要仔细的并发控制(latches).</li>
<li>B 树索引必须至少两次写入每一段数据:一次写入预先写入日志, 一次写入树页面本身（也许再次分页）. 即使在该页面中只有几个字节发生了变化, 也需要一次编写整个页面的开销. 有些存储引擎甚至会覆盖同一个页面两次, 以免在电源故障的情况下导致页面部分更新.</li>
</ol>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><ol>
<li>一些数据库(如 LMDB)使用写时复制方案, 而不是覆盖页面并维护 WAL 进行崩溃恢复.修改的页面被写入到不同的位置, 并且树中的父页面的新版本被创建, 指向新的位置. 这种方法对于并发控制也很有用.</li>
<li>可以通过不存储整个 key 来节省空间. key 只需要提供足够的信息来充当 key range 的边界. 一个 page 有更多的 key, 运行树有更高的分支因子, 减少层数.</li>
<li>通常, page 可以放置在磁盘上的任何位置, 如果查询需要按照排序顺序扫描大部分关键字范围, 那么每个页面的布局可能会非常不方便, 因为每个读取的页面都可能需要磁盘查找. 因此许多 B 树实现尝试叶子页面按顺序出现在磁盘上, 但是随着树的增长,维持这个顺序是很困难的. 由于 LSM 树在合并过程中一次又一次地重写存储的大部分, 所以它们更容易使顺序键在磁盘上彼此靠近.</li>
<li>添加额外的指针, eg:每个叶子页面可以在左边和右边具有对其兄弟页面的引用, 这样就能顺序扫描 key 而不跳回父页面.</li>
</ol>
<h3 id="LSM-Tree-VS-B-Tree"><a href="#LSM-Tree-VS-B-Tree" class="headerlink" title="LSM Tree VS B Tree"></a>LSM Tree VS B Tree</h3><h4 id="LSM"><a href="#LSM" class="headerlink" title="LSM"></a>LSM</h4><ol>
<li>LSM 写快, B 读快. LSM 顺序地写入紧凑的 SSTable 文件而不是必须覆盖树中的几个页面.</li>
<li>LSM 树可以被压缩得更好, B 树存储引擎会由于分割而留下一些未使用的磁盘空间.</li>
<li>在许多 SSD 上, 固件内部使用日志结构化算法, 将随机写入转变为顺序写入底层存储芯片. 但是较低的写入放大率和减少的碎片对 SSD 仍然有利: 更紧凑地表示数据可在可用的 I/O 带宽内提供更多的读取和写入请求.</li>
</ol>
<h4 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B Tree"></a>B Tree</h4><ol>
<li>日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作, 很容易发生请求需要等待而磁盘完成昂贵的压缩操作. 对吞吐量和平均响应时间的影响通常很小, 但是在更高百分比的情况下（参阅 “描述性能”）, 对日志结构化存储引擎的查询响应时间有时会相当长, 而 B 树的行为则相对更具可预测性.</li>
<li>压缩的另一个问题出现在高写入吞吐量: 磁盘的有限写入带宽需要在初始写入(记录和刷新内存表到磁盘)和在后台运行的压缩线程之间共享. 写入空数据库时, 可以使用全磁盘带宽进行初始写入, 但数据库越大, 压缩所需的磁盘带宽就越多. 如果写入吞吐量很高, 并且压缩没有仔细配置, 压缩跟不上写入速率. 在这种情况下, 磁盘上未合并段的数量不断增加, 直到磁盘空间用完, 读取速度也会减慢, 因为它们需要检查更多段文件. 通常情况下, 即使压缩无法跟上, 基于 SSTable 的存储引擎也不会限制传入写入的速率, 所以需要进行明确的监控来检测这种情况</li>
<li>B 树的一个优点是每个键只存在于索引中的一个位置, 而日志结构化的存储引擎可能在不同的段中有相同键的多个副本. 这个方面使得 B 树在想要提供强大的事务语义的数据库中很有吸引力. 在许多关系数据库中, 事务隔离是通过在键范围上使用锁来实现的, 在 B 树索引中, 这些锁可以直接连接到它.</li>
</ol>
<h1 id="列存储"><a href="#列存储" class="headerlink" title="列存储"></a>列存储</h1><p>如果一列的值, count 很大, 但是基数不大, 可以使用 bit map. 可以很高效的压缩.<br><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-9-1/37827590.jpg" alt=""></p>
<h2 id="vectorized-process"><a href="#vectorized-process" class="headerlink" title="vectorized process"></a>vectorized process</h2><p>除了减少需要从磁盘加载的数据量以外, 面向列的存储布局也可以有效利用 CPU 周期. 例如 query engine 可以把一块(chunk) 的  compressed column data(为了单位信息密度更大) 放到 CPU 的 L1 cache. 前面说的按位与/或可以直接 apply 到这些 chunk 上.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/08/22/Parquet-encoding-definitions-official/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/22/Parquet-encoding-definitions-official/" itemprop="url">Parquet encoding definitions(official)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-22T20:49:53+08:00">
                2018-08-22
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/22/Parquet-encoding-definitions-official/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/08/22/Parquet-encoding-definitions-official/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/22/Parquet-encoding-definitions-official/" class="leancloud_visitors" data-flag-title="Parquet encoding definitions(official)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <!--
  - Licensed to the Apache Software Foundation (ASF) under one
  - or more contributor license agreements.  See the NOTICE file
  - distributed with this work for additional information
  - regarding copyright ownership.  The ASF licenses this file
  - to you under the Apache License, Version 2.0 (the
  - "License"); you may not use this file except in compliance
  - with the License.  You may obtain a copy of the License at
  -
  -   http://www.apache.org/licenses/LICENSE-2.0
  -
  - Unless required by applicable law or agreed to in writing,
  - software distributed under the License is distributed on an
  - "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  - KIND, either express or implied.  See the License for the
  - specific language governing permissions and limitations
  - under the License.
  -->
<h1 id="Parquet-encoding-definitions"><a href="#Parquet-encoding-definitions" class="headerlink" title="Parquet encoding definitions"></a><a href="https://github.com/apache/parquet-format/blob/master/Encodings.md" target="_blank" rel="noopener">Parquet encoding definitions</a></h1><p>This file contains the specification of all supported encodings.</p>
<h3 id="Plain-PLAIN-0"><a href="#Plain-PLAIN-0" class="headerlink" title="Plain: (PLAIN = 0)"></a><a name="PLAIN"></a>Plain: (PLAIN = 0)</h3><p>Supported Types: all</p>
<p>This is the plain encoding that must be supported for types.  It is<br>intended to be the simplest encoding.  Values are encoded back to back.</p>
<p>The plain encoding is used whenever a more efficient encoding can not be used. It<br>stores the data in the following format:</p>
<ul>
<li>BOOLEAN: <a href="#RLE">Bit Packed</a>, LSB first</li>
<li>INT32: 4 bytes little endian</li>
<li>INT64: 8 bytes little endian</li>
<li>INT96: 12 bytes little endian (deprecated)</li>
<li>FLOAT: 4 bytes IEEE little endian</li>
<li>DOUBLE: 8 bytes IEEE little endian</li>
<li>BYTE_ARRAY: length in 4 bytes little endian followed by the bytes contained in the array</li>
<li>FIXED_LEN_BYTE_ARRAY: the bytes contained in the array</li>
</ul>
<p>For native types, this outputs the data as little endian. Floating<br>    point types are encoded in IEEE.</p>
<p>For the byte array type, it encodes the length as a 4 byte little<br>endian, followed by the bytes.</p>
<h3 id="Dictionary-Encoding-PLAIN-DICTIONARY-2-and-RLE-DICTIONARY-8"><a href="#Dictionary-Encoding-PLAIN-DICTIONARY-2-and-RLE-DICTIONARY-8" class="headerlink" title="Dictionary Encoding (PLAIN_DICTIONARY = 2 and RLE_DICTIONARY = 8)"></a>Dictionary Encoding (PLAIN_DICTIONARY = 2 and RLE_DICTIONARY = 8)</h3><p>The dictionary encoding builds a dictionary of values encountered in a given column. The<br>dictionary will be stored in a dictionary page per column chunk. The values are stored as integers<br>using the <a href="#RLE">RLE/Bit-Packing Hybrid</a> encoding. If the dictionary grows too big, whether in size<br>or number of distinct values, the encoding will fall back to the plain encoding. The dictionary page is<br>written first, before the data pages of the column chunk.</p>
<p>Dictionary page format: the entries in the dictionary - in dictionary order - using the <a href="#PLAIN">plain</a> encoding.</p>
<p>Data page format: the bit width used to encode the entry ids stored as 1 byte (max bit width = 32),<br>followed by the values encoded using RLE/Bit packed described above (with the given bit width).</p>
<p>Using the PLAIN_DICTIONARY enum value is deprecated in the Parquet 2.0 specification. Prefer using RLE_DICTIONARY<br>in a data page and PLAIN in a dictionary page for Parquet 2.0+ files.</p>
<h3 id="Run-Length-Encoding-Bit-Packing-Hybrid-RLE-3"><a href="#Run-Length-Encoding-Bit-Packing-Hybrid-RLE-3" class="headerlink" title="Run Length Encoding / Bit-Packing Hybrid (RLE = 3)"></a><a name="RLE"></a>Run Length Encoding / Bit-Packing Hybrid (RLE = 3)</h3><p>This encoding uses a combination of bit-packing and run length encoding to more efficiently store repeated values.</p>
<p>The grammar for this encoding looks like this, given a fixed bit-width known in advance:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">rle-bit-packed-hybrid: &lt;length&gt; &lt;encoded-data&gt;</span><br><span class="line">length := length of the &lt;encoded-data&gt; in bytes stored as 4 bytes little endian (unsigned int32)</span><br><span class="line">encoded-data := &lt;run&gt;*</span><br><span class="line">run := &lt;bit-packed-run&gt; | &lt;rle-run&gt;</span><br><span class="line">bit-packed-run := &lt;bit-packed-header&gt; &lt;bit-packed-values&gt;</span><br><span class="line">bit-packed-header := varint-encode(&lt;bit-pack-scaled-run-len&gt; &lt;&lt; 1 | 1)</span><br><span class="line">// we always bit-pack a multiple of 8 values at a time, so we only store the number of values / 8</span><br><span class="line">bit-pack-scaled-run-len := (bit-packed-run-len) / 8</span><br><span class="line">bit-packed-run-len := *see 3 below*</span><br><span class="line">bit-packed-values := *see 1 below*</span><br><span class="line">rle-run := &lt;rle-header&gt; &lt;repeated-value&gt;</span><br><span class="line">rle-header := varint-encode( (rle-run-len) &lt;&lt; 1)</span><br><span class="line">rle-run-len := *see 3 below*</span><br><span class="line">repeated-value := value that is repeated, using a fixed-width of round-up-to-next-byte(bit-width)</span><br></pre></td></tr></table></figure></p>
<ol>
<li><p>The bit-packing here is done in a different order than the one in the <a href="#BITPACKED">deprecated bit-packing</a> encoding.<br>The values are packed from the least significant bit of each byte to the most significant bit,<br>though the order of the bits in each value remains in the usual order of most significant to least<br>significant. For example, to pack the same values as the example in the deprecated encoding above:</p>
<p>The numbers 1 through 7 using bit width 3:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dec value: 0   1   2   3   4   5   6   7</span><br><span class="line">bit value: 000 001 010 011 100 101 110 111</span><br><span class="line">bit label: ABC DEF GHI JKL MNO PQR STU VWX</span><br></pre></td></tr></table></figure>
<p>would be encoded like this where spaces mark byte boundaries (3 bytes):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bit value: 10001000 11000110 11111010</span><br><span class="line">bit label: HIDEFABC RMNOJKLG VWXSTUPQ</span><br></pre></td></tr></table></figure>
<p>The reason for this packing order is to have fewer word-boundaries on little-endian hardware<br>when deserializing more than one byte at at time. This is because 4 bytes can be read into a<br>32 bit register (or 8 bytes into a 64 bit register) and values can be unpacked just by<br>shifting and ORing with a mask. (to make this optimization work on a big-endian machine,<br>you would have to use the ordering used in the <a href="#BITPACKED">deprecated bit-packing</a> encoding)</p>
</li>
<li><p>varint-encode() is ULEB-128 encoding, see <a href="https://en.wikipedia.org/wiki/LEB128" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/LEB128</a></p>
</li>
<li><p>bit-packed-run-len and rle-run-len must be in the range [1, 2<sup>31</sup> - 1].<br>This means that a Parquet implementation can always store the run length in a signed<br>32-bit integer. This length restriction was not part of the Parquet 2.5.0 and earlier<br>specifications, but longer runs were not readable by the most common Parquet<br>implementations so, in practice, were not safe for Parquet writers to emit.</p>
</li>
</ol>
<p>Note that the RLE encoding method is only supported for the following types of<br>data:</p>
<ul>
<li>Repetition and definition levels</li>
<li>Dictionary indices</li>
<li>Boolean values in data pages, as an alternative to PLAIN encoding</li>
</ul>
<h3 id="Bit-packed-Deprecated-BIT-PACKED-4"><a href="#Bit-packed-Deprecated-BIT-PACKED-4" class="headerlink" title="Bit-packed (Deprecated) (BIT_PACKED = 4)"></a><a name="BITPACKED"></a>Bit-packed (Deprecated) (BIT_PACKED = 4)</h3><p>This is a bit-packed only encoding, which is deprecated and will be replaced by the <a href="#RLE">RLE/bit-packing</a> hybrid encoding.<br>Each value is encoded back to back using a fixed width.<br>There is no padding between values (except for the last byte) which is padded with 0s.<br>For example, if the max repetition level was 3 (2 bits) and the max definition level as 3<br>(2 bits), to encode 30 values, we would have 30 * 2 = 60 bits = 8 bytes.</p>
<p>This implementation is deprecated because the <a href="#RLE">RLE/bit-packing</a> hybrid is a superset of this implementation.<br>For compatibility reasons, this implementation packs values from the most significant bit to the least significant bit,<br>which is not the same as the <a href="#RLE">RLE/bit-packing</a> hybrid.</p>
<p>For example, the numbers 1 through 7 using bit width 3:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dec value: 0   1   2   3   4   5   6   7</span><br><span class="line">bit value: 000 001 010 011 100 101 110 111</span><br><span class="line">bit label: ABC DEF GHI JKL MNO PQR STU VWX</span><br></pre></td></tr></table></figure></p>
<p>would be encoded like this where spaces mark byte boundaries (3 bytes):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bit value: 00000101 00111001 01110111</span><br><span class="line">bit label: ABCDEFGH IJKLMNOP QRSTUVWX</span><br></pre></td></tr></table></figure></p>
<p>Note that the BIT_PACKED encoding method is only supported for encoding<br>repetition and definition levels.</p>
<h3 id="Delta-Encoding-DELTA-BINARY-PACKED-5"><a href="#Delta-Encoding-DELTA-BINARY-PACKED-5" class="headerlink" title="Delta Encoding (DELTA_BINARY_PACKED = 5)"></a><a name="DELTAENC"></a>Delta Encoding (DELTA_BINARY_PACKED = 5)</h3><p>Supported Types: INT32, INT64</p>
<p>This encoding is adapted from the Binary packing described in <a href="http://arxiv.org/pdf/1209.2137v5.pdf" target="_blank" rel="noopener">“Decoding billions of integers per second through vectorization”</a> by D. Lemire and L. Boytsov</p>
<p>Delta encoding consists of a header followed by blocks of delta encoded values binary packed. Each block is made of miniblocks, each of them binary packed with its own bit width. When there are not enough values to encode a full block we pad with zeros (added to the frame of reference).<br>The header is defined as follows:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;block size in values&gt; &lt;number of miniblocks in a block&gt; &lt;total value count&gt; &lt;first value&gt;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>the block size is a multiple of 128 stored as VLQ int</li>
<li>the miniblock count per block is a diviser of the block size stored as VLQ int the number of values in the miniblock is a multiple of 32.</li>
<li>the total value count is stored as a VLQ int</li>
<li>the first value is stored as a zigzag VLQ int</li>
</ul>
<p>Each block contains<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;min delta&gt; &lt;list of bitwidths of miniblocks&gt; &lt;miniblocks&gt;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>the min delta is a VLQ int (we compute a minimum as we need positive integers for bit packing)</li>
<li>the bitwidth of each block is stored as a byte</li>
<li>each miniblock is a list of bit packed ints according to the bit width stored at the begining of the block</li>
</ul>
<p>Having multiple blocks allows us to escape values and restart from a new base value.</p>
<p>To encode each delta block, we will:</p>
<ol>
<li><p>Compute the deltas</p>
</li>
<li><p>Encode the first value as zigzag VLQ int</p>
</li>
<li><p>For each block, compute the frame of reference(minimum of the deltas) for the deltas. This guarantees<br>all deltas are positive.</p>
</li>
<li><p>encode the frame of reference delta as VLQ int followed by the delta values (minus the minimum) encoded as bit packed per miniblock.</p>
</li>
</ol>
<p>Steps 2 and 3 are skipped if the number of values in the block is 1.</p>
<h4 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h4><p>1, 2, 3, 4, 5</p>
<p>After step 1), we compute the deltas as:</p>
<p>1, 1, 1, 1</p>
<p>The minimum delta is 1 and after step 2, the deltas become</p>
<p>0, 0, 0, 0</p>
<p>The final encoded data is:</p>
<p> header:<br>8 (block size), 1 (miniblock count), 5 (value count), 1 (first value)</p>
<p> block<br>1 (minimum delta), 0 (bitwidth), (no data needed for bitwidth 0)</p>
<h4 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h4><p>7, 5, 3, 1, 2, 3, 4, 5, the deltas would be</p>
<p>-2, -2, -2, 1, 1, 1, 1</p>
<p>The minimum is -2, so the relative deltas are:</p>
<p>0, 0, 0, 3, 3, 3, 3</p>
<p>The encoded data is</p>
<p> header:<br>8 (block size), 1 (miniblock count), 8 (value count), 7 (first value)</p>
<p> block<br>-2 (minimum delta), 2 (bitwidth), 00000011111111b (0,0,0,3,3,3,3 packed on 2 bits)</p>
<h4 id="Characteristics"><a href="#Characteristics" class="headerlink" title="Characteristics"></a>Characteristics</h4><p>This encoding is similar to the <a href="#RLE">RLE/bit-packing</a> encoding. However the <a href="#RLE">RLE/bit-packing</a> encoding is specifically used when the range of ints is small over the entire page, as is true of repetition and definition levels. It uses a single bit width for the whole page.<br>The delta encoding algorithm described above stores a bit width per mini block and is less sensitive to variations in the size of encoded integers. It is also somewhat doing RLE encoding as a block containing all the same values will be bit packed to a zero bit width thus being only a header.</p>
<h3 id="Delta-length-byte-array-DELTA-LENGTH-BYTE-ARRAY-6"><a href="#Delta-length-byte-array-DELTA-LENGTH-BYTE-ARRAY-6" class="headerlink" title="Delta-length byte array: (DELTA_LENGTH_BYTE_ARRAY = 6)"></a>Delta-length byte array: (DELTA_LENGTH_BYTE_ARRAY = 6)</h3><p>Supported Types: BYTE_ARRAY</p>
<p>This encoding is always preferred over PLAIN for byte array columns.</p>
<p>For this encoding, we will take all the byte array lengths and encode them using delta<br>encoding (DELTA_BINARY_PACKED). The byte array data follows all of the length data just<br>concatenated back to back. The expected savings is from the cost of encoding the lengths<br>and possibly better compression in the data (it is no longer interleaved with the lengths).</p>
<p>The data stream looks like:</p>
<p><delta encoded="" lengths=""> <byte array="" data=""></byte></delta></p>
<p>For example, if the data was “Hello”, “World”, “Foobar”, “ABCDEF”:</p>
<p>The encoded data would be DeltaEncoding(5, 5, 6, 6) “HelloWorldFoobarABCDEF”</p>
<h3 id="Delta-Strings-DELTA-BYTE-ARRAY-7"><a href="#Delta-Strings-DELTA-BYTE-ARRAY-7" class="headerlink" title="Delta Strings: (DELTA_BYTE_ARRAY = 7)"></a>Delta Strings: (DELTA_BYTE_ARRAY = 7)</h3><p>Supported Types: BYTE_ARRAY</p>
<p>This is also known as incremental encoding or front compression: for each element in a<br>sequence of strings, store the prefix length of the previous entry plus the suffix.</p>
<p>For a longer description, see <a href="https://en.wikipedia.org/wiki/Incremental_encoding" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Incremental_encoding</a>.</p>
<p>This is stored as a sequence of delta-encoded prefix lengths (DELTA_BINARY_PACKED), followed by<br>the suffixes encoded as delta length byte arrays (DELTA_LENGTH_BYTE_ARRAY).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/08/21/Parquet-in-Spark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/21/Parquet-in-Spark/" itemprop="url">Parquet in Spark</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-21T15:11:45+08:00">
                2018-08-21
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/21/Parquet-in-Spark/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/08/21/Parquet-in-Spark/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/21/Parquet-in-Spark/" class="leancloud_visitors" data-flag-title="Parquet in Spark">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>ParquetFileFormat#buildReaderWithPartitionValues</p>
<p>注意看 enableVectorizedReader. enable 了之后用的是<code>VectorizedParquetRecordReader</code>, 否则用的是<code>ParquetRecordReader[UnsafeRow](new ParquetReadSupport(convertTz))</code>.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Try to push down filters when filter push-down is enabled.</span></span><br><span class="line"><span class="comment">// Notice: This push-down is RowGroups level, not individual records.</span></span><br><span class="line"><span class="keyword">if</span> (pushed.isDefined) &#123;</span><br><span class="line">  <span class="type">ParquetInputFormat</span>.setFilterPredicate(hadoopAttemptContext.getConfiguration, pushed.get)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> taskContext = <span class="type">Option</span>(<span class="type">TaskContext</span>.get())</span><br><span class="line"><span class="keyword">if</span> (enableVectorizedReader) &#123;</span><br><span class="line">  <span class="keyword">val</span> vectorizedReader = <span class="keyword">new</span> <span class="type">VectorizedParquetRecordReader</span>(</span><br><span class="line">    convertTz.orNull, enableOffHeapColumnVector &amp;&amp; taskContext.isDefined, capacity)</span><br><span class="line">  <span class="keyword">val</span> iter = <span class="keyword">new</span> <span class="type">RecordReaderIterator</span>(vectorizedReader)</span><br><span class="line">  <span class="comment">// SPARK-23457 Register a task completion lister before `initialization`.</span></span><br><span class="line">  taskContext.foreach(_.addTaskCompletionListener[<span class="type">Unit</span>](_ =&gt; iter.close()))</span><br><span class="line">  vectorizedReader.initialize(split, hadoopAttemptContext)</span><br><span class="line">  logDebug(<span class="string">s"Appending <span class="subst">$partitionSchema</span> <span class="subst">$&#123;file.partitionValues&#125;</span>"</span>)</span><br><span class="line">  vectorizedReader.initBatch(partitionSchema, file.partitionValues)</span><br><span class="line">  <span class="keyword">if</span> (returningBatch) &#123;</span><br><span class="line">    vectorizedReader.enableReturningBatches()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// UnsafeRowParquetRecordReader appends the columns internally to avoid another copy.</span></span><br><span class="line">  iter.asInstanceOf[<span class="type">Iterator</span>[<span class="type">InternalRow</span>]]</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  logDebug(<span class="string">s"Falling back to parquet-mr"</span>)</span><br><span class="line">  <span class="comment">// ParquetRecordReader returns UnsafeRow</span></span><br><span class="line">  <span class="keyword">val</span> reader = <span class="keyword">if</span> (pushed.isDefined &amp;&amp; enableRecordFilter) &#123;</span><br><span class="line">    <span class="keyword">val</span> parquetFilter = <span class="type">FilterCompat</span>.get(pushed.get, <span class="literal">null</span>)</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ParquetRecordReader</span>[<span class="type">UnsafeRow</span>](<span class="keyword">new</span> <span class="type">ParquetReadSupport</span>(convertTz), parquetFilter)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ParquetRecordReader</span>[<span class="type">UnsafeRow</span>](<span class="keyword">new</span> <span class="type">ParquetReadSupport</span>(convertTz))</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">val</span> iter = <span class="keyword">new</span> <span class="type">RecordReaderIterator</span>(reader)</span><br><span class="line">  <span class="comment">// SPARK-23457 Register a task completion lister before `initialization`.</span></span><br><span class="line">  taskContext.foreach(_.addTaskCompletionListener[<span class="type">Unit</span>](_ =&gt; iter.close()))</span><br><span class="line">  reader.initialize(split, hadoopAttemptContext)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> fullSchema = requiredSchema.toAttributes ++ partitionSchema.toAttributes</span><br><span class="line">  <span class="keyword">val</span> joinedRow = <span class="keyword">new</span> <span class="type">JoinedRow</span>()</span><br><span class="line">  <span class="keyword">val</span> appendPartitionColumns = <span class="type">GenerateUnsafeProjection</span>.generate(fullSchema, fullSchema)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// This is a horrible erasure hack...  if we type the iterator above, then it actually check</span></span><br><span class="line">  <span class="comment">// the type in next() and we get a class cast exception.  If we make that function return</span></span><br><span class="line">  <span class="comment">// Object, then we can defer the cast until later!</span></span><br><span class="line">  <span class="keyword">if</span> (partitionSchema.length == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// There is no partition columns</span></span><br><span class="line">    iter.asInstanceOf[<span class="type">Iterator</span>[<span class="type">InternalRow</span>]]</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    iter.asInstanceOf[<span class="type">Iterator</span>[<span class="type">InternalRow</span>]]</span><br><span class="line">      .map(d =&gt; appendPartitionColumns(joinedRow(d, file.partitionValues)))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>来看 <code>VectorizedParquetRecordReader</code>:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Advances to the next batch of rows. Returns false if there are no more.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">public boolean nextBatch() <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">WritableColumnVector</span> vector : columnVectors) &#123;</span><br><span class="line">    vector.reset();</span><br><span class="line">  &#125;</span><br><span class="line">  columnarBatch.setNumRows(<span class="number">0</span>);</span><br><span class="line">  <span class="keyword">if</span> (rowsReturned &gt;= totalRowCount) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  checkEndOfRowGroup();</span><br><span class="line"></span><br><span class="line">  int num = (int) <span class="type">Math</span>.min((long) capacity, totalCountLoadedSoFar - rowsReturned);</span><br><span class="line">  <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; columnReaders.length; ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span> (columnReaders[i] == <span class="literal">null</span>) <span class="keyword">continue</span>;</span><br><span class="line">    columnReaders[i].readBatch(num, columnVectors[i]);</span><br><span class="line">  &#125;</span><br><span class="line">  rowsReturned += num;</span><br><span class="line">  columnarBatch.setNumRows(num);</span><br><span class="line">  numBatched = num;</span><br><span class="line">  batchIdx = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> void checkEndOfRowGroup() <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (rowsReturned != totalCountLoadedSoFar) <span class="keyword">return</span>;</span><br><span class="line">  <span class="type">PageReadStore</span> pages = reader.readNextRowGroup();</span><br><span class="line">  <span class="keyword">if</span> (pages == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IOException</span>(<span class="string">"expecting more rows but reached last block. Read "</span></span><br><span class="line">        + rowsReturned + <span class="string">" out of "</span> + totalRowCount);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">List</span>&lt;<span class="type">ColumnDescriptor</span>&gt; columns = requestedSchema.getColumns();</span><br><span class="line">  <span class="type">List</span>&lt;<span class="type">Type</span>&gt; types = requestedSchema.asGroupType().getFields();</span><br><span class="line">  columnReaders = <span class="keyword">new</span> <span class="type">VectorizedColumnReader</span>[columns.size()];</span><br><span class="line">  <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; columns.size(); ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span> (missingColumns[i]) <span class="keyword">continue</span>;</span><br><span class="line">    columnReaders[i] = <span class="keyword">new</span> <span class="type">VectorizedColumnReader</span>(columns.get(i), types.get(i).getOriginalType(),</span><br><span class="line">      pages.getPageReader(columns.get(i)), convertTz);</span><br><span class="line">  &#125;</span><br><span class="line">  totalCountLoadedSoFar += pages.getRowCount();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>VectorizedColumnReader</code>:Decoder to return values from a single column.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Reads `total` values from this columnReader into column.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">readBatch</span><span class="params">(<span class="keyword">int</span> total, WritableColumnVector column)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> rowId = <span class="number">0</span>;</span><br><span class="line">  WritableColumnVector dictionaryIds = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (dictionary != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// SPARK-16334: We only maintain a single dictionary per row batch, so that it can be used to</span></span><br><span class="line">    <span class="comment">// decode all previous dictionary encoded pages if we ever encounter a non-dictionary encoded</span></span><br><span class="line">    <span class="comment">// page.</span></span><br><span class="line">    dictionaryIds = column.reserveDictionaryIds(total);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> (total &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Compute the number of values we want to read in this page.</span></span><br><span class="line">    <span class="keyword">int</span> leftInPage = (<span class="keyword">int</span>) (endOfPageValueCount - valuesRead);</span><br><span class="line">    <span class="keyword">if</span> (leftInPage == <span class="number">0</span>) &#123;</span><br><span class="line">      readPage();</span><br><span class="line">      leftInPage = (<span class="keyword">int</span>) (endOfPageValueCount - valuesRead);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> num = Math.min(total, leftInPage);</span><br><span class="line">    PrimitiveType.PrimitiveTypeName typeName =</span><br><span class="line">      descriptor.getPrimitiveType().getPrimitiveTypeName();</span><br><span class="line">    <span class="keyword">if</span> (isCurrentPageDictionaryEncoded) &#123;</span><br><span class="line">      <span class="comment">// Read and decode dictionary ids.</span></span><br><span class="line">      defColumn.readIntegers(</span><br><span class="line">          num, dictionaryIds, column, rowId, maxDefLevel, (VectorizedValuesReader) dataColumn);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// TIMESTAMP_MILLIS encoded as INT64 can't be lazily decoded as we need to post process</span></span><br><span class="line">      <span class="comment">// the values to add microseconds precision.</span></span><br><span class="line">      <span class="keyword">if</span> (column.hasDictionary() || (rowId == <span class="number">0</span> &amp;&amp;</span><br><span class="line">          (typeName == PrimitiveType.PrimitiveTypeName.INT32 ||</span><br><span class="line">          (typeName == PrimitiveType.PrimitiveTypeName.INT64 &amp;&amp;</span><br><span class="line">            originalType != OriginalType.TIMESTAMP_MILLIS) ||</span><br><span class="line">          typeName == PrimitiveType.PrimitiveTypeName.FLOAT ||</span><br><span class="line">          typeName == PrimitiveType.PrimitiveTypeName.DOUBLE ||</span><br><span class="line">          typeName == PrimitiveType.PrimitiveTypeName.BINARY))) &#123;</span><br><span class="line">        <span class="comment">// Column vector supports lazy decoding of dictionary values so just set the dictionary.</span></span><br><span class="line">        <span class="comment">// We can't do this if rowId != 0 AND the column doesn't have a dictionary (i.e. some</span></span><br><span class="line">        <span class="comment">// non-dictionary encoded values have already been added).</span></span><br><span class="line">        column.setDictionary(<span class="keyword">new</span> ParquetDictionary(dictionary));</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        decodeDictionaryIds(rowId, num, column, dictionaryIds);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (column.hasDictionary() &amp;&amp; rowId != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// This batch already has dictionary encoded values but this new page is not. The batch</span></span><br><span class="line">        <span class="comment">// does not support a mix of dictionary and not so we will decode the dictionary.</span></span><br><span class="line">        decodeDictionaryIds(<span class="number">0</span>, rowId, column, column.getDictionaryIds());</span><br><span class="line">      &#125;</span><br><span class="line">      column.setDictionary(<span class="keyword">null</span>);</span><br><span class="line">      <span class="keyword">switch</span> (typeName) &#123;</span><br><span class="line">        <span class="keyword">case</span> BOOLEAN:</span><br><span class="line">          readBooleanBatch(rowId, num, column);</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> INT32:</span><br><span class="line">          readIntBatch(rowId, num, column);</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> INT64:</span><br><span class="line">          readLongBatch(rowId, num, column);</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> INT96:</span><br><span class="line">          readBinaryBatch(rowId, num, column);</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> FLOAT:</span><br><span class="line">          readFloatBatch(rowId, num, column);</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> DOUBLE:</span><br><span class="line">          readDoubleBatch(rowId, num, column);</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> BINARY:</span><br><span class="line">          readBinaryBatch(rowId, num, column);</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> FIXED_LEN_BYTE_ARRAY:</span><br><span class="line">          readFixedLenByteArrayBatch(</span><br><span class="line">            rowId, num, column, descriptor.getPrimitiveType().getTypeLength());</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unsupported type: "</span> + typeName);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    valuesRead += num;</span><br><span class="line">    rowId += num;</span><br><span class="line">    total -= num;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readIntBatch</span><span class="params">(<span class="keyword">int</span> rowId, <span class="keyword">int</span> num, WritableColumnVector column)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// This is where we implement support for the valid type conversions.</span></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> implement remaining type conversions</span></span><br><span class="line">  <span class="keyword">if</span> (column.dataType() == DataTypes.IntegerType || column.dataType() == DataTypes.DateType ||</span><br><span class="line">      DecimalType.is32BitDecimalType(column.dataType())) &#123;</span><br><span class="line">    defColumn.readIntegers(</span><br><span class="line">        num, column, rowId, maxDefLevel, (VectorizedValuesReader) dataColumn);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (column.dataType() == DataTypes.ByteType) &#123;</span><br><span class="line">    defColumn.readBytes(</span><br><span class="line">        num, column, rowId, maxDefLevel, (VectorizedValuesReader) dataColumn);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (column.dataType() == DataTypes.ShortType) &#123;</span><br><span class="line">    defColumn.readShorts(</span><br><span class="line">        num, column, rowId, maxDefLevel, (VectorizedValuesReader) dataColumn);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">throw</span> constructConvertNotSupportedException(descriptor, column);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>VectorizedRleValuesReader#readIntegers</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Reads `total` ints into `c` filling them in starting at `c[rowId]`. This reader</span></span><br><span class="line"><span class="comment"> * reads the definition levels and then will read from `data` for the non-null values.</span></span><br><span class="line"><span class="comment"> * If the value is null, c will be populated with `nullValue`. Note that `nullValue` is only</span></span><br><span class="line"><span class="comment"> * necessary for readIntegers because we also use it to decode dictionaryIds and want to make</span></span><br><span class="line"><span class="comment"> * sure it always has a value in range.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This is a batched version of this logic:</span></span><br><span class="line"><span class="comment"> *  if (this.readInt() == level) &#123;</span></span><br><span class="line"><span class="comment"> *    c[rowId] = data.readInteger();</span></span><br><span class="line"><span class="comment"> *  &#125; else &#123;</span></span><br><span class="line"><span class="comment"> *    c[rowId] = null;</span></span><br><span class="line"><span class="comment"> *  &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readIntegers</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> total,</span></span></span><br><span class="line"><span class="function"><span class="params">    WritableColumnVector c,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> rowId,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> level,</span></span></span><br><span class="line"><span class="function"><span class="params">    VectorizedValuesReader data)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> left = total;</span><br><span class="line">  <span class="keyword">while</span> (left &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.currentCount == <span class="number">0</span>) <span class="keyword">this</span>.readNextGroup();</span><br><span class="line">    <span class="keyword">int</span> n = Math.min(left, <span class="keyword">this</span>.currentCount);</span><br><span class="line">    <span class="keyword">switch</span> (mode) &#123;</span><br><span class="line">      <span class="keyword">case</span> RLE:</span><br><span class="line">        <span class="keyword">if</span> (currentValue == level) &#123;</span><br><span class="line">          data.readIntegers(n, c, rowId);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          c.putNulls(rowId, n);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> PACKED:</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">          <span class="keyword">if</span> (currentBuffer[currentBufferIdx++] == level) &#123;</span><br><span class="line">            c.putInt(rowId + i, data.readInteger());</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            c.putNull(rowId + i);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    rowId += n;</span><br><span class="line">    left -= n;</span><br><span class="line">    currentCount -= n;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>VectorizedPlainValuesReader#readIntegers</code>:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VectorizedPlainValuesReader</span> <span class="keyword">extends</span> <span class="title">ValuesReader</span> <span class="keyword">implements</span> <span class="title">VectorizedValuesReader</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">readIntegers</span><span class="params">(<span class="keyword">int</span> total, WritableColumnVector c, <span class="keyword">int</span> rowId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> requiredBytes = total * <span class="number">4</span>;</span><br><span class="line">    ByteBuffer buffer = getBuffer(requiredBytes);</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (buffer.hasArray()) &#123;</span><br><span class="line">      <span class="keyword">int</span> offset = buffer.arrayOffset() + buffer.position();</span><br><span class="line">      c.putIntsLittleEndian(rowId, total, buffer.array(), offset);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; total; i += <span class="number">1</span>) &#123;</span><br><span class="line">        c.putInt(rowId + i, buffer.getInt());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>OffHeapColumnVector#putIntsLittleEndian</code>:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Column data backed using offheap memory.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">OffHeapColumnVector</span> <span class="keyword">extends</span> <span class="title">WritableColumnVector</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putIntsLittleEndian</span><span class="params">(<span class="keyword">int</span> rowId, <span class="keyword">int</span> count, <span class="keyword">byte</span>[] src, <span class="keyword">int</span> srcIndex)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!bigEndianPlatform) &#123;</span><br><span class="line">      Platform.copyMemory(src, srcIndex + Platform.BYTE_ARRAY_OFFSET,</span><br><span class="line">          <span class="keyword">null</span>, data + <span class="number">4L</span> * rowId, count * <span class="number">4L</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">int</span> srcOffset = srcIndex + Platform.BYTE_ARRAY_OFFSET;</span><br><span class="line">      <span class="keyword">long</span> offset = data + <span class="number">4L</span> * rowId;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; ++i, offset += <span class="number">4</span>, srcOffset += <span class="number">4</span>) &#123;</span><br><span class="line">        Platform.putInt(<span class="keyword">null</span>, offset,</span><br><span class="line">            java.lang.Integer.reverseBytes(Platform.getInt(src, srcOffset)));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="ColumnarBatch"><a href="#ColumnarBatch" class="headerlink" title="ColumnarBatch"></a>ColumnarBatch</h3><p>columnarBatch.column 返回一个 ColumnVector, 可以看到是一列作为一个 ColumnVector.一次 put 是 put 一行, rowId 会 ++.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">test(<span class="string">"ColumnBatch"</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> schema = <span class="type">StructType</span>(</span><br><span class="line">    <span class="type">Array</span>(</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"id"</span>, <span class="type">IntegerType</span>, nullable = <span class="literal">true</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"birth"</span>, <span class="type">DateType</span>, nullable = <span class="literal">true</span>),</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"time"</span>, <span class="type">TimestampType</span>, nullable = <span class="literal">true</span>)</span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> columnarBatch = <span class="type">ColumnarBatch</span>.allocate(schema, <span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span>, <span class="number">1024</span>)</span><br><span class="line">  <span class="keyword">val</span> c0 = columnarBatch.column(<span class="number">0</span>)</span><br><span class="line">  <span class="keyword">val</span> c1 = columnarBatch.column(<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">val</span> c2 = columnarBatch.column(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">  c0.putInt(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">  <span class="comment">// 1355241600 &lt;=&gt; 2012-12-12, /3600/24 to days</span></span><br><span class="line">  c1.putInt(<span class="number">0</span>, <span class="number">1355241600</span> / <span class="number">3600</span> / <span class="number">24</span>)</span><br><span class="line">  <span class="comment">// microsecond</span></span><br><span class="line">  c2.putLong(<span class="number">0</span>, <span class="number">1355285532000000</span>L)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> internal0 = columnarBatch.getRow(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> convert = <span class="type">UnsafeProjection</span>.create(schema)</span><br><span class="line">  <span class="keyword">val</span> internal = convert.apply(internal0)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> enc = <span class="type">RowEncoder</span>.apply(schema).resolveAndBind()</span><br><span class="line">  <span class="keyword">val</span> row = enc.fromRow(internal0)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> df = spark.createDataFrame(<span class="type">Lists</span>.newArrayList(row), schema)</span><br><span class="line">  print(df.take(<span class="number">1</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="ColumnVector"><a href="#ColumnVector" class="headerlink" title="ColumnVector"></a>ColumnVector</h3><p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-21/71064933.jpg" alt=""></p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-21/4432890.jpg" alt=""></p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-21/77850304.jpg" alt=""></p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-21/54044866.jpg" alt=""></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"> * Capacity: The data stored is dense but the arrays are not fixed capacity. It is the</span><br><span class="line"> * <span class="function">responsibility of the caller to call <span class="title">reserve</span><span class="params">()</span> to ensure there is enough room before adding</span></span><br><span class="line"><span class="function"> * elements. This means that the <span class="title">put</span><span class="params">()</span> APIs <span class="keyword">do</span> not check as in common <span class="title">cases</span> <span class="params">(i.e. flat schemas)</span>,</span></span><br><span class="line"><span class="function"> * the lengths are known up front.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"> * Most of the APIs take the rowId as a parameter. This is the batch local 0-based row id <span class="keyword">for</span> values</span></span><br><span class="line"><span class="function"> * in the current RowBatch.</span></span><br><span class="line"><span class="function"> *</span></span><br><span class="line"><span class="function"> * A ColumnVector should be considered immutable once originally created. In other words, it is not</span></span><br><span class="line"><span class="function"> * valid to call put APIs after reads until <span class="title">reset</span><span class="params">()</span> is called.</span></span><br><span class="line"><span class="function"> *</span></span><br><span class="line"><span class="function"> * ColumnVectors are intended to be reused.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">/**</span></span></span><br><span class="line"><span class="function"><span class="comment"> * A column backed by an in memory JVM array. This stores the NULLs as a byte per value</span></span></span><br><span class="line"><span class="function"><span class="comment"> * and a java array for the values.</span></span></span><br><span class="line"><span class="function"><span class="comment"> */</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> class OnHeapColumnVector extends ColumnVector </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">boolean</span> bigEndianPlatform =</span><br><span class="line">    ByteOrder.nativeOrder().equals(ByteOrder.BIG_ENDIAN);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The data stored in these arrays need to maintain binary compatible. We can</span></span><br><span class="line">  <span class="comment">// directly pass this buffer to external components.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// This is faster than a boolean array and we optimize this over memory footprint.</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">byte</span>[] nulls;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Array for each type. Only 1 is populated for any type.</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">byte</span>[] byteData;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">short</span>[] shortData;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span>[] intData;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span>[] longData;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">float</span>[] floatData;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">double</span>[] doubleData;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Only set if type is Array.</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span>[] arrayLengths;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span>[] arrayOffsets;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="title">OnHeapColumnVector</span><span class="params">(<span class="keyword">int</span> capacity, DataType type)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(capacity, type, MemoryMode.ON_HEAP);</span><br><span class="line">    reserveInternal(capacity);</span><br><span class="line">    reset();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.close();</span><br><span class="line">    nulls = <span class="keyword">null</span>;</span><br><span class="line">    byteData = <span class="keyword">null</span>;</span><br><span class="line">    shortData = <span class="keyword">null</span>;</span><br><span class="line">    intData = <span class="keyword">null</span>;</span><br><span class="line">    longData = <span class="keyword">null</span>;</span><br><span class="line">    floatData = <span class="keyword">null</span>;</span><br><span class="line">    doubleData = <span class="keyword">null</span>;</span><br><span class="line">    arrayLengths = <span class="keyword">null</span>;</span><br><span class="line">    arrayOffsets = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putInts</span><span class="params">(<span class="keyword">int</span> rowId, <span class="keyword">int</span> count, <span class="keyword">int</span>[] src, <span class="keyword">int</span> srcIndex)</span> </span>&#123;</span><br><span class="line">    System.arraycopy(src, srcIndex, intData, rowId, count);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getInt</span><span class="params">(<span class="keyword">int</span> rowId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (dictionary == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> intData[rowId];</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> dictionary.decodeToInt(dictionaryIds.getDictId(rowId));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Column data backed using offheap memory.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">OffHeapColumnVector</span> <span class="keyword">extends</span> <span class="title">ColumnVector</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">boolean</span> bigEndianPlatform =</span><br><span class="line">    ByteOrder.nativeOrder().equals(ByteOrder.BIG_ENDIAN);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The data stored in these two allocations need to maintain binary compatible. We can</span></span><br><span class="line">  <span class="comment">// directly pass this buffer to external components.</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> nulls;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> data;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Set iff the type is array.</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> lengthData;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> offsetData;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="title">OffHeapColumnVector</span><span class="params">(<span class="keyword">int</span> capacity, DataType type)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(capacity, type, MemoryMode.OFF_HEAP);</span><br><span class="line"></span><br><span class="line">    nulls = <span class="number">0</span>;</span><br><span class="line">    data = <span class="number">0</span>;</span><br><span class="line">    lengthData = <span class="number">0</span>;</span><br><span class="line">    offsetData = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    reserveInternal(capacity);</span><br><span class="line">    reset();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">valuesNativeAddress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> data;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">nullsNativeAddress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> nulls;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.close();</span><br><span class="line">    Platform.freeMemory(nulls);</span><br><span class="line">    Platform.freeMemory(data);</span><br><span class="line">    Platform.freeMemory(lengthData);</span><br><span class="line">    Platform.freeMemory(offsetData);</span><br><span class="line">    nulls = <span class="number">0</span>;</span><br><span class="line">    data = <span class="number">0</span>;</span><br><span class="line">    lengthData = <span class="number">0</span>;</span><br><span class="line">    offsetData = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putInts</span><span class="params">(<span class="keyword">int</span> rowId, <span class="keyword">int</span> count, <span class="keyword">int</span>[] src, <span class="keyword">int</span> srcIndex)</span> </span>&#123;</span><br><span class="line">    Platform.copyMemory(src, Platform.INT_ARRAY_OFFSET + srcIndex * <span class="number">4</span>,</span><br><span class="line">        <span class="keyword">null</span>, data + <span class="number">4</span> * rowId, count * <span class="number">4</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getInt</span><span class="params">(<span class="keyword">int</span> rowId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (dictionary == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> Platform.getInt(<span class="keyword">null</span>, data + <span class="number">4</span> * rowId);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> dictionary.decodeToInt(dictionaryIds.getDictId(rowId));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Something-interesting-about-decimal-in-Spark"><a href="#Something-interesting-about-decimal-in-Spark" class="headerlink" title="Something interesting about decimal in Spark."></a>Something interesting about decimal in Spark.</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Returns the decimal for rowId.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Decimal <span class="title">getDecimal</span><span class="params">(<span class="keyword">int</span> rowId, <span class="keyword">int</span> precision, <span class="keyword">int</span> scale)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (precision &lt;= Decimal.MAX_INT_DIGITS()) &#123;</span><br><span class="line">    <span class="keyword">return</span> Decimal.createUnsafe(getInt(rowId), precision, scale);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (precision &lt;= Decimal.MAX_LONG_DIGITS()) &#123;</span><br><span class="line">    <span class="keyword">return</span> Decimal.createUnsafe(getLong(rowId), precision, scale);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> best perf?</span></span><br><span class="line">    <span class="keyword">byte</span>[] bytes = getBinary(rowId);</span><br><span class="line">    BigInteger bigInteger = <span class="keyword">new</span> BigInteger(bytes);</span><br><span class="line">    BigDecimal javaDecimal = <span class="keyword">new</span> BigDecimal(bigInteger, scale);</span><br><span class="line">    <span class="keyword">return</span> Decimal.apply(javaDecimal, precision, scale);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">putDecimal</span><span class="params">(<span class="keyword">int</span> rowId, Decimal value, <span class="keyword">int</span> precision)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (precision &lt;= Decimal.MAX_INT_DIGITS()) &#123;</span><br><span class="line">    putInt(rowId, (<span class="keyword">int</span>) value.toUnscaledLong());</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (precision &lt;= Decimal.MAX_LONG_DIGITS()) &#123;</span><br><span class="line">    putLong(rowId, value.toUnscaledLong());</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    BigInteger bigInteger = value.toJavaBigDecimal().unscaledValue();</span><br><span class="line">    putByteArray(rowId, bigInteger.toByteArray());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="data-flow"><a href="#data-flow" class="headerlink" title="data flow"></a>data flow</h3><p>最底下的流在 <code>VectorizedPlainValuesReader</code><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VectorizedPlainValuesReader</span> <span class="keyword">extends</span> <span class="title">ValuesReader</span> <span class="keyword">implements</span> <span class="title">VectorizedValuesReader</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> ByteBufferInputStream in = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initFromPage</span><span class="params">(<span class="keyword">int</span> valueCount, ByteBufferInputStream in)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.in = in;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> ByteBuffer <span class="title">getBuffer</span><span class="params">(<span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> in.slice(length).order(ByteOrder.LITTLE_ENDIAN);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ParquetDecodingException(<span class="string">"Failed to read "</span> + length + <span class="string">" bytes"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">readIntegers</span><span class="params">(<span class="keyword">int</span> total, WritableColumnVector c, <span class="keyword">int</span> rowId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> requiredBytes = total * <span class="number">4</span>;</span><br><span class="line">    ByteBuffer buffer = getBuffer(requiredBytes);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (buffer.hasArray()) &#123;</span><br><span class="line">      <span class="keyword">int</span> offset = buffer.arrayOffset() + buffer.position();</span><br><span class="line">      c.putIntsLittleEndian(rowId, total, buffer.array(), offset);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; total; i += <span class="number">1</span>) &#123;</span><br><span class="line">        c.putInt(rowId + i, buffer.getInt());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到是 <code>initFromPage</code> 的时候传入的, 是在 <code>VectorizedColumnReader#readPage</code> 时, 读出的 page:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Decoder to return values from a single column.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VectorizedColumnReader</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> ValuesReader dataColumn;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> PageReader pageReader;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readPage</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    DataPage page = pageReader.readPage();</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> Why is this a visitor?</span></span><br><span class="line">    page.accept(<span class="keyword">new</span> DataPage.Visitor&lt;Void&gt;() &#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> Void <span class="title">visit</span><span class="params">(DataPageV1 dataPageV1)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          readPageV1(dataPageV1);</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> Void <span class="title">visit</span><span class="params">(DataPageV2 dataPageV2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          readPageV2(dataPageV2);</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initDataReader</span><span class="params">(Encoding dataEncoding, ByteBufferInputStream in)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (dataEncoding != Encoding.PLAIN) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Unsupported encoding: "</span> + dataEncoding);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.dataColumn = <span class="keyword">new</span> VectorizedPlainValuesReader();</span><br><span class="line">    <span class="keyword">this</span>.isCurrentPageDictionaryEncoded = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      dataColumn.initFromPage(pageValueCount, in);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"could not read page in col "</span> + descriptor, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readPageV1</span><span class="params">(DataPageV1 page)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.pageValueCount = page.getValueCount();</span><br><span class="line">    ValuesReader rlReader = page.getRlEncoding().getValuesReader(descriptor, REPETITION_LEVEL);</span><br><span class="line">    ValuesReader dlReader;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Initialize the decoders.</span></span><br><span class="line">    <span class="keyword">if</span> (page.getDlEncoding() != Encoding.RLE &amp;&amp; descriptor.getMaxDefinitionLevel() != <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Unsupported encoding: "</span> + page.getDlEncoding());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> bitWidth = BytesUtils.getWidthFromMaxInt(descriptor.getMaxDefinitionLevel());</span><br><span class="line">    <span class="keyword">this</span>.defColumn = <span class="keyword">new</span> VectorizedRleValuesReader(bitWidth);</span><br><span class="line">    dlReader = <span class="keyword">this</span>.defColumn;</span><br><span class="line">    <span class="keyword">this</span>.repetitionLevelColumn = <span class="keyword">new</span> ValuesReaderIntIterator(rlReader);</span><br><span class="line">    <span class="keyword">this</span>.definitionLevelColumn = <span class="keyword">new</span> ValuesReaderIntIterator(dlReader);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      BytesInput bytes = page.getBytes();</span><br><span class="line">      ByteBufferInputStream in = bytes.toInputStream();</span><br><span class="line">      rlReader.initFromPage(pageValueCount, in);</span><br><span class="line">      dlReader.initFromPage(pageValueCount, in);</span><br><span class="line">      initDataReader(page.getValueEncoding(), in);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"could not read page "</span> + page + <span class="string">" in col "</span> + descriptor, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readPageV2</span><span class="params">(DataPageV2 page)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.pageValueCount = page.getValueCount();</span><br><span class="line">    <span class="keyword">this</span>.repetitionLevelColumn = createRLEIterator(descriptor.getMaxRepetitionLevel(),</span><br><span class="line">        page.getRepetitionLevels(), descriptor);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> bitWidth = BytesUtils.getWidthFromMaxInt(descriptor.getMaxDefinitionLevel());</span><br><span class="line">    <span class="comment">// do not read the length from the stream. v2 pages handle dividing the page bytes.</span></span><br><span class="line">    <span class="keyword">this</span>.defColumn = <span class="keyword">new</span> VectorizedRleValuesReader(bitWidth, <span class="keyword">false</span>);</span><br><span class="line">    <span class="keyword">this</span>.definitionLevelColumn = <span class="keyword">new</span> ValuesReaderIntIterator(<span class="keyword">this</span>.defColumn);</span><br><span class="line">    <span class="keyword">this</span>.defColumn.initFromPage(</span><br><span class="line">        <span class="keyword">this</span>.pageValueCount, page.getDefinitionLevels().toInputStream());</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      initDataReader(page.getDataEncoding(), page.getData().toInputStream());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"could not read page "</span> + page + <span class="string">" in col "</span> + descriptor, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在 <code>VectorizedColumnReader</code> 会 readPage. 见 VectorizedColumnReader#readBatch. readBatch 又被 VectorizedParquetRecordReader#nextBatch 调用. nextBatch 又被 <code>.VectorizedParquetRecordReader#nextKeyValue</code> 调用</p>
<p><code>nextKeyValue</code> 的调用见:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * An adaptor from a Hadoop [[RecordReader]] to an [[Iterator]] over the values returned.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Note that this returns [[Object]]s instead of [[InternalRow]] because we rely on erasure to pass</span></span><br><span class="line"><span class="comment"> * column batches by pretending they are rows.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">class RecordReaderIterator[T](private[this] var rowReader: RecordReader[_, T]) extends Iterator[T] with Closeable &#123;</span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] var havePair = <span class="keyword">false</span></span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] var finished = <span class="keyword">false</span></span><br><span class="line"></span><br><span class="line">  override def hasNext: Boolean = &#123;</span><br><span class="line">    <span class="keyword">if</span> (!finished &amp;&amp; !havePair) &#123;</span><br><span class="line">      finished = !rowReader.nextKeyValue</span><br><span class="line">      <span class="keyword">if</span> (finished) &#123;</span><br><span class="line">        <span class="comment">// Close and release the reader here; close() will also be called when the task</span></span><br><span class="line">        <span class="comment">// completes, but for tasks that read from many files, it helps to release the</span></span><br><span class="line">        <span class="comment">// resources early.</span></span><br><span class="line">        close()</span><br><span class="line">      &#125;</span><br><span class="line">      havePair = !finished</span><br><span class="line">    &#125;</span><br><span class="line">    !finished</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">override def <span class="title">next</span><span class="params">()</span>: T </span>= &#123;</span><br><span class="line">    <span class="keyword">if</span> (!hasNext) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> java.util.NoSuchElementException(<span class="string">"End of stream"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    havePair = <span class="keyword">false</span></span><br><span class="line">    rowReader.getCurrentValue</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>最后在 ParquetFileFormat 中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (enableVectorizedReader) &#123;</span><br><span class="line">  val vectorizedReader = <span class="keyword">new</span> VectorizedParquetRecordReader(convertTz.orNull, enableOffHeapColumnVector &amp;&amp; taskContext.isDefined, capacity)</span><br><span class="line">  val iter = <span class="keyword">new</span> RecordReaderIterator(vectorizedReader)</span><br><span class="line">  <span class="comment">// SPARK-23457 Register a task completion lister before `initialization`.</span></span><br><span class="line">  taskContext.foreach(_.addTaskCompletionListener[Unit](_ =&gt; iter.close()))</span><br><span class="line">  vectorizedReader.initialize(split, hadoopAttemptContext)</span><br><span class="line">  logDebug(s<span class="string">"Appending $partitionSchema $&#123;file.partitionValues&#125;"</span>)</span><br><span class="line">  vectorizedReader.initBatch(partitionSchema, file.partitionValues)</span><br><span class="line">  <span class="keyword">if</span> (returningBatch) &#123;</span><br><span class="line">    vectorizedReader.enableReturningBatches()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// UnsafeRowParquetRecordReader appends the columns internally to avoid another copy.</span></span><br><span class="line">  iter.asInstanceOf[Iterator[InternalRow]]</span><br><span class="line">&#125; <span class="keyword">else</span> &#123; ... &#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/08/12/Spark-Strategy-DataSource/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/12/Spark-Strategy-DataSource/" itemprop="url">Spark Strategy:DataSource</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-12T22:32:25+08:00">
                2018-08-12
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/12/Spark-Strategy-DataSource/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/08/12/Spark-Strategy-DataSource/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/12/Spark-Strategy-DataSource/" class="leancloud_visitors" data-flag-title="Spark Strategy:DataSource">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><code>DataFrameReader#format(&quot;json&quot;).load(paths : _*)</code> 返回一个 DataFrame, 我们来看看背后发生了什么事情.</p>
<p>首先 <code>load</code>会进入到:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">DataFrameReader</span>#</span><br><span class="line"></span><br><span class="line">sparkSession.baseRelationToDataFrame(</span><br><span class="line">      <span class="type">DataSource</span>.apply(</span><br><span class="line">        sparkSession,</span><br><span class="line">        paths = paths,</span><br><span class="line">        userSpecifiedSchema = userSpecifiedSchema,</span><br><span class="line">        className = source,</span><br><span class="line">        options = extraOptions.toMap).resolveRelation())</span><br></pre></td></tr></table></figure></p>
<p>resolveRelation 会生成一个 Resolved BaseRelation , 如果你看执行计划, 会发现 table scan 那里的执行树节点就是 Relation.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">JsonDataSource</span>#</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inferFromDataset</span></span>(json: <span class="type">Dataset</span>[<span class="type">String</span>], parsedOptions: <span class="type">JSONOptions</span>): <span class="type">StructType</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> sampled: <span class="type">Dataset</span>[<span class="type">String</span>] = <span class="type">JsonUtils</span>.sample(json, parsedOptions)</span><br><span class="line">  <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">UTF8String</span>] = sampled.queryExecution.toRdd.map(_.getUTF8String(<span class="number">0</span>))</span><br><span class="line">  <span class="type">JsonInferSchema</span>.infer(rdd, parsedOptions, <span class="type">CreateJacksonParser</span>.utf8String)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SparkPlan</span># </span><br><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> toRdd: <span class="type">RDD</span>[<span class="type">InternalRow</span>] = executedPlan.execute()</span><br><span class="line"><span class="keyword">lazy</span> <span class="keyword">val</span> executedPlan: <span class="type">SparkPlan</span> = prepareForExecution(sparkPlan)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">lazy</span> <span class="keyword">val</span> sparkPlan: <span class="type">SparkPlan</span> = &#123;</span><br><span class="line">    <span class="type">SparkSession</span>.setActiveSession(sparkSession)</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> We use next(), i.e. take the first plan returned by the planner, here for now,</span></span><br><span class="line">    <span class="comment">//       but we will implement to choose the best plan.</span></span><br><span class="line">    planner.plan(<span class="type">ReturnAnswer</span>(optimizedPlan)).next()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">QueryPlanner</span>#</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">plan</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">Iterator</span>[<span class="type">PhysicalPlan</span>] = &#123;</span><br><span class="line">    <span class="comment">// Obviously a lot to do here still...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Collect physical plan candidates.</span></span><br><span class="line">    <span class="keyword">val</span> candidates = strategies.iterator.flatMap(_(plan))</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A strategy for planning scans over collections of files that might be partitioned or bucketed</span></span><br><span class="line"><span class="comment"> * by user specified columns.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * At a high level planning occurs in several phases:</span></span><br><span class="line"><span class="comment"> *  - Split filters by when they need to be evaluated.</span></span><br><span class="line"><span class="comment"> *  - Prune the schema of the data requested based on any projections present. Today this pruning</span></span><br><span class="line"><span class="comment"> *    is only done on top level columns, but formats should support pruning of nested columns as</span></span><br><span class="line"><span class="comment"> *    well.</span></span><br><span class="line"><span class="comment"> *  - Construct a reader function by passing filters and the schema into the FileFormat.</span></span><br><span class="line"><span class="comment"> *  - Using a partition pruning predicates, enumerate the list of files that should be read.</span></span><br><span class="line"><span class="comment"> *  - Split the files into tasks and construct a FileScanRDD.</span></span><br><span class="line"><span class="comment"> *  - Add any projection or filters that must be evaluated after the scan.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Files are assigned into tasks using the following algorithm:</span></span><br><span class="line"><span class="comment"> *  - If the table is bucketed, group files by bucket id into the correct number of partitions.</span></span><br><span class="line"><span class="comment"> *  - If the table is not bucketed or bucketing is turned off:</span></span><br><span class="line"><span class="comment"> *   - If any file is larger than the threshold, split it into pieces based on that threshold</span></span><br><span class="line"><span class="comment"> *   - Sort the files by decreasing file size.</span></span><br><span class="line"><span class="comment"> *   - Assign the ordered files to buckets using the following algorithm.  If the current partition</span></span><br><span class="line"><span class="comment"> *     is under the threshold with the addition of the next file, add it.  If not, open a new bucket</span></span><br><span class="line"><span class="comment"> *     and add it.  Proceed to the next file.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">FileSourceStrategy</span> <span class="keyword">extends</span> <span class="title">Strategy</span> <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">Seq</span>[<span class="type">SparkPlan</span>] = plan <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">PhysicalOperation</span>(projects, filters,</span><br><span class="line">      l @ <span class="type">LogicalRelation</span>(fsRelation: <span class="type">HadoopFsRelation</span>, _, table)) =&gt;</span><br><span class="line">      <span class="comment">// Filters on this relation fall into four categories based on where we can use them to avoid</span></span><br><span class="line">      <span class="comment">// reading unneeded data:</span></span><br><span class="line">      <span class="comment">//  - partition keys only - used to prune directories to read</span></span><br><span class="line">      <span class="comment">//  - bucket keys only - optionally used to prune files to read</span></span><br><span class="line">      <span class="comment">//  - keys stored in the data only - optionally used to skip groups of data in files</span></span><br><span class="line">      <span class="comment">//  - filters that need to be evaluated again after the scan</span></span><br><span class="line">      <span class="keyword">val</span> filterSet = <span class="type">ExpressionSet</span>(filters)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// The attribute name of predicate could be different than the one in schema in case of</span></span><br><span class="line">      <span class="comment">// case insensitive, we should change them to match the one in schema, so we do not need to</span></span><br><span class="line">      <span class="comment">// worry about case sensitivity anymore.</span></span><br><span class="line">      <span class="keyword">val</span> normalizedFilters = filters.map &#123; e =&gt;</span><br><span class="line">        e transform &#123;</span><br><span class="line">          <span class="keyword">case</span> a: <span class="type">AttributeReference</span> =&gt;</span><br><span class="line">            a.withName(l.output.find(_.semanticEquals(a)).get.name)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> partitionColumns =</span><br><span class="line">        l.resolve(</span><br><span class="line">          fsRelation.partitionSchema, fsRelation.sparkSession.sessionState.analyzer.resolver)</span><br><span class="line">      <span class="keyword">val</span> partitionSet = <span class="type">AttributeSet</span>(partitionColumns)</span><br><span class="line">      <span class="keyword">val</span> partitionKeyFilters =</span><br><span class="line">        <span class="type">ExpressionSet</span>(normalizedFilters.filter(_.references.subsetOf(partitionSet)))</span><br><span class="line">      logInfo(<span class="string">s"Pruning directories with: <span class="subst">$&#123;partitionKeyFilters.mkString(",")&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> dataColumns =</span><br><span class="line">        l.resolve(fsRelation.dataSchema, fsRelation.sparkSession.sessionState.analyzer.resolver)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Partition keys are not available in the statistics of the files.</span></span><br><span class="line">      <span class="keyword">val</span> dataFilters = normalizedFilters.filter(_.references.intersect(partitionSet).isEmpty)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Predicates with both partition keys and attributes need to be evaluated after the scan.</span></span><br><span class="line">      <span class="keyword">val</span> afterScanFilters = filterSet -- partitionKeyFilters.filter(_.references.nonEmpty)</span><br><span class="line">      logInfo(<span class="string">s"Post-Scan Filters: <span class="subst">$&#123;afterScanFilters.mkString(",")&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> filterAttributes = <span class="type">AttributeSet</span>(afterScanFilters)</span><br><span class="line">      <span class="keyword">val</span> requiredExpressions: <span class="type">Seq</span>[<span class="type">NamedExpression</span>] = filterAttributes.toSeq ++ projects</span><br><span class="line">      <span class="keyword">val</span> requiredAttributes = <span class="type">AttributeSet</span>(requiredExpressions)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> readDataColumns =</span><br><span class="line">        dataColumns</span><br><span class="line">          .filter(requiredAttributes.contains)</span><br><span class="line">          .filterNot(partitionColumns.contains)</span><br><span class="line">      <span class="keyword">val</span> outputSchema = readDataColumns.toStructType</span><br><span class="line">      logInfo(<span class="string">s"Output Data Schema: <span class="subst">$&#123;outputSchema.simpleString(5)&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> outputAttributes = readDataColumns ++ partitionColumns</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> scan =</span><br><span class="line">        <span class="type">FileSourceScanExec</span>(</span><br><span class="line">          fsRelation,</span><br><span class="line">          outputAttributes,</span><br><span class="line">          outputSchema,</span><br><span class="line">          partitionKeyFilters.toSeq,</span><br><span class="line">          dataFilters,</span><br><span class="line">          table.map(_.identifier))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> afterScanFilter = afterScanFilters.toSeq.reduceOption(expressions.<span class="type">And</span>)</span><br><span class="line">      <span class="keyword">val</span> withFilter = afterScanFilter.map(execution.<span class="type">FilterExec</span>(_, scan)).getOrElse(scan)</span><br><span class="line">      <span class="keyword">val</span> withProjections = <span class="keyword">if</span> (projects == withFilter.output) &#123;</span><br><span class="line">        withFilter</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        execution.<span class="type">ProjectExec</span>(projects, withFilter)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      withProjections :: <span class="type">Nil</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> _ =&gt; <span class="type">Nil</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<p>  lazy val toRdd: RDD[InternalRow] = executedPlan.execute()</p>
<p>  /**</p>
<ul>
<li>Returns the result of this query as an RDD[InternalRow] by delegating to <code>doExecute</code> after preparations.</li>
<li>Concrete implementations of SparkPlan should override <code>doExecute</code>.<br>*/<br>final def execute(): RDD[InternalRow] = executeQuery {<br>doExecute()<br>}<br>org.apache.spark.sql.execution.WholeStageCodegenExec#doExecute<br>org.apache.spark.sql.execution.WholeStageCodegenExec#doCodeGen<br>org.apache.spark.sql.execution.CodegenSupport#produce<br>org.apache.spark.sql.execution.CodegenSupport#doProduce</li>
</ul>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-19/37558220.jpg" alt=""></p>
<p>SparkPlan : base class for physical operators, The naming convention is that physical operators end with “Exec” suffix, e.g. ProjectExec.<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkPlan</span> <span class="keyword">extends</span> <span class="title">QueryPlan</span>[<span class="type">SparkPlan</span>] <span class="keyword">with</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Execute a query after preparing the query and adding query plan information to created RDDs</span></span><br><span class="line"><span class="comment">   * for visualization.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">executeQuery</span></span>[<span class="type">T</span>](query: =&gt; <span class="type">T</span>): <span class="type">T</span> = &#123;</span><br><span class="line">    <span class="type">RDDOperationScope</span>.withScope(sparkContext, nodeName, <span class="literal">false</span>, <span class="literal">true</span>) &#123;</span><br><span class="line">      prepare()</span><br><span class="line">      waitForSubqueries()</span><br><span class="line">      query</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;  </span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Returns the result of this query as an RDD[InternalRow] by delegating to `doExecute` after</span></span><br><span class="line"><span class="comment">   * preparations.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Concrete implementations of SparkPlan should override `doExecute`.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">execute</span></span>(): <span class="type">RDD</span>[<span class="type">InternalRow</span>] = executeQuery &#123;</span><br><span class="line">    doExecute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Overridden by concrete implementations of SparkPlan.</span></span><br><span class="line"><span class="comment">   * Produces the result of the query as an RDD[InternalRow]</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">doExecute</span></span>(): <span class="type">RDD</span>[<span class="type">InternalRow</span>]</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Prepare a SparkPlan for execution. It's idempotent.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">prepare</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// doPrepare() may depend on it's children, we should call prepare() on all the children first.</span></span><br><span class="line">    children.foreach(_.prepare())</span><br><span class="line">    synchronized &#123;</span><br><span class="line">      <span class="keyword">if</span> (!prepared) &#123;</span><br><span class="line">        prepareSubqueries()</span><br><span class="line">        doPrepare()</span><br><span class="line">        prepared = <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Overridden by concrete implementations of SparkPlan. It is guaranteed to run before any</span></span><br><span class="line"><span class="comment">   * `execute` of SparkPlan. This is helpful if we want to set up some state before executing the</span></span><br><span class="line"><span class="comment">   * query, e.g., `BroadcastHashJoin` uses it to broadcast asynchronously.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note: the prepare method has already walked down the tree, so the implementation doesn't need</span></span><br><span class="line"><span class="comment">   * to call children's prepare methods.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * This will only be called once, protected by `this`.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">doPrepare</span></span>(): <span class="type">Unit</span> = &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>WholeStageCodegenExec(this).execute()</code> 注意这行.`<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSourceScanExec</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    @transient relation: <span class="type">HadoopFsRelation</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    output: <span class="type">Seq</span>[<span class="type">Attribute</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    requiredSchema: <span class="type">StructType</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    partitionFilters: <span class="type">Seq</span>[<span class="type">Expression</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    dataFilters: <span class="type">Seq</span>[<span class="type">Expression</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    override val metastoreTableIdentifier: <span class="type">Option</span>[<span class="type">TableIdentifier</span>]</span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">DataSourceScanExec</span> <span class="keyword">with</span> <span class="title">ColumnarBatchScan</span>  </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doExecute</span></span>(): <span class="type">RDD</span>[<span class="type">InternalRow</span>] = &#123;</span><br><span class="line">    <span class="keyword">if</span> (supportsBatch) &#123;</span><br><span class="line">      <span class="comment">// in the case of fallback, this batched scan should never fail because of:</span></span><br><span class="line">      <span class="comment">// 1) only primitive types are supported</span></span><br><span class="line">      <span class="comment">// 2) the number of columns should be smaller than spark.sql.codegen.maxFields</span></span><br><span class="line">      <span class="type">WholeStageCodegenExec</span>(<span class="keyword">this</span>).execute()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> unsafeRows = &#123;</span><br><span class="line">        <span class="keyword">val</span> scan = inputRDD</span><br><span class="line">        <span class="keyword">if</span> (needsUnsafeRowConversion) &#123;</span><br><span class="line">          scan.mapPartitionsWithIndexInternal &#123; (index, iter) =&gt;</span><br><span class="line">            <span class="keyword">val</span> proj = <span class="type">UnsafeProjection</span>.create(schema)</span><br><span class="line">            proj.initialize(index)</span><br><span class="line">            iter.map(proj)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          scan</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> numOutputRows = longMetric(<span class="string">"numOutputRows"</span>)</span><br><span class="line">      unsafeRows.map &#123; r =&gt;</span><br><span class="line">        numOutputRows += <span class="number">1</span></span><br><span class="line">        r</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">CodegenSupport</span> <span class="keyword">extends</span> <span class="title">SparkPlan</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Returns Java source code to process the rows from input RDD.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">produce</span></span>(ctx: <span class="type">CodegenContext</span>, parent: <span class="type">CodegenSupport</span>): <span class="type">String</span> = executeQuery &#123;</span><br><span class="line">    <span class="keyword">this</span>.parent = parent</span><br><span class="line">    ctx.freshNamePrefix = variablePrefix</span><br><span class="line">    <span class="string">s""</span><span class="string">"</span></span><br><span class="line"><span class="string">       |$&#123;ctx.registerComment(s"</span><span class="type">PRODUCE</span>: $&#123;<span class="keyword">this</span>.simpleString&#125;<span class="string">")&#125;</span></span><br><span class="line"><span class="string">       |$&#123;doProduce(ctx)&#125;</span></span><br><span class="line"><span class="string">     "</span><span class="string">""</span>.stripMargin</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Generate the Java source code to process, should be overridden by subclass to support codegen.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * doProduce() usually generate the framework, for example, aggregation could generate this:</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   *   if (!initialized) &#123;</span></span><br><span class="line"><span class="comment">   *     # create a hash map, then build the aggregation hash map</span></span><br><span class="line"><span class="comment">   *     # call child.produce()</span></span><br><span class="line"><span class="comment">   *     initialized = true;</span></span><br><span class="line"><span class="comment">   *   &#125;</span></span><br><span class="line"><span class="comment">   *   while (hashmap.hasNext()) &#123;</span></span><br><span class="line"><span class="comment">   *     row = hashmap.next();</span></span><br><span class="line"><span class="comment">   *     # build the aggregation results</span></span><br><span class="line"><span class="comment">   *     # create variables for results</span></span><br><span class="line"><span class="comment">   *     # call consume(), which will call parent.doConsume()</span></span><br><span class="line"><span class="comment">   *      if (shouldStop()) return;</span></span><br><span class="line"><span class="comment">   *   &#125;</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">doProduce</span></span>(ctx: <span class="type">CodegenContext</span>): <span class="type">String</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Consume the generated columns or row from current SparkPlan, call its parent's `doConsume()`.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">consume</span></span>(ctx: <span class="type">CodegenContext</span>, outputVars: <span class="type">Seq</span>[<span class="type">ExprCode</span>], row: <span class="type">String</span> = <span class="literal">null</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> inputVars =</span><br><span class="line">      <span class="keyword">if</span> (row != <span class="literal">null</span>) &#123;</span><br><span class="line">        ctx.currentVars = <span class="literal">null</span></span><br><span class="line">        ctx.<span class="type">INPUT_ROW</span> = row</span><br><span class="line">        output.zipWithIndex.map &#123; <span class="keyword">case</span> (attr, i) =&gt;</span><br><span class="line">          <span class="type">BoundReference</span>(i, attr.dataType, attr.nullable).genCode(ctx)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        assert(outputVars != <span class="literal">null</span>)</span><br><span class="line">        assert(outputVars.length == output.length)</span><br><span class="line">        <span class="comment">// outputVars will be used to generate the code for UnsafeRow, so we should copy them</span></span><br><span class="line">        outputVars.map(_.copy())</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> rowVar = <span class="keyword">if</span> (row != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="type">ExprCode</span>(<span class="string">""</span>, <span class="string">"false"</span>, row)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (outputVars.nonEmpty) &#123;</span><br><span class="line">        <span class="keyword">val</span> colExprs = output.zipWithIndex.map &#123; <span class="keyword">case</span> (attr, i) =&gt;</span><br><span class="line">          <span class="type">BoundReference</span>(i, attr.dataType, attr.nullable)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">val</span> evaluateInputs = evaluateVariables(outputVars)</span><br><span class="line">        <span class="comment">// generate the code to create a UnsafeRow</span></span><br><span class="line">        ctx.<span class="type">INPUT_ROW</span> = row</span><br><span class="line">        ctx.currentVars = outputVars</span><br><span class="line">        <span class="keyword">val</span> ev = <span class="type">GenerateUnsafeProjection</span>.createCode(ctx, colExprs, <span class="literal">false</span>)</span><br><span class="line">        <span class="keyword">val</span> code = <span class="string">s""</span><span class="string">"</span></span><br><span class="line"><span class="string">          |$evaluateInputs</span></span><br><span class="line"><span class="string">          |$&#123;ev.code.trim&#125;</span></span><br><span class="line"><span class="string">         "</span><span class="string">""</span>.stripMargin.trim</span><br><span class="line">        <span class="type">ExprCode</span>(code, <span class="string">"false"</span>, ev.value)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// There is no columns</span></span><br><span class="line">        <span class="type">ExprCode</span>(<span class="string">""</span>, <span class="string">"false"</span>, <span class="string">"unsafeRow"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ctx.freshNamePrefix = parent.variablePrefix</span><br><span class="line">    <span class="keyword">val</span> evaluated = evaluateRequiredVariables(output, inputVars, parent.usedInputs)</span><br><span class="line">    <span class="string">s""</span><span class="string">"</span></span><br><span class="line"><span class="string">       |$&#123;ctx.registerComment(s"</span><span class="type">CONSUME</span>: $&#123;parent.simpleString&#125;<span class="string">")&#125;</span></span><br><span class="line"><span class="string">       |$evaluated</span></span><br><span class="line"><span class="string">       |$&#123;parent.doConsume(ctx, inputVars, rowVar)&#125;</span></span><br><span class="line"><span class="string">     "</span><span class="string">""</span>.stripMargin</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Generate the Java source code to process the rows from child SparkPlan.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * This should be override by subclass to support codegen.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * For example, Filter will generate the code like this:</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   *   # code to evaluate the predicate expression, result is isNull1 and value2</span></span><br><span class="line"><span class="comment">   *   if (isNull1 || !value2) continue;</span></span><br><span class="line"><span class="comment">   *   # call consume(), which will call parent.doConsume()</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Note: A plan can either consume the rows as UnsafeRow (row), or a list of variables (input).</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doConsume</span></span>(ctx: <span class="type">CodegenContext</span>, input: <span class="type">Seq</span>[<span class="type">ExprCode</span>], row: <span class="type">ExprCode</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnsupportedOperationException</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * WholeStageCodegen compile a subtree of plans that support codegen together into single Java</span></span><br><span class="line"><span class="comment"> * function.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Here is the call graph of to generate Java source (plan A support codegen, but plan B does not):</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *   WholeStageCodegen       Plan A               FakeInput        Plan B</span></span><br><span class="line"><span class="comment"> * =========================================================================</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * -&gt; execute()</span></span><br><span class="line"><span class="comment"> *     |</span></span><br><span class="line"><span class="comment"> *  doExecute() ---------&gt;   inputRDDs() -------&gt; inputRDDs() ------&gt; execute()</span></span><br><span class="line"><span class="comment"> *     |</span></span><br><span class="line"><span class="comment"> *     +-----------------&gt;   produce()</span></span><br><span class="line"><span class="comment"> *                             |</span></span><br><span class="line"><span class="comment"> *                          doProduce()  -------&gt; produce()</span></span><br><span class="line"><span class="comment"> *                                                   |</span></span><br><span class="line"><span class="comment"> *                                                doProduce()</span></span><br><span class="line"><span class="comment"> *                                                   |</span></span><br><span class="line"><span class="comment"> *                         doConsume() &lt;--------- consume()</span></span><br><span class="line"><span class="comment"> *                             |</span></span><br><span class="line"><span class="comment"> *  doConsume()  &lt;--------  consume()</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * SparkPlan A should override doProduce() and doConsume().</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * doCodeGen() will create a CodeGenContext, which will hold a list of variables for input,</span></span><br><span class="line"><span class="comment"> * used to generated code for BoundReference.</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/07/24/Kylin-执行查询流程分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/24/Kylin-执行查询流程分析/" itemprop="url">Kylin 执行查询流程分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-24T17:10:51+08:00">
                2018-07-24
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/07/24/Kylin-执行查询流程分析/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/07/24/Kylin-执行查询流程分析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/07/24/Kylin-执行查询流程分析/" class="leancloud_visitors" data-flag-title="Kylin 执行查询流程分析">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>转载自:</strong><a href="https://blog.csdn.net/yu616568/article/details/50838504" target="_blank" rel="noopener">Kylin 执行查询流程分析</a></p>
<p>这篇博客应该是目前网上最好的一篇关于 Kylin 查询流程的 blog, 不过年代也有些久远了.</p>
<p>Kylin 基于 MOLAP 实现，查询的时候利用 Calcite 框架，从存储在 Hbase 的 segment 表（每一个 segment 对应着一个 htable）获取数据，其实理论上就相当于使用 Calcite 支持 SQL 解析，数据从 Hbase 中读取，中间 Kylin 主要完成如何确定从 Hbase 中的哪些表读数据，如何读取数据，以及解析数据的格式。</p>
<h2 id="场景设置"><a href="#场景设置" class="headerlink" title="场景设置"></a>场景设置</h2><p>首先设想一种 cube 的场景：</p>
<p>维度：A（cardinality=10）、B（cardinality=20）、C（cardinality=30）、D（cardinality=40），其中 A 为 mandatory 维度，rowkey 顺序为 A、B、C、D，只有一个分组。</p>
<p>度量：COUNT(1), SUM(X)</p>
<p>　　在这种情况下，这个 cube 包含如下的 cuboid：ABCD、ABC、ABD、ACD、AB、AC、AD、A。目前 Kylin 在执行查询的时候只能通过查找 cube 进行匹配，如果能够找到一个匹配的 cube 则读取通过扫描该 cube 的所有 segment 处理该请求，首先先看一下 kylin 是如何处理一个 SQL 查询的。</p>
<h2 id="执行查询"><a href="#执行查询" class="headerlink" title="执行查询"></a>执行查询</h2><p>　　Kylin 提供了两种执行 SQL 查询的方式：jdbc 访问和 http api 的访问，前者的实现实际上是在客户端封装了 http api 请求，然后获取结果再转换成 ResultSet 对象，在执行查询之前 Kylin 服务端会对查询的 SQL 做缓存，尤其是执行时间比较久的查询，缓存是基于 SQL 的内容作为 key，结果作为 value 的，所以重复执行一个查询会很快返回的（这是因为 Kylin 假设数据是只读的，不会被修改）。如果缓存不命中则使用服务器内嵌的 Calcite 创建一个向 Calcite 的 jdbc connection，然后使用 jdbc 的方式获取执行结果，在使用 Calcite 的时候用户只需要给 Calcite 提供数据，Calcite 能够完成其他物理算子的优化和执行，但是对于 Kylin 来说，它深度定制了 Calcite，增加了一些优化的策略，所以总的来说查询可以分成两部分：1、kylin 是如何使用 calcite 完成 SQL 的解析，获取 SQL 的上下文；2、kylin 如何从预计算的数据中获取数据并进行计算的。</p>
<h3 id="使用-Calcite-完成-SQL-解析，获取查询上下文"><a href="#使用-Calcite-完成-SQL-解析，获取查询上下文" class="headerlink" title="使用 Calcite 完成 SQL 解析，获取查询上下文"></a>使用 Calcite 完成 SQL 解析，获取查询上下文</h3><p><img src="http://img.blog.csdn.net/20160309201844038" alt="这里写图片描述 "></p>
<p>　　当在 Calcite 中执行一个 SQL 时，Calcite 会解析得到 AST 树，然后再对逻辑执行计划进行优化，Calcite 的优化规则是基于规则的，在 Calcite 中注册了一些新的 Rule，在优化的过程中会根据这些规则对算子进行转换为对应的物理执行算子，接下来 Calcite 从上到下一次执行这些算子。这些算子都实现了 EnumerableRel 接口，在执行的时候调用 implement 函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public interface EnumerableRel</span><br><span class="line">    extends RelNode &#123;</span><br><span class="line">  /**</span><br><span class="line">   * Creates a plan for this expression according to a calling convention.</span><br><span class="line">   *</span><br><span class="line">   * @param implementor Implementor</span><br><span class="line">   * @param pref Preferred representation for rows in result expression</span><br><span class="line">   * @return Plan for this expression according to a calling convention</span><br><span class="line">   */</span><br><span class="line">  Result implement (EnumerableRelImplementor implementor , Prefer pref);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20160309202202156" alt="这里写图片描述 "></p>
<p>　　在所有 Kylin 优化之后的查询树中，根节点都是 OLAPToEnumerableConverter，在它的 implement 函数中首先根据每一个算子中保持的信息构造本次查询的上下文 OLAPContext，例如根据 OLAPAggregateRel 算子获取 groupByColumns，根据 OLAPFilterRel 算子将每次查询的过滤条件转换成 TupleFilter。然后根据本次查询中使用的维度列（出现在 groupByColumns 和 filterColumns 中）、度量信息（aggregations）查询是否有满足本次查询的 Cube，如果有则将其保存在 OLAPContext 的 realization 中，获取数据时需要依赖于它。然后再 rewrite 回调函数中递归调用每一个算子的 implementRewrite 函数重新构造每一个算子的参数，最后再调用每一个算子的 implementEnumerable 函数将其转换成 EnumerableRel 对象，这一步相当于将上面生成的物理执行计划再次转换生成一个新的物理执行计划。</p>
<p>　　Calcite 会根据这个执行计划动态生成执行代码，其中代码的生成根据每一个算子的 implement 函数构造，并且 Calcite 根据算子之间的依赖关系生成在新生成的类中构造 bind 函数，在 bind 函数中首先会执行 TableScan 获取数据，数据是通过一个 Enumerable 对象返回的，所以 OLAPTableScan 需要负责产生一个该对象获取原始数据，在执行 moveNext 获取下一条记录的时候通过 filter 中指定的条件对原始数据进行过滤，在 current 函数中执行映射返回 select 中指定的列数据，接着对这个 Enumerable 依次执行 groupBy 和 orderBy 函数，将结果返回。本次查询的 statement 会根据 bind 函数返回的 Enumerable 对象构造 ResultSet 对象。</p>
<p>　　上面大致上介绍了 Kylin 利用 Calcite 框架执行查询的流程，Kylin 主要注册了几个优化规则，在每一个优化规则中将对应的物理算子转换成 Kylin 自己的 OLAPxxxRel 算子，然后再将每一个算子根据本次查询的参数生成 Calcite 自身的 EnumerableXXX 算子执行，比较特殊的是 OLAPTableScan 并不会转换成其他的算子，同样的还有 OLAPJoinRel（当执行的 sql 有 JOIN 是会产生该算子），这 OLAPTableScan 算子的 implement 函数实现如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public Result implement(EnumerableRelImplementor implementor, Prefer pref ) &#123;</span><br><span class="line">    PhysType physType = PhysTypeImpl. of(implementor.getTypeFactory(), this.rowType , pref .preferArray());</span><br><span class="line"></span><br><span class="line">    String execFunction = genExecFunc();</span><br><span class="line"></span><br><span class="line">    MethodCallExpression exprCall = Expressions.call(table.getExpression(OLAPTable. class), execFunction , implementor.getRootExpression(), Expressions.constant( context. id));</span><br><span class="line">    return implementor .result(physType , Blocks.toBlock( exprCall));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private String genExecFunc() &#123;</span><br><span class="line">    // if the table to scan is not the fact table of cube, then it&apos;s a lookup table</span><br><span class="line">    if (context .hasJoin == false &amp;&amp; tableName.equalsIgnoreCase(context .realization .getFactTable()) == false) &#123;</span><br><span class="line">        return &quot;executeLookupTableQuery&quot; ;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        return &quot;executeIndexQuery&quot; ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>　　可以看出它根据 MethodCallExpression 对象 exprCall 执行 Blocks.toBlock 生成对应的代码段（在 bind 函数中调用），例如本例中生成的代码段如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">final org.apache.calcite.linq4j.Enumerable _inputEnumerable = ((org.apache.kylin.query.schema.OLAPTable)</span><br><span class="line">     root.getRootSchema().getSubSchema(&quot;databaseName&quot;).getTable(&quot;tableName&quot;)).executeIndexQuery(root, 0);</span><br></pre></td></tr></table></figure>
<p>　　返回的 Enumerable 是由 executeIndexQuery 函数返回的，在 genExecFunc 函数中会判断是根据之前生成的查询上下文 OLAPContext，如果本次查询没有 join 并且查询的表不是当前使用的 Cube 的事实表，则使用 executeLookupTableQuery 函数，否则（有 join 或者查询事实表）则使用 executeIndexQuery 函数。</p>
<p>　　而在 OLAPJoinRel 的 implement 函数的实现则是直接使用 executeIndexQuery 函数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public Result implement(EnumerableRelImplementor implementor, Prefer pref ) &#123;</span><br><span class="line">    PhysType physType = PhysTypeImpl. of(implementor.getTypeFactory(), getRowType(), pref.preferArray());</span><br><span class="line">    RelOptTable factTable = context .firstTableScan .getTable();</span><br><span class="line">    MethodCallExpression exprCall = Expressions.call(factTable.getExpression(OLAPTable. class), &quot;executeIndexQuery&quot; , implementor.getRootExpression(), Expressions.constant( context. id));</span><br><span class="line">    return implementor .result(physType , Blocks.toBlock( exprCall));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>　　为什么是这两个不同的函数呢？这是由于在 Kylin 中预计算了所有可能的组合值保存在 hbase 中，rowkey 为值的组合，例如 A=”abc”,B=”xyz”就对应着一条记录，value 为 select count(1), sum(X) from table where A=”abc” and B=”xyz”的返回值，所以对于事实表中的数据都是需要进行计算的，保存在 hbase 中，只能通过访问 hbase 获取，而 Kylin 会保存所有维度表的信息，在内存中生成 SnapshotTable，这样对维度表的查询则不需要扫描 hbase 了。</p>
<h3 id="Kylin-从-Hbase-中获取数据"><a href="#Kylin-从-Hbase-中获取数据" class="headerlink" title="Kylin 从 Hbase 中获取数据"></a>Kylin 从 Hbase 中获取数据</h3><p>　　上面吧 Calcite 解析和执行部分介绍完了，在 bind 函数中需要返回一个 Enumerable 对象给 Calcite 执行接下来的过滤、Project、groupBy、orderBy、limit 等操作，这里不关注只对维度表的查询，而是看一下 Kylin 如何从 Hbase 中获取数据的。首先这个 Enumerable 对象时 OLAPTable 的 executeIndexQuery 函数返回的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public Enumerable&lt;Object[]&gt; executeIndexQuery(DataContext optiqContext, int ctxSeq) &#123;</span><br><span class="line">    return new OLAPQuery(optiqContext, EnumeratorTypeEnum. INDEX, ctxSeq );</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>　　它的 enumerator 函数如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> public Enumerator&lt;Object[]&gt; enumerator() &#123;</span><br><span class="line">    OLAPContext olapContext = OLAPContext.getThreadLocalContextById( contextId);</span><br><span class="line">    switch (type ) &#123;</span><br><span class="line">    case INDEX :</span><br><span class="line">        return new CubeEnumerator(olapContext, optiqContext);</span><br><span class="line">    case LOOKUP_TABLE :</span><br><span class="line">        return new LookupTableEnumerator(olapContext);</span><br><span class="line">    case HIVE :</span><br><span class="line">        return new HiveEnumerator(olapContext);</span><br><span class="line">    default:</span><br><span class="line">        throw new IllegalArgumentException(&quot;Wrong type &quot; + type + &quot;!&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>　　在 CubeEnumerator 中主要由 current 返回当前的数据，moveNext 查看是否还有数据，它们完成了一个迭代器的功能：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public Object[] current() &#123;</span><br><span class="line">    return current ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public boolean moveNext() &#123;</span><br><span class="line">    if (cursor == null) &#123;</span><br><span class="line">        cursor = queryStorage();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (!cursor .hasNext()) &#123;</span><br><span class="line">        return false ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ITuple tuple = cursor.next();</span><br><span class="line">    if (tuple == null) &#123;</span><br><span class="line">        return false ;</span><br><span class="line">    &#125;</span><br><span class="line">    convertCurrentRow (tuple );</span><br><span class="line">    return true ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>　　queryStorage 函数返回一个迭代器，所有的数据都是通过这个迭代器获得，其中 current 变量是在 covertCurrentRow 函数中根据 hbase 中的数据解码之后的值，为什么需要解码呢？首先 hbase 中存储的都是二进制的数据，然后由于维度的成员的值可能会占用很大的空间，如果存储原始值的话会造成：1、hbase 存储空间增大，2、相同 cuboid 的 rowkey 的长度不一样，所以 Kylin 在构建 Cube 的时候会将每一个维度下的成员进行编码，每一个维度中的每一个成员编码程一个从 0 开始的整数值，存储在 hbase 中的数据是这些编码值的二进制组合，因此读取到这些值之后需要解码获取原始的维度值。</p>
<p>　　querySorage 函数主要执行逻辑：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">IStorageEngine storageEngine = StorageEngineFactory.getStorageEngine( olapContext.realization );</span><br><span class="line">ITupleIterator iterator = storageEngine.search(olapContext .storageContext , olapContext.getSQLDigest());</span><br></pre></td></tr></table></figure>
<p>　　首先根据本次查询选中的 Cube 生成 storageEngine 对象，然后通过 search 方法返回一个迭代器，从其中获取全部数据。CubeStorageEngine 是在 Cube 中获取数据使用的 engine，它的 search 方法执行逻辑如下：</p>
<p><img src="http://img.blog.csdn.net/20160309202741151" alt="这里写图片描述 "></p>
<p>　　由于在线程局部变量中保存了本次查询的 OLAPContext，可以根据它保存的信息获取根据哪些列 group by 和 filter，以及对哪些度量进行计算，此时需要考虑 derived 维度，这种维度实际上会被它所在的维度表的主键代替，所以需要将这些列转换为主键列，并根据 snapshotTable 修改 filter 对象，然后判断本次查询是否需要启动 hbase 的 coprocessor，Kylin 对于每一个 htable 都设置了一个 observer 类型的 coprocessor，当执行 scan 操作之前会回调这个类的 doPostScannerObserver 函数，执行对表中的原始记录执行一些过滤和聚合运算，这样可以减小每一个 scan 返回的记录数，例如执行 select A，count(1) from table where B &gt; 1 and C not in (”) group by A，这样的查询可以根据 B&gt;1 计算出本次查询需要扫描的 rowkey 范围，而 C not in (”) 则需要在 coprocessor 对扫描获得的每一条记录执行判断，如果满足才可以从 hbase 中返回。例如上例中查询出现了 A/B/C 维度，但是这个 cuboid 并没有预计算，此时只能定位到 A/B/C/D 这个 cuboid，在 coprocessor 中需要再根据 D 这一列执行聚合，进一步减小返回记录数。</p>
<h2 id="关于内存"><a href="#关于内存" class="headerlink" title="关于内存"></a>关于内存</h2><ul>
<li><p>1、首先在 coprocessor 中，它是在 hbase 的 regionServer 中执行的，所以不能占用 hbase 太多的内存，Kylin 在这里做的内存限制是 500MB，因为需要执行额外的聚合运算，因此在 coprocessor 中维护了一个 map 保存每一个需要返回的记录并且持续的执行聚合运算，但是如果查询中带有 distinct count 的聚合运算，Kylin 使用 HLL 实现的，每一个聚合值大概占用 32KB 大小（根据精确度），所以如果查询中有这样的聚合函数会很快消耗完这些内存，所以这种聚合的查询不会启动 coprocessor。</p>
</li>
<li><p>2、对于返回的记录，只是原始的数据，需要再交给 calcite 完成下面的聚合、过滤和排序等操作，但是既然 coprocessor 中都已经把过滤和聚合做完了，为什么还要在 coprocessor 中做呢？filter 的确是在 Kylin 中已经完成的了，再使用 Calcite 执行过滤是为了正确性的保证，但是这样也限制的 Kylin 不能支持全部的 Calcite 的过滤（这里可以扩展，Kylin 只处理自己能处理的，剩余由 Calcite 处理），至于还需要聚合运算是因为一个 Cube 查询可能涉及到多个 segment，因此这些 segment 可能返回相同的 key，此时就需要 Calcite 执行聚合运算，运算函数是由 Kylin 指定的，但是需要将所有从 hbase 中返回的记录保存在内存中，Kylin 为每一个查询设置了最大内存内存上线为 3GB，根据每一个 key-value 的大小计算出 hbase 最多返回的记录数，如果超出这个数则根据配置是否接受部分结果，如果不接受则返回查询失败，如果接受则指根据已返回的记录进行 Calcite 的运算，可能出现错误。</p>
</li>
</ul>
<h2 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h2><p>　　将 filter 转换为扁平式的使用 AND 连接 filter，然后每一个 childFilter 可以根据不同的 segment 生成一个 keyRange，这里成为 ColumnKeyRange，每一个 segment 中有多个 ColumnKeyRange，由于每一个 segment 对应着一个 htable，所以首先会尝试 merge 每一个 segment 下的 ColumnKeyRange（根据是否有重合的范围），生成多个 HBaseKeyRange（merge 之后的多个范围，直接对应着 hbase 中 rowkey 的范围），根据这些 HBaseKeyRange 生成 SerializedHBaseTupleIterator。</p>
<p>　　在这个 SerializedHBaseTupleIterator 迭代器中按照每一个 segment 下的 HbaseKeyRange 创建一个 map，segment 为 key，这个 segment 下需要扫面的 HbaseKeyRange 数组作为 value，然后为每一个 Segment 创建一个 CubeSegmentTupleIterator 对象，它中保持了多个 HbaseKeyRange，然后对每一个 HbaseKeyRange 创建 Scan 对象，接着使用该对象向 Hbase 发起一个 scan 请求，上面每一个迭代器都是对它包含的迭代器数组的封装。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>　　本文介绍了 Kylin 如何处理 Sql 的查询，充分利用了 Calcite 的 sql 解析和优化的功能，可以看到 Calcite 是一个非常强大的 SQL 引擎框架，Kylin 较深入的定制了 Calcite 的功能，对于 Calcite 的初级使用可以参考：<a href="http://blog.csdn.net/yu616568/article/details/49915577" title="初识 Calcite——使用实例" target="_blank" rel="noopener">http://blog.csdn.net/yu616568/article/details/49915577</a>，而 Kylin 提供从 Hbase 中读取数据返回前端又有点类似于 phoenix 的做法（它也是通过 Calcite 完成解析和优化的），但是后者更加通用一些。Kylin 2.0 中把存储做成插件式的，理论上可以支持更多的存储组件（需要支持 scan 和类似 coprocessor 的功能啊），但是基本上查询流程是类似的。本文如果有什么错误，还请多多指正，谢谢~</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/07/19/Linux-IO-模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/19/Linux-IO-模型/" itemprop="url">Linux IO 模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-19T20:44:23+08:00">
                2018-07-19
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/07/19/Linux-IO-模型/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/07/19/Linux-IO-模型/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/07/19/Linux-IO-模型/" class="leancloud_visitors" data-flag-title="Linux IO 模型">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/07/19/Elixir/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/19/Elixir/" itemprop="url">Elixir</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-19T20:44:00+08:00">
                2018-07-19
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/07/19/Elixir/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/07/19/Elixir/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/07/19/Elixir/" class="leancloud_visitors" data-flag-title="Elixir">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/07/19/Scala/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/19/Scala/" itemprop="url">Scala</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-19T20:42:38+08:00">
                2018-07-19
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/07/19/Scala/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/07/19/Scala/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/07/19/Scala/" class="leancloud_visitors" data-flag-title="Scala">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://gitee.com/Meldoy/image/raw/master/life/head.jpg"
                alt="Aron" />
            
              <p class="site-author-name" itemprop="name">Aron</p>
              <p class="site-description motion-element" itemprop="description">Kyligence</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Aron</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'xUIDY0rxakumlhKmQqajlnUc-gzGzoHsz',
        appKey: 'lrqs8UwcvY6z1has9clbxJWL',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("mUXETWIxo42z09pHif0vNGo2-gzGzoHsz", "Sv2QHSHPjuj5DVnTOmO5VQIj");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  

</body>
</html>
