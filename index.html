<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Kyligence">
<meta property="og:type" content="website">
<meta property="og:title" content="Jiatao Tao&#39;s blog">
<meta property="og:url" content="https://tttmelody.github.io/index.html">
<meta property="og:site_name" content="Jiatao Tao&#39;s blog">
<meta property="og:description" content="Kyligence">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jiatao Tao&#39;s blog">
<meta name="twitter:description" content="Kyligence">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://tttmelody.github.io/"/>





  <title>Jiatao Tao's blog</title>
  








  
  <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiatao Tao's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/10/22/Spark-Parquet-file-split/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/22/Spark-Parquet-file-split/" itemprop="url">Spark Parquet file split</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-22T20:14:43+08:00">
                2018-10-22
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/22/Spark-Parquet-file-split/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/10/22/Spark-Parquet-file-split/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/10/22/Spark-Parquet-file-split/" class="leancloud_visitors" data-flag-title="Spark Parquet file split">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>先说结论, spark 中, parquet 是 splitable 的, 代码见<code>ParquetFileFormat#isSplitable</code>. 那会不会把数据切碎? 答案是不会, 因为是以 row group 为最小单位切分的</p>
<h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><h4 id="1-按文件大小切块"><a href="#1-按文件大小切块" class="headerlink" title="1.按文件大小切块:"></a>1.按文件大小切块:</h4><p>在 <code>FileSourceScanExec#createNonBucketedReadRDD</code> 中, 如果文件是 splitable 的 , 按照 maxSplitBytes 把文件切分, 最后生成的数量, 就是 RDD partition 的数量.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> maxSplitBytes = <span class="type">Math</span>.min(defaultMaxSplitBytes, <span class="type">Math</span>.max(openCostInBytes, bytesPerCore))</span><br><span class="line">logInfo(<span class="string">s"Planning scan with bin packing, max size: <span class="subst">$maxSplitBytes</span> bytes, "</span> +</span><br><span class="line">      <span class="string">s"open cost is considered as scanning <span class="subst">$openCostInBytes</span> bytes."</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> splitFiles = selectedPartitions.flatMap &#123; partition =&gt;</span><br><span class="line">  partition.files.flatMap &#123; file =&gt;</span><br><span class="line">    <span class="keyword">val</span> blockLocations = getBlockLocations(file)</span><br><span class="line">    <span class="keyword">if</span> (fsRelation.fileFormat.isSplitable(</span><br><span class="line">        fsRelation.sparkSession, fsRelation.options, file.getPath)) &#123;</span><br><span class="line">      (<span class="number">0</span>L until file.getLen by maxSplitBytes).map &#123; offset =&gt;</span><br><span class="line">        <span class="keyword">val</span> remaining = file.getLen - offset</span><br><span class="line">        <span class="keyword">val</span> size = <span class="keyword">if</span> (remaining &gt; maxSplitBytes) maxSplitBytes <span class="keyword">else</span> remaining</span><br><span class="line">        <span class="keyword">val</span> hosts = getBlockHosts(blockLocations, offset, size)</span><br><span class="line">        <span class="type">PartitionedFile</span>(</span><br><span class="line">          partition.values, file.getPath.toUri.toString, offset, size, hosts)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> hosts = getBlockHosts(blockLocations, <span class="number">0</span>, file.getLen)</span><br><span class="line">      <span class="type">Seq</span>(<span class="type">PartitionedFile</span>(</span><br><span class="line">        partition.values, file.getPath.toUri.toString, <span class="number">0</span>, file.getLen, hosts))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;.toArray.sortBy(_.length)(implicitly[<span class="type">Ordering</span>[<span class="type">Long</span>]].reverse)</span><br></pre></td></tr></table></figure>
<h4 id="2-使用-ParquetInputSplit-构造-reader"><a href="#2-使用-ParquetInputSplit-构造-reader" class="headerlink" title="2.使用 ParquetInputSplit 构造 reader:"></a>2.使用 ParquetInputSplit 构造 reader:</h4><h4 id="2-使用-ParquetInputSplit-构造-reader-1"><a href="#2-使用-ParquetInputSplit-构造-reader-1" class="headerlink" title="2.使用 ParquetInputSplit 构造 reader:"></a>2.使用 ParquetInputSplit 构造 reader:</h4><p>在 <code>ParquetFileFormat#buildReaderWithPartitionValues</code> 实现中, 会使用 split 来初始化 reader, 根据配置分是否是 vectorized 的,</p>
<ul>
<li><code>vectorizedReader.initialize(split, hadoopAttemptContext)</code></li>
<li><code>reader.initialize(split, hadoopAttemptContext)</code></li>
</ul>
<p>完整代码如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">(file: <span class="type">PartitionedFile</span>) =&gt; &#123;</span><br><span class="line">  assert(file.partitionValues.numFields == partitionSchema.size)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> fileSplit =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">FileSplit</span>(<span class="keyword">new</span> <span class="type">Path</span>(<span class="keyword">new</span> <span class="type">URI</span>(file.filePath)), file.start, file.length, <span class="type">Array</span>.empty)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> split =</span><br><span class="line">    <span class="keyword">new</span> org.apache.parquet.hadoop.<span class="type">ParquetInputSplit</span>(</span><br><span class="line">      fileSplit.getPath,</span><br><span class="line">      fileSplit.getStart,</span><br><span class="line">      fileSplit.getStart + fileSplit.getLength,</span><br><span class="line">      fileSplit.getLength,</span><br><span class="line">      fileSplit.getLocations,</span><br><span class="line">      <span class="literal">null</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> attemptId = <span class="keyword">new</span> <span class="type">TaskAttemptID</span>(<span class="keyword">new</span> <span class="type">TaskID</span>(<span class="keyword">new</span> <span class="type">JobID</span>(), <span class="type">TaskType</span>.<span class="type">MAP</span>, <span class="number">0</span>), <span class="number">0</span>)</span><br><span class="line">  <span class="keyword">val</span> hadoopAttemptContext =</span><br><span class="line">    <span class="keyword">new</span> <span class="type">TaskAttemptContextImpl</span>(broadcastedHadoopConf.value.value, attemptId)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Try to push down filters when filter push-down is enabled.</span></span><br><span class="line">  <span class="comment">// Notice: This push-down is RowGroups level, not individual records.</span></span><br><span class="line">  <span class="keyword">if</span> (pushed.isDefined) &#123;</span><br><span class="line">    <span class="type">ParquetInputFormat</span>.setFilterPredicate(hadoopAttemptContext.getConfiguration, pushed.get)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">val</span> parquetReader = <span class="keyword">if</span> (enableVectorizedReader) &#123;</span><br><span class="line">    <span class="keyword">val</span> vectorizedReader = <span class="keyword">new</span> <span class="type">VectorizedParquetRecordReader</span>()</span><br><span class="line">    vectorizedReader.initialize(split, hadoopAttemptContext)</span><br><span class="line">    logDebug(<span class="string">s"Appending <span class="subst">$partitionSchema</span> <span class="subst">$&#123;file.partitionValues&#125;</span>"</span>)</span><br><span class="line">    vectorizedReader.initBatch(partitionSchema, file.partitionValues)</span><br><span class="line">    <span class="keyword">if</span> (returningBatch) &#123;</span><br><span class="line">      vectorizedReader.enableReturningBatches()</span><br><span class="line">    &#125;</span><br><span class="line">    vectorizedReader</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    logDebug(<span class="string">s"Falling back to parquet-mr"</span>)</span><br><span class="line">    <span class="comment">// ParquetRecordReader returns UnsafeRow</span></span><br><span class="line">    <span class="keyword">val</span> reader = pushed <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(filter) =&gt;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">ParquetRecordReader</span>[<span class="type">UnsafeRow</span>](</span><br><span class="line">          <span class="keyword">new</span> <span class="type">ParquetReadSupport</span>,</span><br><span class="line">          <span class="type">FilterCompat</span>.get(filter, <span class="literal">null</span>))</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">ParquetRecordReader</span>[<span class="type">UnsafeRow</span>](<span class="keyword">new</span> <span class="type">ParquetReadSupport</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    reader.initialize(split, hadoopAttemptContext)</span><br><span class="line">    reader</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> iter = <span class="keyword">new</span> <span class="type">RecordReaderIterator</span>(parquetReader)</span><br><span class="line">  <span class="type">Option</span>(<span class="type">TaskContext</span>.get()).foreach(_.addTaskCompletionListener(_ =&gt; iter.close()))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// UnsafeRowParquetRecordReader appends the columns internally to avoid another copy.</span></span><br><span class="line">  <span class="keyword">if</span> (parquetReader.isInstanceOf[<span class="type">VectorizedParquetRecordReader</span>] &amp;&amp;</span><br><span class="line">      enableVectorizedReader) &#123;</span><br><span class="line">    iter.asInstanceOf[<span class="type">Iterator</span>[<span class="type">InternalRow</span>]]</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> fullSchema = requiredSchema.toAttributes ++ partitionSchema.toAttributes</span><br><span class="line">    <span class="keyword">val</span> joinedRow = <span class="keyword">new</span> <span class="type">JoinedRow</span>()</span><br><span class="line">    <span class="keyword">val</span> appendPartitionColumns = <span class="type">GenerateUnsafeProjection</span>.generate(fullSchema, fullSchema)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// This is a horrible erasure hack...  if we type the iterator above, then it actually check</span></span><br><span class="line">    <span class="comment">// the type in next() and we get a class cast exception.  If we make that function return</span></span><br><span class="line">    <span class="comment">// Object, then we can defer the cast until later!</span></span><br><span class="line">    <span class="keyword">if</span> (partitionSchema.length == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// There is no partition columns</span></span><br><span class="line">      iter.asInstanceOf[<span class="type">Iterator</span>[<span class="type">InternalRow</span>]]</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      iter.asInstanceOf[<span class="type">Iterator</span>[<span class="type">InternalRow</span>]]</span><br><span class="line">        .map(d =&gt; appendPartitionColumns(joinedRow(d, file.partitionValues)))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>by the way, 这个返回的<code>(PartitionedFile) =&gt; Iterator[InternalRow]</code>, 是在<code>FileSourceScanExec#inputRDD</code>用的<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">lazy</span> <span class="keyword">val</span> inputRDD: <span class="type">RDD</span>[<span class="type">InternalRow</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> readFile: (<span class="type">PartitionedFile</span>) =&gt; <span class="type">Iterator</span>[<span class="type">InternalRow</span>] =</span><br><span class="line">    relation.fileFormat.buildReaderWithPartitionValues(</span><br><span class="line">      sparkSession = relation.sparkSession,</span><br><span class="line">      dataSchema = relation.dataSchema,</span><br><span class="line">      partitionSchema = relation.partitionSchema,</span><br><span class="line">      requiredSchema = requiredSchema,</span><br><span class="line">      filters = pushedDownFilters,</span><br><span class="line">      options = relation.options,</span><br><span class="line">      hadoopConf = relation.sparkSession.sessionState.newHadoopConfWithOptions(relation.options))</span><br><span class="line"></span><br><span class="line">  relation.bucketSpec <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(bucketing) <span class="keyword">if</span> relation.sparkSession.sessionState.conf.bucketingEnabled =&gt;</span><br><span class="line">      createBucketedReadRDD(bucketing, readFile, selectedPartitions, relation)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt;</span><br><span class="line">      createNonBucketedReadRDD(readFile, selectedPartitions, relation)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>FileScanRDD<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FileScanRDD</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    @transient private val sparkSession: <span class="type">SparkSession</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    readFunction: (<span class="type">PartitionedFile</span></span>) <span class="title">=&gt;</span> <span class="title">Iterator</span>[<span class="type">InternalRow</span>],</span></span><br><span class="line"><span class="class">    <span class="title">@transient</span> <span class="title">val</span> <span class="title">filePartitions</span></span>: <span class="type">Seq</span>[<span class="type">FilePartition</span>])</span><br><span class="line">  <span class="keyword">extends</span> <span class="type">RDD</span>[<span class="type">InternalRow</span>](sparkSession.sparkContext, <span class="type">Nil</span>) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">RDDPartition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">InternalRow</span>] = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> files = split.asInstanceOf[<span class="type">FilePartition</span>].files.toIterator</span><br><span class="line">    <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> currentFile: <span class="type">PartitionedFile</span> = <span class="literal">null</span> <span class="comment">// 根据 currentFile = files.next() 来的, 具体实现我就不贴了 有兴趣的可以自己看下.</span></span><br><span class="line">    ...</span><br><span class="line">    readFunction(currentFile)</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="3-根据-row-group-所在位置-filter-没有-row-group-的-partition"><a href="#3-根据-row-group-所在位置-filter-没有-row-group-的-partition" class="headerlink" title="3. 根据 row group 所在位置 filter 没有 row group 的 partition"></a>3. 根据 row group 所在位置 filter 没有 row group 的 partition</h4><p>在 1 中根据文件大小均分了一些 partitions, 但不是所有这些 partitions 最后都会有数据. 在 <code>SpecificParquetRecordReaderBase#initialize</code> 中, 会在 readFooter 的时候传入一个<code>RangeMetadataFilter</code>, 这个 filter 的range 是根据你的 split 的边界来的:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    footer = readFooter(configuration, file, range(inputSplit.getStart(), inputSplit.getEnd()));</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>parquet 的<code>ParquetFileReader#readFooter</code>方法会用到<code>ParquetMetadataConverter#converter.readParquetMetadata(f, filter);</code>, 这个<code>readParquetMetadata</code>对于<code>RangeMetadataFilter</code>的处理是:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> FileMetaData <span class="title">visit</span><span class="params">(RangeMetadataFilter filter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> filterFileMetaDataByMidpoint(readFileMetaData(from), filter);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>终于到了最关键的切分的地方, 最关键的就是这一段, 谁拥有这个 row group的中点, 谁就可以处理这个 row group. </p>
<p>现在假设我们有一个40m 的文件, 只有一个 row group, 10m 一分, 那么将会有4个 partitions, 但是只有一个 partition 会占有这个 row group 的中点, 所以也只有这一个 partition 会有数据.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> midPoint = startIndex + totalSize / <span class="number">2</span>;</span><br><span class="line"><span class="keyword">if</span> (filter.contains(midPoint)) &#123;</span><br><span class="line">  newRowGroups.add(rowGroup);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>完整代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> FileMetaData <span class="title">filterFileMetaDataByMidpoint</span><span class="params">(FileMetaData metaData, RangeMetadataFilter filter)</span> </span>&#123;</span><br><span class="line">  List&lt;RowGroup&gt; rowGroups = metaData.getRow_groups();</span><br><span class="line">  List&lt;RowGroup&gt; newRowGroups = <span class="keyword">new</span> ArrayList&lt;RowGroup&gt;();</span><br><span class="line">  <span class="keyword">for</span> (RowGroup rowGroup : rowGroups) &#123;</span><br><span class="line">    <span class="keyword">long</span> totalSize = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">long</span> startIndex = getOffset(rowGroup.getColumns().get(<span class="number">0</span>));</span><br><span class="line">    <span class="keyword">for</span> (ColumnChunk col : rowGroup.getColumns()) &#123;</span><br><span class="line">      totalSize += col.getMeta_data().getTotal_compressed_size();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">long</span> midPoint = startIndex + totalSize / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (filter.contains(midPoint)) &#123;</span><br><span class="line">      newRowGroups.add(rowGroup);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  metaData.setRow_groups(newRowGroups);</span><br><span class="line">  <span class="keyword">return</span> metaData;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/10/16/Spark-map-vs-mapPartitions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/16/Spark-map-vs-mapPartitions/" itemprop="url">Spark map vs mapPartitions</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-16T10:43:54+08:00">
                2018-10-16
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/16/Spark-map-vs-mapPartitions/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/10/16/Spark-map-vs-mapPartitions/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/10/16/Spark-map-vs-mapPartitions/" class="leancloud_visitors" data-flag-title="Spark map vs mapPartitions">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>官方定义:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return a new RDD by applying a function to all elements of this RDD.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.map(cleanF))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return a new RDD by applying a function to each partition of this RDD.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * `preservesPartitioning` indicates whether the input function preserves the partitioner, which</span></span><br><span class="line"><span class="comment"> * should be `false` unless this is a pair RDD and the input function doesn't modify the keys.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartitions</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    f: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Iterator</span>[<span class="type">U</span>],</span><br><span class="line">    preservesPartitioning: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanedF = sc.clean(f)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>(</span><br><span class="line">    <span class="keyword">this</span>,</span><br><span class="line">    (context: <span class="type">TaskContext</span>, index: <span class="type">Int</span>, iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; cleanedF(iter),</span><br><span class="line">    preservesPartitioning)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到的是 mapPartitions 需要的函数参数传入的是一个 iter, 返回的也是一个 iter, 而 map 仅仅是一个元素.</p>
<p>假设我们有 10k 个元素, 10个 partitions, 数据均匀分布:</p>
<ol>
<li>map:调用10k 次 map 方法</li>
<li>mapPartitions:调用10次 mapPartitions 方法, 每次传入1k个(一个 partition 的数据量)进行计算. 结果先存到 memory 中, 直到可以返回.</li>
<li>flatMap在 单个元素(map)上工作，生成结果是多个元素(mapPartitions)</li>
</ol>
<p>结论:mapPartitions 转换比 map 快，因为它调用你的函数 一次/分区，而不是 一次/元素, 像有一些高开销的 init 的时候, 如数据库连接, 使用 mapPartitions, 每个分区就只需要一次 init.</p>
<p>来看一个使用 mapPartitions 报错的例子, 运行这段代码, 会报 already closed exception, 因为 spark 的计算都是 lazy 的, 下面的 partition.map 到真的触发计算的时候, conn 已经 close 了.解决方法就是 <code>val newPartition = partition.map(...}).toList</code> 触发计算.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> newDF = myDF.mapPartitions(</span><br><span class="line">  partition =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> conn = <span class="keyword">new</span> <span class="type">DbConnection</span></span><br><span class="line">    <span class="keyword">val</span> newPartition = partition.map(record =&gt; &#123; readMatchingFromDB(record, connection) &#125;)</span><br><span class="line">    conn.close()</span><br><span class="line">    newPartition</span><br><span class="line">  &#125;).toDF()</span><br></pre></td></tr></table></figure>
<p>map mapPartitions 对外部引用的更新都没法作用出来: 下面的 flag 还是0.<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> flag = <span class="number">0</span></span><br><span class="line"><span class="keyword">val</span> test = rdd.map &#123;</span><br><span class="line">  row =&gt; flag += <span class="number">1</span></span><br><span class="line">&#125;.collect()</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/10/13/Learning-Scala/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/13/Learning-Scala/" itemprop="url">Learning Scala</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-13T17:22:36+08:00">
                2018-10-13
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/13/Learning-Scala/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/10/13/Learning-Scala/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/10/13/Learning-Scala/" class="leancloud_visitors" data-flag-title="Learning Scala">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h3><p>a Scala array is a mutable sequence of objects that all share the same type. 当然 array 本身是不可变的, 比如 length, 引用, 但是里面的元素可以变.</p>
<p>Scala achieves a conceptual simplicity by treating everything, from arrays to expressions, as objects with methods.</p>
<p>No special case! Moreover, this uniformity does not incur a significant performance cost. The Scala compiler uses Java arrays, primitive types, and native arithmetic where possible in the compiled code.</p>
<p>Scala has fewer special cases than Java. Arrays are simply instances of classes like any other class in Scala. When you apply parentheses surrounding one or more values to a variable, Scala will transform the code into an invocation of a method named apply on that variable. So greetStrings(i) gets transformed into greetStrings.apply(i). Thus accessing an element of an array in Scala is simply a method call like any other. This principle is not restricted to arrays: any application of an object to some arguments in parentheses will be transformed to an apply method call. Of course this will compile only if that type of object actually defines an apply method. So it’s not a special case; it’s a general rule.</p>
<p>greetStrings(0) = “Hello” &lt;=&gt; greetStrings.update(0, “Hello”)</p>
<p>val numNames = Array(“zero”, “one”, “two”) &lt;=&gt; val numNames2 = Array.apply(“zero”, “one”, “two”)</p>
<p>Array companion object. 伴生对象. 定义在 <code>object Array</code> 中的, 静态. 而具体实例的.apply() 是在<code>class Array[T]</code>中的.</p>
<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>Array 是 mutable sequence of objects, List 是 immutable sequence of objects.</p>
<p>init:<code>val l = List(1, 2, 3)`</code></p>
<p>concatenation:<code>list1 ::: list2</code>, <code>List(1, 2) ::: List(3, 4) = List(3, 4).:::(List(1, 2)) = List(1, 2, 3, 4)</code></p>
<p>append to head:<code>1 :: List(2, 3)</code> &lt;=&gt; List(1, 2, 3)</p>
<p>If the method name ends in a colon, the method is invoked on the right operand. <code>1 :: twoThree</code> &lt;=&gt; <code>twoThree.::(1)</code>, <code>1 :: List(2, 3) = List(2, 3).::(1) = List(1, 2, 3)</code></p>
<p>可以看看这个:<code>final case class ::[B](override val head: B, private[scala] var tl: List[B]) extends List[B]</code>: A non empty list characterized by a head and a tail.</p>
<p>Class List does offer an “append” operation, because the time it takes to append to a list grows linearly with the size of the list, whereas prepending with :: takes constant time.</p>
<p>you can use a ListBuffer, a mutable list that does offer an append operation, and when you’re done call toList.</p>
<p><img src="https://aron-blog-1257818292.cos.ap-shanghai.myqcloud.com/11591539421591_.pic_hd.jpg" alt=""></p>
<p><code>def printArgs(args: Array[String]): Unit = { args.foreach(println) }</code> 即使这样也是有副作用的. 改成这样更 functional<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def formatArgs(args: Array[String]) = args.mkString(&quot;\n&quot;)</span><br><span class="line">println(formatArgs(args))</span><br></pre></td></tr></table></figure></p>
<p>If a function isn’t returning any interesting value(Unit), the only way that function can make a difference in the world is through some kind of side effect.</p>
<p>Every useful program is likely to have side effects of some form; otherwise, it wouldn’t be able to provide value to the outside world. 但是尽量减少side effects, 让你的代码更容易的去测试.(void 方法 没法测)</p>
<p><code>val lines = Source.fromFile(args(0)).getLines().toList</code>, getLines()返回一个 iter, toList 的话, 可以想访问几遍元素访问几遍元素, 代价是进入到内存中区.</p>
<h3 id="折叠"><a href="#折叠" class="headerlink" title="折叠"></a>折叠</h3><p>奥义:<strong>op( op( … op(x_1, x_2) …, x_{n-1}), x_n)</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fold</span><br><span class="line">foldLeft</span><br><span class="line">foldRight</span><br><span class="line">reduce</span><br><span class="line">reduceLeft</span><br><span class="line">reduceRight</span><br></pre></td></tr></table></figure>
<h4 id="fold系列"><a href="#fold系列" class="headerlink" title="fold系列"></a>fold系列</h4><p>fold 函数是不讲究折叠顺序的，适合应用在并发计算中；而 foldLeft 和 foldRight 按元素顺序折叠，一个是由左开始，一个是由右开始。</p>
<p><code>scala&gt; List(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).foldLeft(0)(_ + _.toInt)</code>, 也可以<code>foldLeft(0)((a, b) =&gt; a + b.toInt)</code></p>
<p>坑:<code>List(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).fold(0) {_ + _.toInt}</code> 抛错<code>value toInt is not a member of Any</code>, 因为顺序可能变成了:<code>(0 + &quot;2&quot;.toInt) + (&quot;1&quot; + &quot;3&quot;.toInt).toInt</code>, 而期望是:<code>((0 + &quot;1&quot;.toInt) + &quot;2&quot;.toInt) + &quot;3&quot;.toInt</code></p>
<p>foldLeft 和 foldRight 的速写法分别为：/:() 和:()：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(0 /: List(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)) &#123;(sum, elem) =&gt; sum + elem.toInt&#125;</span><br><span class="line">(List(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;) :\ 0) &#123;_.toInt + _&#125;</span><br></pre></td></tr></table></figure>
<h4 id="reduce-系列"><a href="#reduce-系列" class="headerlink" title="reduce 系列"></a>reduce 系列</h4><p><strong>op( op( … op(x_1, x_2) …, x_{n-1}), x_n)</strong></p>
<p>reduce 系列与 fold 系列的区别在于：reduce 的返回值类型必须和列表的元素类型一致或是其父类，而 fold 无这种限制；fold 必须设定折叠初始值，reduce 不需。来看看：</p>
<p><code>List(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).reduceLeft((a, b) =&gt; a.toInt + b.toInt)</code>, 报错:<code>error: type mismatch; found : Int, required: String</code>, 要改成<code>List(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).map(_.toInt).reduceLeft(_ + _)</code></p>
<p>reduce 与 reduceLeft、reduceRight 的区别也类似于 fold 系列。reduce 的折叠结合是无序的，因此 reduce 也可以用于并行计算。可以把 reduce 当成 fold 的一个特殊版。</p>
<p>看下官方的说法:reduceLeft:Applies a binary operator to all elements of this $coll, going left to right. <code>op( op( ... op(x_1, x_2) ..., x_{n-1}), x_n)</code></p>
<h3 id="Classes-and-Objects"><a href="#Classes-and-Objects" class="headerlink" title="Classes and Objects"></a>Classes and Objects</h3><p>scala 里默认的 access level 是 public</p>
<p>方法的 args 都是 val 的.</p>
<p>不显示的用 return, This philosophy will encourage you to make methods quite small, 减少 multi return.</p>
<p>A method that is executed only for its side effects is known as a procedure.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">x</span><br><span class="line">+ y</span><br><span class="line"></span><br><span class="line">会被认为是两个 statement, 可以这样写</span><br><span class="line"></span><br><span class="line">(x</span><br><span class="line">+ y)</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">x +</span><br><span class="line">y</span><br><span class="line"></span><br><span class="line">it is a common <span class="type">Scala</span> style to put the operators at the end of the line instead of the beginning:</span><br></pre></td></tr></table></figure>
<h4 id="THE-RULES-OF-SEMICOLON-INFERENCE"><a href="#THE-RULES-OF-SEMICOLON-INFERENCE" class="headerlink" title="THE RULES OF SEMICOLON INFERENCE"></a>THE RULES OF SEMICOLON INFERENCE</h4><p>In short, a line ending is treated as a semicolon unless one of the following conditions is true:</p>
<ol>
<li>The line in question ends in a word that would not be legal as the end of a statement, such as a period or an infix operator.</li>
<li>The next line begins with a word that cannot start a statement.</li>
<li>The line ends while inside parentheses (…) or brackets […], because these cannot contain multiple statements anyway.</li>
</ol>
<h4 id="SINGLETON-OBJECTS"><a href="#SINGLETON-OBJECTS" class="headerlink" title="SINGLETON OBJECTS"></a>SINGLETON OBJECTS</h4><p>Scala 不能有静态成员变量. 但是Scala has singleton objects.</p>
<p>When a singleton object shares the same name with a class, it is called that class’s companion object.</p>
<p>You must define both the class and its companion object in the same source file.</p>
<p>In particular, a singleton object is initialized the first time some code accesses it.</p>
<p>A singleton object that does not share the same name with a companion class is called a standalone object.</p>
<h3 id="Depp-in-inherit"><a href="#Depp-in-inherit" class="headerlink" title="Depp in inherit"></a>Depp in inherit</h3><p><strong>Point</strong></p>
<p>A method is abstract if it does not have an implementation (i.e., no equals sign or body). 不用显示写明是 abstract.</p>
<p>use a parameterless method whenever there are no parameters and the method accesses mutable state only by reading fields of the containing object (in particular, it does not change mutable state). This convention supports the uniform access principle,[1] which says that client code should not be affected by a decision to implement an attribute as a field or method.</p>
<p>使用 method 省内存, 使用 filed 会快, 因为类初始化的时候就算好了, and that usage profile might change over time. The point is that clients of theElement class should not be affected when its internal implementation changes.</p>
<p>Element should not need to be rewritten if a field of that class gets changed into an access function, so long as the access function is pure (i.e., it does not have any side effects and does not depend on mutable state). The client should not need to care either way.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">abstract class Element &#123;</span><br><span class="line">  def contents: Array[String]</span><br><span class="line"></span><br><span class="line">  def height: Int = contents.length</span><br><span class="line">  def width: Int = if (height == 0) 0 else contents(0).length</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">abstract class Element &#123;</span><br><span class="line">  def contents: Array[String]</span><br><span class="line"></span><br><span class="line">  val height = contents.length</span><br><span class="line">  val width = if (height == 0) 0 else contents(0).length</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>You can also leave off the empty parentheses on an invocation of any function that takes no arguments.</p>
<p><strong>On the other hand, you should never define a method that has side-effects without parentheses, because invocations of that method would then look like a field selection.</strong></p>
<h4 id="OVERRIDING-METHODS-AND-FIELDS"><a href="#OVERRIDING-METHODS-AND-FIELDS" class="headerlink" title="OVERRIDING METHODS AND FIELDS"></a>OVERRIDING METHODS AND FIELDS</h4><p>This makes it possible for a field to override a parameterless method.(parameterless method 在子类里可以用 field 来 override)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">class ArrayElement(conts: Array[String]) extends Element &#123; </span><br><span class="line">  val contents: Array[String] = conts </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Scala it is forbidden to define a field and method with the same name in the same class</p>
<h4 id="INVOKING-SUPERCLASS-CONSTRUCTORS"><a href="#INVOKING-SUPERCLASS-CONSTRUCTORS" class="headerlink" title="INVOKING SUPERCLASS CONSTRUCTORS"></a>INVOKING SUPERCLASS CONSTRUCTORS</h4><p><code>class LineElement(s: String) extends ArrayElement(Array(s))</code> 尼玛 这写法略丑啊…</p>
<p>if you add new members to base classes (which we usually call superclasses) in a class hierarchy, you risk breaking client code.</p>
<p>组合优于继承, 继承 suffers from the fragile base class problem, base class 会 break client 代码. 使用继承的时候 常常问 is a. 然后client代码里子类有被转成父类的需要吗.</p>
<p>If one of the two operand arrays is longer than the other, zip will drop the remaining elements, <code>Array(1, 2, 3) zip Array(&quot;a&quot;, &quot;b&quot;)</code> &lt;=&gt; <code>Array((1, &quot;a&quot;), (2, &quot;b&quot;))</code></p>
<p>当你的循环结束，将会返回被 yield 的值的一个集合。集合的类型和被迭代的集合类型一样，如果迭代的是 list，返回 list, 如果是 map 就返回 map<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; for (i &lt;- 1 to 5) yield &#123;println(i); i * 3&#125;</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">res1: scala.collection.immutable.IndexedSeq[Int] = Vector(3, 6, 9, 12, 15)</span><br></pre></td></tr></table></figure></p>
<h3 id="Type-Parameterization"><a href="#Type-Parameterization" class="headerlink" title="Type Parameterization"></a>Type Parameterization</h3><h4 id="协变-逆变-variance-annotations"><a href="#协变-逆变-variance-annotations" class="headerlink" title="协变/逆变 (variance annotations)"></a>协变/逆变 (variance annotations)</h4><p>S 是 T 的子类, 那么 Queue[S] 是 Queue[T] 的子类吗, 如果是, 你可以说 Queue 是协变的(covariant). 这样一个方法的参数是Queue[AnyRef], 你可以传入任何Queue[…].</p>
<p>scala 默认是 nonvariant/rigid subtyping. </p>
<p><code>trait Queue[+T] { ... }</code> 定义成这样是协变(covariant)</p>
<p><code>trait Queue[-T] { ... }</code> 定义成这样是逆变(contravariant)</p>
<p>逆变是如果 T 是 S 的子类, Queue[S] 是 Queue[T] 的子类</p>
<p>在 java 中, 数组被当成 covariant 对待. covariant 会有这种问题, 编译可以过, 但是运行出错, 有了泛型后, array 的 covariant 不再 necessary:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String[] a1 = &#123; <span class="string">"abc"</span> &#125;; </span><br><span class="line">Object[] a2 = a1; </span><br><span class="line">a2[<span class="number">0</span>] = <span class="keyword">new</span> Integer(<span class="number">17</span>); </span><br><span class="line">String s = a1[<span class="number">0</span>];</span><br></pre></td></tr></table></figure>
<p>Scala 不会把数组当做可以 covariant 的.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val a1 = Array(<span class="string">"abc"</span>)</span><br><span class="line">scala&gt; val a2: Array[Any] = a1 </span><br><span class="line">&lt;console&gt;:<span class="number">8</span>: error: type mismatch; </span><br><span class="line">  found : Array[String] </span><br><span class="line">  required: Array[Any] </span><br><span class="line">        val a2: Array[Any] = a1</span><br></pre></td></tr></table></figure></p>
<p>如果要用, 要这样用:<code>scala&gt; val a2: Array[Object] = a1.asInstanceOf[Array[Object]]</code></p>
<p>对于纯函数式的语言来说, 协变可能是自然的, 但是只要的你参数是泛型, 都有可能有上面的问题:<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StrangeIntQueue</span> <span class="keyword">extends</span> <span class="title">Queue</span>[<span class="type">Int</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">enqueue</span></span>(x: <span class="type">Int</span>) = &#123;</span><br><span class="line">    println(math.sqrt(x))</span><br><span class="line">    <span class="keyword">super</span>.enqueue(x)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> x: <span class="type">Queue</span>[<span class="type">Any</span>] = <span class="keyword">new</span> <span class="type">StrangeIntQueue</span> </span><br><span class="line">x.enqueue(<span class="string">"abc"</span>)</span><br></pre></td></tr></table></figure></p>
<p>用 + 注解的类型不允许作用于作为 方法参数 的类型, 像 setter 方法:<code>def x_=(y:T)</code> 这个 T 类型不能是协变的</p>
<h4 id="LOWER-BOUNDS"><a href="#LOWER-BOUNDS" class="headerlink" title="LOWER BOUNDS"></a>LOWER BOUNDS</h4><p><code>U &gt;: T</code> 定义了 U 的下界为 T. 这样 U 必须是 T 的超类型. 可以用这种方式绕过上面说的 方法参数的类型不能是协变的<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Queue</span>[+<span class="type">T</span>](<span class="params">private val leading: <span class="type">List</span>[<span class="type">T</span>], private val trailing: <span class="type">List</span>[<span class="type">T</span>]</span>) </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">enqueue</span></span>[<span class="type">U</span> &gt;: <span class="type">T</span>](x: <span class="type">U</span>) = <span class="keyword">new</span> <span class="type">Queue</span>[<span class="type">U</span>](leading, x :: trailing)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>假设我们有 Fruit 类和两个子类: Apple 和 Orange. 可以对Queue[Apple] 追加一个 Orange, 其结果是一个 Queue[Fruit]</p>
<p>超类型和子类型的关系是反身(reflexive)的, 一个类型同时是自己的超类型和子类型, 所以上面我们仍可以把一个 T 传入 enqueue.</p>
<h4 id="逆变"><a href="#逆变" class="headerlink" title="逆变"></a>逆变</h4><p>里氏代换原则:在任何需要类型 U 的值的地方, 都可以用 T 的值替换. 那么就可以安全的假定类型 T 是类型 U 的子类型.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Function1</span>[-<span class="type">S</span>, +<span class="type">T</span>] </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(x: <span class="type">S</span>): <span class="type">T</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/10/06/Druid-Storage-原理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/06/Druid-Storage-原理/" itemprop="url">Druid Storage 原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-06T20:49:18+08:00">
                2018-10-06
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/06/Druid-Storage-原理/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/10/06/Druid-Storage-原理/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/10/06/Druid-Storage-原理/" class="leancloud_visitors" data-flag-title="Druid Storage 原理">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转载自<a href="https://blog.bcmeng.com/post/druid-storage.html" target="_blank" rel="noopener">编程小梦</a>, 该博主一系列文章质量都非常高</p>
<h3 id="What-is-Druid"><a href="#What-is-Druid" class="headerlink" title="What is Druid"></a>What is Druid</h3><p>Druid 是一个开源的实时 OLAP 系统，可以对超大规模数据提供亚秒级查询，其具有以下特点：</p>
<ol>
<li>列式存储</li>
<li>倒排索引 （基于 Bitmap 实现）</li>
<li>分布式的 Shared-Nothing 架构 （高可用，易扩展是 Druid 的设计目标）</li>
<li>实时摄入 （数据被 Druid 实时摄入后便可以立即查询）</li>
</ol>
<h3 id="Why-Druid"><a href="#Why-Druid" class="headerlink" title="Why Druid"></a>Why Druid</h3><p>为了能够提取利用大数据的商业价值，我们必然需要对数据进行分析，尤其是多维分析， 但是在几年前，整个业界并没有一款很好的 OLAP 工具，各种多维分析的方式如下图所示：</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-10-6/55283969.jpg" alt="屏幕快照 2017-10-31 下午8.27.50.png-1080.8kB"></p>
<p>其中直接基于 Hive，MR，Spark 的方式查询速度一般十分慢，并发低；而传统的关系型数据库无法支撑大规模数据；以 HBase 为代表的 NoSQL 数据库也无法提供高效的过滤，聚合能力。正因为现有工具有着各种各样的痛点，Druid 应运而生，以下几点自然是其设计目标：</p>
<ol>
<li>快速查询</li>
<li>可以支撑大规模数据集</li>
<li>高效的过滤和聚合</li>
<li>实时摄入</li>
</ol>
<h3 id="Druid-架构"><a href="#Druid-架构" class="headerlink" title="Druid 架构"></a>Druid 架构</h3><p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-10-6/98456054.jpg" alt="image.png-181kB"></p>
<p>Druid 的整体架构如上图所示，其中主要有 3 条路线：</p>
<ol>
<li><p>实时摄入的过程： 实时数据会首先按行摄入 Real-time Nodes，Real-time Nodes 会先将每行的数据加入到 1 个 map 中，等达到一定的行数或者大小限制时，Real-time Nodes 就会将内存中的 map 持久化到磁盘中，Real-time Nodes 会按照 segmentGranularity 将一定时间段内的小文件 merge 为一个大文件，生成 Segment，然后将 Segment 上传到 Deep Storage（HDFS，S3）中，Coordinator 知道有 Segment 生成后，会通知相应的 Historical Node 下载对应的 Segment，并负责该 Segment 的查询。</p>
</li>
<li><p>离线摄入的过程： 离线摄入的过程比较简单，就是直接通过 MR job 生成 Segment，剩下的逻辑和实时摄入相同：</p>
</li>
<li><p>用户查询过程： 用户的查询都是直接发送到 Broker Node，Broker Node 会将查询分发到 Real-time 节点和 Historical 节点，然后将结果合并后返回给用户。</p>
</li>
</ol>
<p>各节点的主要职责如下：</p>
<h4 id="Historical-Nodes"><a href="#Historical-Nodes" class="headerlink" title="Historical Nodes"></a>Historical Nodes</h4><p>Historical 节点是整个 Druid 集群的骨干，主要负责加载不可变的 segment，并负责 Segment 的查询（注意，Segment 必须加载到 Historical 的内存中才可以提供查询）。Historical 节点是无状态的，所以可以轻易的横向扩展和快速恢复。Historical 节点 load 和 un-load segment 是依赖 ZK 的，但是即使 ZK 挂掉，Historical 依然可以对已经加载的 Segment 提供查询，只是不能再 load 新 segment，drop 旧 segment。</p>
<h4 id="Broker-Nodes"><a href="#Broker-Nodes" class="headerlink" title="Broker Nodes"></a>Broker Nodes</h4><p>Broker 节点是 Druid 查询的入口，主要负责查询的分发和 Merge。 之外，Broker 还会对不可变的 Segment 的查询结果进行 LRU 缓存。</p>
<h4 id="Coordinator-Nodes"><a href="#Coordinator-Nodes" class="headerlink" title="Coordinator Nodes"></a>Coordinator Nodes</h4><p>Coordinator 节点主要负责 Segment 的管理。Coordinator 节点会通知 Historical 节点加载新 Segment，删除旧 Segment，复制 Segment，以及 Segment 间的复杂均衡。</p>
<p>Coordinator 节点依赖 ZK 确定 Historical 的存活和集群 Segment 的分布。</p>
<h4 id="Real-time-Node"><a href="#Real-time-Node" class="headerlink" title="Real-time Node"></a>Real-time Node</h4><p>实时节点主要负责数据的实时摄入，实时数据的查询，将实时数据转为 Segment，将 Segment Hand off 给 Historical 节点。</p>
<h4 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h4><p>Druid 依赖 ZK 实现服务发现，数据拓扑的感知，以及 Coordinator 的选主。</p>
<h4 id="Metadata-Storage"><a href="#Metadata-Storage" class="headerlink" title="Metadata Storage"></a>Metadata Storage</h4><p>Metadata storage（Mysql） 主要用来存储 Segment 和配置的元数据。当有新 Segment 生成时，就会将 Segment 的元信息写入 metadata store, Coordinator 节点会监控 Metadata store 从而知道何时 load 新 Segment，何时 drop 旧 Segment。注意，查询时不会涉及 Metadata store。</p>
<h4 id="Deep-Storage"><a href="#Deep-Storage" class="headerlink" title="Deep Storage"></a>Deep Storage</h4><p>Deep storage (S3 and HDFS) 是作为 Segment 的永久备份，查询时同样不会涉及 Deep storage。</p>
<h3 id="Column"><a href="#Column" class="headerlink" title="Column"></a>Column</h3><p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-10-6/34009295.jpg" alt="屏幕快照 2017-10-27 下午3.45.05.png-278kB"></p>
<p>Druid 中的列主要分为 3 类：时间列，维度列，指标列。Druid 在数据摄入和查询时都依赖时间列，这也是合理的，因为多维分析一般都带有时间维度。维度和指标是 OLAP 系统中常见的概念，维度主要是事件的属性，在查询时一般用来 filtering 和 group by，指标是用来聚合和计算的，一般是数值类型，像 count,sum，min，max 等。</p>
<p>Druid 中的维度列支持 String，Long，Float，不过只有 String 类型支持倒排索引；指标列支持 Long，Float，Complex， 其中 Complex 指标包含 HyperUnique，Cardinality，Histogram，Sketch 等复杂指标。强类型的好处是可以更好的对每 1 列进行编码和压缩， 也可以保证数据索引的高效性和查询性能。</p>
<h3 id="Segment"><a href="#Segment" class="headerlink" title="Segment"></a>Segment</h3><p>前面提到过，Druid 中会按时间段生成不可变的带倒排索引的列式文件，这个文件就称之为 Segment，Segment 是 Druid 中数据存储、复制、均衡、以及计算的基本单元， Segment 由 dataSource_beginTime_endTime_version_shardNumber 唯一标识，1 个 segment 一般包含 5–10 million 行记录，大小一般在 300~700mb。</p>
<h3 id="Segment-的存储格式"><a href="#Segment-的存储格式" class="headerlink" title="Segment 的存储格式"></a>Segment 的存储格式</h3><p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-10-6/29577015.jpg" alt="image.png-90kB">Druid segment 的存储格式如上图所示，包含 3 部分：</p>
<ul>
<li>version 文件</li>
<li>meta 文件</li>
<li>数据文件</li>
</ul>
<p>其中 meta 文件主要包含每 1 列的文件名和文件的偏移量。（注，druid 为了减少文件描述符，将 1 个 segment 的所有列都合并到 1 个大的 smoosh 中，由于 druid 访问 segment 文件的时候采用 MMap 的方式，所以单个 smoosh 文件的大小不能超过 2G，如果超过 2G，就会写到下一个 smoosh 文件）。</p>
<p>在 smoosh 文件中，数据是按列存储中，包含时间列，维度列和指标列，其中每 1 列会包含 2 部分：ColumnDescriptor 和 binary 数据。其中 ColumnDescriptor 主要保存每 1 列的数据类型和 Serde 的方式。</p>
<p>smoosh 文件中还有 index.drd 文件和 metadata.drd 文件，其中 index.drd 主要包含该 segment 有哪些列，哪些维度，该 Segment 的时间范围以及使用哪种 bitmap；metadata.drd 主要包含是否需要聚合，指标的聚合函数，查询粒度，时间戳字段的配置等。</p>
<h3 id="指标列的存储格式"><a href="#指标列的存储格式" class="headerlink" title="指标列的存储格式"></a>指标列的存储格式</h3><p>我们先来看指标列的存储格式：</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-10-6/8107893.jpg" alt="image.png-35.9kB"></p>
<p>指标列的存储格式如上图所示：</p>
<ul>
<li>version</li>
<li>value 个数</li>
<li>每个 block 的 value 的个数（druid 对 Long 和 Float 类型会按 block 进行压缩，block 的大小是 64K）</li>
<li>压缩类型 （druid 目前主要有 LZ4 和 LZF 俩种压缩算法）</li>
<li>编码类型 （druid 对 Long 类型支持差分编码和 Table 编码两种方式，Table 编码就是将 long 值映射到 int，当指标列的基数小于 256 时，druid 会选择 Table 编码，否则会选择差分编码）</li>
<li>编码的 header （以差分编码为例，header 中会记录版本号，base value，每个 value 用几个 bit 表示）</li>
<li>每个 block 的 header （主要记录版本号，是否允许反向查找，value 的数量，列名长度和列名）</li>
<li>每 1 列具体的值</li>
</ul>
<h4 id="Long-型指标"><a href="#Long-型指标" class="headerlink" title="Long 型指标"></a>Long 型指标</h4><p>Druid 中对 Long 型指标会先进行编码，然后按 block 进行压缩。编码算法包含差分编码和 table 编码，压缩算法包含 LZ4 和 LZF。</p>
<h4 id="Float-型指标"><a href="#Float-型指标" class="headerlink" title="Float 型指标"></a>Float 型指标</h4><p>Druid 对于 Float 类型的指标不会进行编码，只会按 block 进行压缩。</p>
<h4 id="Complex-型指标"><a href="#Complex-型指标" class="headerlink" title="Complex 型指标"></a>Complex 型指标</h4><p>Druid 对于 HyperUnique，Cardinality，Histogram，Sketch 等复杂指标不会进行编码和压缩处理，每种复杂指标的 Serde 方式由每种指标自己的 ComplexMetricSerde 实现类实现。</p>
<h3 id="String-维度的存储格式"><a href="#String-维度的存储格式" class="headerlink" title="String 维度的存储格式"></a>String 维度的存储格式</h3><p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-10-6/79137485.jpg" alt="image.png-81.2kB"></p>
<p>String 维度的存储格式如上图所示，前面提到过，时间列，维度列，指标列由两部分组成：ColumnDescriptor 和 binary 数据。 String 维度的 binary 数据主要由 3 部分组成：dict，字典编码后的 id 数组，用于倒排索引的 bitmap。</p>
<p>以上图中的 D2 维度列为例，总共有 4 行，前 3 行的值是 meituan，第 4 行的值是 dianing。Druid 中 dict 的实现十分简单，就是一个 hashmap。图中 dict 的内容就是将 meituan 编码为 0，dianping 编码为 1。 Id 数组的内容就是用编码后的 ID 替换掉原始值，所以就是 [1,1,1,0]。第 3 部分的倒排索引就是用 bitmap 表示某个值是否出现在某行中，如果出现了，bitmap 对应的位置就会置为 1，如图：meituan 在前 3 行中都有出现，所以倒排索引 1：[1,1,1,0] 就表示 meituan 在前 3 行中出现。</p>
<p>显然，倒排索引的大小是列的基数 * 总的行数，如果没有处理的话结果必然会很大。不过好在如果维度列如果基数很高的话，bitmap 就会比较稀疏，而稀疏的 bitmap 可以进行高效的压缩。</p>
<h3 id="Segment-生成过程"><a href="#Segment-生成过程" class="headerlink" title="Segment 生成过程"></a>Segment 生成过程</h3><ol>
<li>Add Row to Map</li>
<li>Begin persist to disk</li>
<li>Write version file</li>
<li>Merge and write dimension dict</li>
<li>Write time column</li>
<li>Write metric column</li>
<li>Write dimension column</li>
<li>Write index.drd</li>
<li>Merge and write bitmaps</li>
<li>Write metadata.drd</li>
</ol>
<h3 id="Segment-load-过程"><a href="#Segment-load-过程" class="headerlink" title="Segment load 过程"></a>Segment load 过程</h3><p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-10-6/34569900.jpg" alt="meta.png-44.3kB"></p>
<ol>
<li>Read version</li>
<li>Load segment to MappedByteBuffer</li>
<li>Get column offset from meta</li>
<li>Deserialize each column from ByteBuffer</li>
</ol>
<h3 id="Segment-Query-过程"><a href="#Segment-Query-过程" class="headerlink" title="Segment Query 过程"></a>Segment Query 过程</h3><p>Druid 查询的最小单位是 Segment，Segment 在查询之前必须先 load 到内存，load 过程如上一步所述。如果没有索引的话，我们的查询过程就只能 Scan 的，遇到符合条件的行选择出来，但是所有查询都进行全表 Scan 肯定是不可行的，所以我们需要索引来快速过滤不需要的行。Druid 的 Segmenet 查询过程如下：</p>
<ol>
<li>构造 1 个 Cursor 进行迭代</li>
<li>查询之前构造出 Fliter</li>
<li>根据 Index 匹配 Fliter，得到满足条件的 Row 的 Offset</li>
<li>根据每列的 ColumnSelector 去指定 Row 读取需要的列。</li>
</ol>
<h3 id="Druid-的编码和压缩"><a href="#Druid-的编码和压缩" class="headerlink" title="Druid 的编码和压缩"></a>Druid 的编码和压缩</h3><p>前面已经提到了，Druid 对 Long 型的指标进行了差分编码和 Table 编码，Long 型和 Float 型的指标进行了 LZ4 或者 LZF 压缩。</p>
<p>其实编码和压缩本质上是一个东西，一切熵增的编码都是压缩。 在计算机领域，我们一般把针对特定类型的编码称之为编码，针对任意类型的通用编码称之为压缩。</p>
<p>编码和压缩的本质就是让每一个 bit 尽可能带有更多的信息。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/10/01/Druid-入门-benchmark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/01/Druid-入门-benchmark/" itemprop="url">Druid 入门&benchmark</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-01T10:36:00+08:00">
                2018-10-01
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/01/Druid-入门-benchmark/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/10/01/Druid-入门-benchmark/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/10/01/Druid-入门-benchmark/" class="leancloud_visitors" data-flag-title="Druid 入门&benchmark">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>coordinator:管理集群状态, 8081<br>broker:查询节点, 8082<br>historical:历史节点, 管理历史数据, 8083<br>overlord: 统治节点, 管理数据写入, 8090<br>middleManager: 中间管理者, 负责写数据<br>pivot: ui, 9095</p>
<p>可以分为三种节点:</p>
<ol>
<li>Master, 包含 overlord 和 coordinator, 负责数据写入和容错.</li>
<li>Data, 数据节点, 包含 historical, middleManager, 负责数据写入和历史数据加载</li>
<li>Query, broker, 查询数据.</li>
</ol>
<p>1,3尽量选多核大内存, 2选磁盘大的机子. 机子资源少时, 可以把 master 和 query 放到一起, 在家 historical 加速热点数据查询.</p>
<hr>
<p>overloard:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">-server</span><br><span class="line">-Xms4g</span><br><span class="line">-Xmx4g</span><br><span class="line">-XX:NewSize=256m</span><br><span class="line">-XX:MaxNewSize=256m</span><br><span class="line">-XX:+UserConcMarkSweepGC</span><br><span class="line">-XX:+PrintGCDetails</span><br><span class="line">-XX:+PrintGCTimeStamps</span><br><span class="line">-Duser.timezone=UTC+0800</span><br><span class="line">-Dfile.encoding=UTF-8</span><br><span class="line">-Djava.io.tmpdir=var/tmp</span><br><span class="line">-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br><span class="line"></span><br><span class="line">druid.service=druid/overlord</span><br><span class="line">druid.host=10.1.30.101</span><br><span class="line">druid.port=8090</span><br><span class="line">druid.indexer.queue.startDelay=PT30S</span><br><span class="line">druid.indexer.runner.type=remote</span><br><span class="line">druid.indexer.storage.type=metadata</span><br></pre></td></tr></table></figure></p>
<p>broker<br>有个 query cache 的 要注意.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"> 1 -server</span><br><span class="line"> 2 -Xms24g</span><br><span class="line"> 3 -Xmx24g</span><br><span class="line"> 4 -XX:NewSize=6g</span><br><span class="line"> 5 -XX:MaxNewSize=6g</span><br><span class="line"> 6 -XX:MaxDirectMemorySize=32g</span><br><span class="line"> 7 -XX:+UserConcMarkSweepGC</span><br><span class="line"> 8 -XX:+PrintGCDetails</span><br><span class="line"> 9 -XX:+PrintGCTimeStamps</span><br><span class="line">10 -Duser.timezone=UTC+0800</span><br><span class="line">11 -Dfile.encoding=UTF-8</span><br><span class="line">12 -Djava.io.tmpdir=var/tmp</span><br><span class="line">13 -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br><span class="line"></span><br><span class="line"> 1 druid.service=druid/broker</span><br><span class="line"> 2 druid.host=10.1.30.102</span><br><span class="line"> 3 druid.port=8082</span><br><span class="line"> 4</span><br><span class="line"> 5 # HTTP server threads</span><br><span class="line"> 6 druid.broker.http.numConnections=20</span><br><span class="line"> 7 druid.broker.http.readTimeout=PT5M</span><br><span class="line"> 8 druid.server.http.numThreads=50</span><br><span class="line"> 9</span><br><span class="line">10 # Processing threads and buffers</span><br><span class="line">11 druid.processing.buffer.sizeBytes=2147483647</span><br><span class="line">12 druid.processing.numMergeBuffers=2</span><br><span class="line">13 druid.processing.numThreads=15</span><br><span class="line">14 druid.processing.tmpDir=var/druid/processing</span><br><span class="line">15</span><br><span class="line">16 # Query cache disabled -- push down caching and merging instead</span><br><span class="line">17 druid.broker.cache.useCache=false</span><br><span class="line">18 druid.broker.cache.populateCache=false</span><br><span class="line">19 # druid.cache.sizeInBytes=6000000000</span><br><span class="line">20</span><br><span class="line">21 # Query config</span><br><span class="line">22 druid.broker.balancer.type=connectionCount</span><br><span class="line">23</span><br><span class="line">24 # SQL</span><br><span class="line">25 druid.sql.enable=true</span><br></pre></td></tr></table></figure></p>
<p>historical<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"> 1 -server</span><br><span class="line"> 2 -Xms12g</span><br><span class="line"> 3 -Xmx12g</span><br><span class="line"> 4 -XX:NewSize=4g</span><br><span class="line"> 5 -XX:MaxNewSize=4g</span><br><span class="line"> 6 -XX:MaxDirectMemorySize=10g</span><br><span class="line"> 7 -XX:+UserConcMarkSweepGC</span><br><span class="line"> 8 -XX:+PrintGCDetails</span><br><span class="line"> 9 -XX:+PrintGCTimeStamps</span><br><span class="line">10 -Duser.timezone=UTC+0800</span><br><span class="line">11 -XX:MaxDirectMemorySize=8g</span><br><span class="line">12 -Dfile.encoding=UTF-8</span><br><span class="line">13 -Djava.io.tmpdir=var/tmp</span><br><span class="line">14 -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager</span><br><span class="line"></span><br><span class="line"> 1 druid.service=druid/historical</span><br><span class="line"> 2 druid.host=10.1.30.103</span><br><span class="line"> 3 druid.port=8083</span><br><span class="line"> 4</span><br><span class="line"> 5 # HTTP server threads</span><br><span class="line"> 6 druid.server.http.numThreads=50</span><br><span class="line"> 7</span><br><span class="line"> 8 # Processing threads and buffers</span><br><span class="line"> 9 druid.processing.buffer.sizeBytes=1073741824</span><br><span class="line">10 druid.processing.numMergeBuffers=2</span><br><span class="line">11 druid.processing.numThreads=15</span><br><span class="line">12 druid.processing.tmpDir=var/druid/processing</span><br><span class="line">13</span><br><span class="line">14 # Segment storage</span><br><span class="line">15 druid.segmentCache.locations=[&#123;&quot;path&quot;:&quot;var/druid/segment-cache&quot;,&quot;maxSize&quot;\:130000000000&#125;]</span><br><span class="line">16 druid.server.maxSize=130000000000</span><br><span class="line">17</span><br><span class="line">18 # Query cache (note change)</span><br><span class="line">19 druid.historical.cache.useCache=false</span><br><span class="line">20 druid.historical.cache.populateCache=false</span><br><span class="line">21 druid.cache.type=caffeine</span><br><span class="line">22 druid.cache.sizeInBytes=2000000000</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/09/14/Maven-shade/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/14/Maven-shade/" itemprop="url">Maven shade</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-14T11:19:06+08:00">
                2018-09-14
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/14/Maven-shade/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/09/14/Maven-shade/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/09/14/Maven-shade/" class="leancloud_visitors" data-flag-title="Maven shade">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>程序里报错<code>Caused by: java.lang.NoSuchMethodError: com.fasterxml.jackson.databind.ObjectMapper.canSerialize(Ljava/lang/Class;Ljava/util/concurrent/atomic/AtomicReference;)Z</code></p>
<p>但是无论从<code>mvn dependency:tree</code>, 还是运行时加载的 jar 包来看, 都是用了正确的 <code>jackson-databind-2.6.5.jar</code>. 问题就刁钻在它用的这个类, 其实不是 <code>jackson-databind</code> 里的, 而是其他的包里 shaed 但是又没有 relocation 的. 除非你把这个包给从依赖李去掉, 在这个包的里面的依赖里去掉, 或者最外面加正确版本的<code>jackson-databind-2.6.5.jar</code>都是没有用的, 见下图:</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-9-14/40098244.jpg" alt=""></p>
<p>所以画框里他 exclusive 也是没有用的. 解决方法就是我们做成 external 的, 并且 exclude 掉.</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>external-influxdb<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>External-InfluxDB<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://kyligence.io<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Curator for KAP<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>apache<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kylin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">relativePath</span>&gt;</span>../../../pom.xml<span class="tag">&lt;/<span class="name">relativePath</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">shadeBase</span>&gt;</span>org.apache.kylin.shaded.influxdb<span class="tag">&lt;/<span class="name">shadeBase</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">shaded.curator.version</span>&gt;</span>2.12.0<span class="tag">&lt;/<span class="name">shaded.curator.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.influxdb<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>influxdb-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.guava<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>20.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- cover log4j from parent pom--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jcl-over-slf4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--overwrite parent, need to upgrade this when upgrade grpc--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-shade-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>shade<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">artifactSet</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">includes</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">include</span>&gt;</span>*:*<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">includes</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>log4j:*<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>org.slf4j:*<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">artifactSet</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">relocations</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>org.influxdb<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">shadedPattern</span>&gt;</span>$&#123;shadeBase&#125;.org.influxdb<span class="tag">&lt;/<span class="name">shadedPattern</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>com.squareup.moshi<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">shadedPattern</span>&gt;</span>$&#123;shadeBase&#125;.com.squareup.moshi<span class="tag">&lt;/<span class="name">shadedPattern</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>okhttp3<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">shadedPattern</span>&gt;</span>$&#123;shadeBase&#125;.okhttp3<span class="tag">&lt;/<span class="name">shadedPattern</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>okio<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">shadedPattern</span>&gt;</span>$&#123;shadeBase&#125;.okio<span class="tag">&lt;/<span class="name">shadedPattern</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>retrofit2<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">shadedPattern</span>&gt;</span>$&#123;shadeBase&#125;.retrofit2<span class="tag">&lt;/<span class="name">shadedPattern</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">relocation</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>com.google<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">shadedPattern</span>&gt;</span>$&#123;shadeBase&#125;.com.google.common<span class="tag">&lt;/<span class="name">shadedPattern</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">relocation</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">relocations</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">filters</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">filter</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">artifact</span>&gt;</span>*:*<span class="tag">&lt;/<span class="name">artifact</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.SF<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.DSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.RSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">filters</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/09/12/Storage-different-strategies-about-high-cardinal-string/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/12/Storage-different-strategies-about-high-cardinal-string/" itemprop="url">Storage:different strategies about high cardinal string</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-12T17:03:14+08:00">
                2018-09-12
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/12/Storage-different-strategies-about-high-cardinal-string/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/09/12/Storage-different-strategies-about-high-cardinal-string/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/09/12/Storage-different-strategies-about-high-cardinal-string/" class="leancloud_visitors" data-flag-title="Storage:different strategies about high cardinal string">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>run length encoding:对数据稀疏的列有较好的压缩率和访问速度</p>
<p>字典</p>
<h1 id="Clickhouse"><a href="#Clickhouse" class="headerlink" title="Clickhouse"></a>Clickhouse</h1><p>ClickHouse doesn’t have the concept of encodings. Strings can contain an arbitrary set of bytes, which are stored and output as-is. If you need to store texts, we recommend using UTF-8 encoding. At the very least, if your terminal uses UTF-8 (as recommended), you can read and write your values without making conversions. Similarly, certain functions for working with strings have separate variations that work under the assumption that the string contains a set of bytes representing a UTF-8 encoded text. For example, the ‘length’ function calculates the string length in bytes, while the ‘lengthUTF8’ function calculates the string length in Unicode code points, assuming that the value is UTF-8 encoded.</p>
<h1 id="Druid"><a href="#Druid" class="headerlink" title="Druid"></a>Druid</h1><p>使用字典:</p>
<p>字典是 mmap 进来的, 见:<code>org.apache.druid.segment.serde.ColumnPartSerde.Deserializer#read</code><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> GenericIndexed&lt;String&gt; rDictionary = GenericIndexed.read(</span><br><span class="line">    buffer,</span><br><span class="line">    GenericIndexed.STRING_STRATEGY,</span><br><span class="line">    builder.getFileMapper()</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">DictionaryEncodedColumnSupplier dictionaryEncodedColumnSupplier = <span class="keyword">new</span> DictionaryEncodedColumnSupplier(</span><br><span class="line">    rDictionary,</span><br><span class="line">    rSingleValuedColumn,</span><br><span class="line">    rMultiValuedColumn,</span><br><span class="line">    columnConfig.columnCacheSizeBytes()</span><br><span class="line">);</span><br></pre></td></tr></table></figure></p>
<p>其中<code>GenericIndexed.read</code>具体:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">GenericIndexed&lt;T&gt; <span class="title">createGenericIndexedVersionTwo</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    ByteBuffer byteBuffer,</span></span></span><br><span class="line"><span class="function"><span class="params">    ObjectStrategy&lt;T&gt; strategy,</span></span></span><br><span class="line"><span class="function"><span class="params">    SmooshedFileMapper fileMapper</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (fileMapper == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IAE(<span class="string">"SmooshedFileMapper can not be null for version 2."</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">boolean</span> allowReverseLookup = byteBuffer.get() == REVERSE_LOOKUP_ALLOWED;</span><br><span class="line">  <span class="keyword">int</span> logBaseTwoOfElementsPerValueFile = byteBuffer.getInt();</span><br><span class="line">  <span class="keyword">int</span> numElements = byteBuffer.getInt();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    String columnName = SERIALIZER_UTILS.readString(byteBuffer);</span><br><span class="line">    <span class="keyword">int</span> elementsPerValueFile = <span class="number">1</span> &lt;&lt; logBaseTwoOfElementsPerValueFile;</span><br><span class="line">    <span class="keyword">int</span> numberOfFilesRequired = getNumberOfFilesRequired(elementsPerValueFile, numElements);</span><br><span class="line">    ByteBuffer[] valueBuffersToUse = <span class="keyword">new</span> ByteBuffer[numberOfFilesRequired];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfFilesRequired; i++) &#123;</span><br><span class="line">      <span class="comment">// SmooshedFileMapper.mapFile() contract guarantees that the valueBuffer's limit equals to capacity.</span></span><br><span class="line">      ByteBuffer valueBuffer = fileMapper.mapFile(GenericIndexedWriter.generateValueFileName(columnName, i));</span><br><span class="line">      valueBuffersToUse[i] = valueBuffer.asReadOnlyBuffer();</span><br><span class="line">    &#125;</span><br><span class="line">    ByteBuffer headerBuffer = fileMapper.mapFile(GenericIndexedWriter.generateHeaderFileName(columnName));</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> GenericIndexed&lt;&gt;(</span><br><span class="line">        valueBuffersToUse,</span><br><span class="line">        headerBuffer,</span><br><span class="line">        strategy,</span><br><span class="line">        allowReverseLookup,</span><br><span class="line">        logBaseTwoOfElementsPerValueFile,</span><br><span class="line">        numElements</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"File mapping failed."</span>, e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>字典的具体表示是:<code>CachingIndexed&lt;String&gt; cachedLookups</code>, get 的时候先 get 从 cache 拿, 然后没有的话再从 mmap 中拿.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CachingIndexed</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">Indexed</span>&lt;<span class="title">T</span>&gt;, <span class="title">Closeable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> INITIAL_CACHE_CAPACITY = <span class="number">16384</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = <span class="keyword">new</span> Logger(CachingIndexed.class);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> GenericIndexed&lt;T&gt;.BufferIndexed delegate;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> SizedLRUMap&lt;Integer, T&gt; cachedValues;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Creates a CachingIndexed wrapping the given GenericIndexed with a value lookup cache</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * CachingIndexed objects are not thread safe and should only be used by a single thread at a time.</span></span><br><span class="line"><span class="comment">   * CachingIndexed objects must be closed to release any underlying cache resources.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> delegate the GenericIndexed to wrap with a lookup cache.</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> lookupCacheSize maximum size in bytes of the lookup cache if greater than zero</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">CachingIndexed</span><span class="params">(GenericIndexed&lt;T&gt; delegate, <span class="keyword">final</span> <span class="keyword">int</span> lookupCacheSize)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.delegate = delegate.singleThreaded();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lookupCacheSize &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      log.debug(<span class="string">"Allocating column cache of max size[%d]"</span>, lookupCacheSize);</span><br><span class="line">      cachedValues = <span class="keyword">new</span> SizedLRUMap&lt;&gt;(INITIAL_CACHE_CAPACITY, lookupCacheSize);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      cachedValues = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Class&lt;? extends T&gt; getClazz()</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">return</span> delegate.getClazz();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> delegate.size();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> T <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (cachedValues != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">final</span> T cached = cachedValues.getValue(index);</span><br><span class="line">      <span class="keyword">if</span> (cached != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> cached;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">final</span> T value = delegate.get(index);</span><br><span class="line">      cachedValues.put(index, value, delegate.getLastValueSize());</span><br><span class="line">      <span class="keyword">return</span> value;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> delegate.get(index);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">indexOf</span><span class="params">(T value)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> delegate.indexOf(value);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Iterator&lt;T&gt; <span class="title">iterator</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> delegate.iterator();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (cachedValues != <span class="keyword">null</span>) &#123;</span><br><span class="line">      log.debug(<span class="string">"Closing column cache"</span>);</span><br><span class="line">      cachedValues.clear();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inspectRuntimeShape</span><span class="params">(RuntimeShapeInspector inspector)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    inspector.visit(<span class="string">"cachedValues"</span>, cachedValues != <span class="keyword">null</span>);</span><br><span class="line">    inspector.visit(<span class="string">"delegate"</span>, delegate);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SizedLRUMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">K</span>, <span class="title">Pair</span>&lt;<span class="title">Integer</span>, <span class="title">V</span>&gt;&gt;</span></span><br><span class="line"><span class="class">  </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> maxBytes;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> numBytes = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SizedLRUMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">int</span> maxBytes)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="keyword">super</span>(initialCapacity, <span class="number">0.75f</span>, <span class="keyword">true</span>);</span><br><span class="line">      <span class="keyword">this</span>.maxBytes = maxBytes;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(Map.Entry&lt;K, Pair&lt;Integer, V&gt;&gt; eldest)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (numBytes &gt; maxBytes) &#123;</span><br><span class="line">        numBytes -= eldest.getValue().lhs;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(K key, V value, <span class="keyword">int</span> size)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">int</span> totalSize = size + <span class="number">48</span>; <span class="comment">// add approximate object overhead</span></span><br><span class="line">      numBytes += totalSize;</span><br><span class="line">      <span class="keyword">super</span>.put(key, <span class="keyword">new</span> Pair&lt;&gt;(totalSize, value));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> V <span class="title">getValue</span><span class="params">(Object key)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">      <span class="keyword">final</span> Pair&lt;Integer, V&gt; sizeValuePair = <span class="keyword">super</span>.get(key);</span><br><span class="line">      <span class="keyword">return</span> sizeValuePair == <span class="keyword">null</span> ? <span class="keyword">null</span> : sizeValuePair.rhs;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="IndexR"><a href="#IndexR" class="headerlink" title="IndexR"></a>IndexR</h1><h1 id="Carbondata"><a href="#Carbondata" class="headerlink" title="Carbondata"></a>Carbondata</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/08/30/Spark-mapPartitions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/30/Spark-mapPartitions/" itemprop="url">Spark:mapPartitions</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-30T22:56:55+08:00">
                2018-08-30
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/30/Spark-mapPartitions/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/08/30/Spark-mapPartitions/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/30/Spark-mapPartitions/" class="leancloud_visitors" data-flag-title="Spark:mapPartitions">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/08/26/Designing-Data-Intensive-Applications-Storage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/26/Designing-Data-Intensive-Applications-Storage/" itemprop="url">Designing Data-Intensive Applications(Storage)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-26T19:30:40+08:00">
                2018-08-26
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/26/Designing-Data-Intensive-Applications-Storage/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/08/26/Designing-Data-Intensive-Applications-Storage/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/26/Designing-Data-Intensive-Applications-Storage/" class="leancloud_visitors" data-flag-title="Designing Data-Intensive Applications(Storage)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Index-基础"><a href="#Index-基础" class="headerlink" title="Index 基础"></a>Index 基础</h1><p>log:泛指 append only 的记录序列.不一定要人可读, 可以是 binary 的.</p>
<p>log 文件是 append only, 而且一旦生成就不可变, 所以对并发和崩溃恢复很友好. 如果用 update 方式来修改值的话, 崩溃时会有很多不可预期的行为.</p>
<p>核心, 就是要减少扫的数据量. full scan (O(n)) 肯定最慢, 扫的时间和数据量成正比.</p>
<p>index 的也就是存出一些额外的信息, 这样的话帮助你定位到你的数据. 管理额外的信息是有开销的:存储(写入) 管理(更新), 所以 db 不会索引所有值.</p>
<h2 id="Hash-Index"><a href="#Hash-Index" class="headerlink" title="Hash Index"></a>Hash Index</h2><p>要找 key 为123456的 content, 只需要先在内存 map 中找到它的 byte offset , 只要一次 seek 过去,读到和下一个 key 的 offset相减的 content. 读的很精准.</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/893370.jpg" alt=""></p>
<blockquote>
<p>Storing a log of key-value pairs in a CSV-like format, indexed with an in-memory hash map.</p>
</blockquote>
<p>通过追加的方式, 可能会造成一个文件太大了, 解决方案是把当 log 到一定 size, 就拆分一个新 segment 文件. 后面我们可以对这些 segments 进行 compaction. compact 会去除 dup 的 key, 留下最新的版本.</p>
<p>还可以对多个 seg 进行 merge.<br><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/39145451.jpg" alt=""></p>
<blockquote>
<p>对一个 seg 进行 compact</p>
</blockquote>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/13193271.jpg" alt=""></p>
<blockquote>
<p>对 seg 进行 compact, 同时进行 merge.</p>
</blockquote>
<h3 id="局限"><a href="#局限" class="headerlink" title="局限"></a>局限</h3><ol>
<li>散列表必须能放进内存. 原则上可以在磁盘上保留一个哈希映射, 但是磁盘哈希映射很难表现优秀, 它需要大量的随机访问I/O, 当它变满时增长也是很昂贵的,并且散列冲突需要很多的逻辑</li>
<li>范围查询效率不高, 必须在散列映射中单独查找每个键.</li>
</ol>
<h2 id="SSLTables-and-LSM-Trees"><a href="#SSLTables-and-LSM-Trees" class="headerlink" title="SSLTables and LSM-Trees"></a>SSLTables and LSM-Trees</h2><p>之前的 log 文件里 record 的顺序是他们写入的顺序.我们现在有个新的要求, 就是写入的 k-v 对要根据 key 排序, 且每个 key 在每个 seg 中只出现一次, 这种 format 叫做 Sorted String Table(SSTable)</p>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ol>
<li><p>可以 merge 比内存还大的多的 seg(使用 merge sort), 对于多个 seg 中都出现的值, 只需要留最新的 seg 中的值就可以了.<br><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/65990847.jpg" alt=""></p>
</li>
<li><p>index 不用保留所有的 key, 因为你所有的 key 都是保序的, 所以只要有几个作为base, 其他的可以在这几个 base 之间去找. 假设你正在内存中寻找键 handiwork，但是你不知道段文件中该关键字的确切偏移量. 然而，你知道 handbag 和 handsome 的偏移，而且由于排序特性，你知道 handiwork 必须出现在这两者之间. 这意味着您可以跳到 handbag 的偏移位置并从那里扫描，直到您找到 handiwork(或没找到，如果该文件中没有该键)</p>
</li>
</ol>
<p>这样, 你内存中的索引就可以很稀疏, 每几千字节的段文件就有一个键就足够了，因为几千字节可以很快被扫描.</p>
<p>如果所有的 k-v 都是 fix length 的, 你可以用 binary search. 这样可以省去整个内存中的索引.不过 in practice 一般都是变长的.</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/28391204.jpg" alt=""></p>
<h3 id="维护和构建-SSTables"><a href="#维护和构建-SSTables" class="headerlink" title="维护和构建 SSTables"></a>维护和构建 SSTables</h3><p>在磁盘上维护一个有序的数据结构是可能的(见 B Tree), 但是在内存中维护会更加简单.类似的结构有 red-black trees, AVL tress.</p>
<h4 id="工作流"><a href="#工作流" class="headerlink" title="工作流"></a>工作流</h4><ol>
<li>写入时将其添加到内存中的平衡树数据结构(例如, 红黑树). 这个内存树有时被称为内存表(mem table).</li>
<li>当内存表大于某个阈值(通常为几兆字节)时, 将其作为 SSTable 文件写入磁盘.新的 SSTable 文件成为数据库的最新部分.当 SSTable 被写入磁盘时, 写入可以继续到一个新的内存表实例.</li>
<li>当读的时候, 首先尝试在内存表中找到关键字, 然后在最近的磁盘段中, 然后在下一个较旧的段中找到该关键字.</li>
<li>可以在后台运行合并和压缩过程以组合段文件并丢弃覆盖或删除的值.</li>
</ol>
<p>基于这种合并和压缩排序文件原理的存储引擎通常被称为 LSM 存储引擎(LevelDB, RocksDB, HBase, BigTable)</p>
<h5 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h5><ol>
<li>当查找数据库中不存在的值时, LSM 会慢, 因为要找到最老的 seg, 解决方法是用 Bloom Filter(粗糙集理论也可以了解下). 节省为不存在的键浪费的 IO.</li>
<li>还有不同的策略来确定 SSTables 如何被压缩和合并的顺序和时间. 最常见的选择是 size-tiered 和 leveled compaction. LevelDB 和 RocksDB 使用平坦压缩(LevelDB 因此得名), HBase 使用size-tiered , Cassandra 同时支持.</li>
</ol>
<p>即使有很多可选优化, 但是 LSM-trees 的基本 idea:保存一系列在后台合并的 SSTables, 简单且有效. 即使数据集比可用内存大的多, 也可以支持高效的范围查询, 而且支持非常高的写入.</p>
<h5 id="问题-amp-解决"><a href="#问题-amp-解决" class="headerlink" title="问题&amp;解决"></a>问题&amp;解决</h5><p>如果数据库崩溃, 则最近的写入(在内存表中, 但尚未写入磁盘)将丢失, 解决方案: WAL(write ahead log), 和前面的一样, 这也是个 log 文件, 写入的时候先写到磁盘上. 但 mem table =&gt; SSTable 的时候, WAL 可以被丢弃.</p>
<h2 id="B-Trees"><a href="#B-Trees" class="headerlink" title="B-Trees"></a>B-Trees</h2><p>像 SSTables 一样, B 树保持按键排序的键值对, 这允许高效的键值查找和范围查询, 但B 树有着非常不同的设计理念.</p>
<p>我们前面看到的日志结构索引将数据库分解为可变大小的段, 通常是几兆字节或更大的大小; B 树将数据库分解成固定大小的块或页面, 传统上大小为 4KB.并且一次只能读取或写入一个页面. 这种设计更接近于底层硬件.因为磁盘也被安排在固定大小的块中.</p>
<p>每个页面都可以使用地址或位置来标识, 这允许一个页面引用另一个页面 —— 类似于指针, 但在磁盘而不是在内存中. 我们可以使用这些页面引用来构建一个页面树.</p>
<p>我们要找251, 于是在[200, 300] 中间找<br><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/89272936.jpg" alt=""></p>
<p>在 B 树的一个页面中对子页面的引用的数量称为分支因子, 在上面图中, 分支因子是6. 在实践中, 分支因子取决于存储页面参考和范围边界所需的空间量, 但通常是几百个</p>
<p>如果要更新 B 树中现有键的值, 则搜索包含该键的叶页, 更改该页中的值, 并将该页写回到磁盘(对该页的任何引用保持有效). 如果你想添加一个新的键, 你需要找到其范围包含新键的页面, 并将其添加到该页面.如果页面中没有足够的可用空间容纳新键, 则将其分成两个半满页面, 并更新父页面以解释键范围的新分区</p>
<p>该算法确保树保持平衡:具有 n 个键的 B 树总是具有 O(log n)的深度.大多数数据库可以放入一个三到四层的 B 树, 所以你不需要遵追踪多页面引用来找到你正在查找的页面. 分支因子为 500 的 4KB 页面的四级树可以存储多达 256TB.</p>
<p><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-8-24/30223544.jpg" alt=""></p>
<p>B 树的基本底层写操作是用新数据覆盖磁盘上的页面, 但是引用不变, 这个和 LSM Tree 正好相反(只附加, 从不修改文件).</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol>
<li>需要拆分页面的时候, 要更新父页面对两个子页面的引用. 因为数据库随时可能崩溃. 解决方案: WAL(redo log), 这个日志被用来使 B 树恢复到一致的状态.</li>
<li>如果多个线程要同时访问 B 树, 则需要仔细的并发控制(latches).</li>
<li>B 树索引必须至少两次写入每一段数据:一次写入预先写入日志, 一次写入树页面本身（也许再次分页）. 即使在该页面中只有几个字节发生了变化, 也需要一次编写整个页面的开销. 有些存储引擎甚至会覆盖同一个页面两次, 以免在电源故障的情况下导致页面部分更新.</li>
</ol>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><ol>
<li>一些数据库(如 LMDB)使用写时复制方案, 而不是覆盖页面并维护 WAL 进行崩溃恢复.修改的页面被写入到不同的位置, 并且树中的父页面的新版本被创建, 指向新的位置. 这种方法对于并发控制也很有用.</li>
<li>可以通过不存储整个 key 来节省空间. key 只需要提供足够的信息来充当 key range 的边界. 一个 page 有更多的 key, 运行树有更高的分支因子, 减少层数.</li>
<li>通常, page 可以放置在磁盘上的任何位置, 如果查询需要按照排序顺序扫描大部分关键字范围, 那么每个页面的布局可能会非常不方便, 因为每个读取的页面都可能需要磁盘查找. 因此许多 B 树实现尝试叶子页面按顺序出现在磁盘上, 但是随着树的增长,维持这个顺序是很困难的. 由于 LSM 树在合并过程中一次又一次地重写存储的大部分, 所以它们更容易使顺序键在磁盘上彼此靠近.</li>
<li>添加额外的指针, eg:每个叶子页面可以在左边和右边具有对其兄弟页面的引用, 这样就能顺序扫描 key 而不跳回父页面.</li>
</ol>
<h3 id="LSM-Tree-VS-B-Tree"><a href="#LSM-Tree-VS-B-Tree" class="headerlink" title="LSM Tree VS B Tree"></a>LSM Tree VS B Tree</h3><h4 id="LSM"><a href="#LSM" class="headerlink" title="LSM"></a>LSM</h4><ol>
<li>LSM 写快, B 读快. LSM 顺序地写入紧凑的 SSTable 文件而不是必须覆盖树中的几个页面.</li>
<li>LSM 树可以被压缩得更好, B 树存储引擎会由于分割而留下一些未使用的磁盘空间.</li>
<li>在许多 SSD 上, 固件内部使用日志结构化算法, 将随机写入转变为顺序写入底层存储芯片. 但是较低的写入放大率和减少的碎片对 SSD 仍然有利: 更紧凑地表示数据可在可用的 I/O 带宽内提供更多的读取和写入请求.</li>
</ol>
<h4 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B Tree"></a>B Tree</h4><ol>
<li>日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作, 很容易发生请求需要等待而磁盘完成昂贵的压缩操作. 对吞吐量和平均响应时间的影响通常很小, 但是在更高百分比的情况下（参阅 “描述性能”）, 对日志结构化存储引擎的查询响应时间有时会相当长, 而 B 树的行为则相对更具可预测性.</li>
<li>压缩的另一个问题出现在高写入吞吐量: 磁盘的有限写入带宽需要在初始写入(记录和刷新内存表到磁盘)和在后台运行的压缩线程之间共享. 写入空数据库时, 可以使用全磁盘带宽进行初始写入, 但数据库越大, 压缩所需的磁盘带宽就越多. 如果写入吞吐量很高, 并且压缩没有仔细配置, 压缩跟不上写入速率. 在这种情况下, 磁盘上未合并段的数量不断增加, 直到磁盘空间用完, 读取速度也会减慢, 因为它们需要检查更多段文件. 通常情况下, 即使压缩无法跟上, 基于 SSTable 的存储引擎也不会限制传入写入的速率, 所以需要进行明确的监控来检测这种情况</li>
<li>B 树的一个优点是每个键只存在于索引中的一个位置, 而日志结构化的存储引擎可能在不同的段中有相同键的多个副本. 这个方面使得 B 树在想要提供强大的事务语义的数据库中很有吸引力. 在许多关系数据库中, 事务隔离是通过在键范围上使用锁来实现的, 在 B 树索引中, 这些锁可以直接连接到它.</li>
</ol>
<h1 id="列存储"><a href="#列存储" class="headerlink" title="列存储"></a>列存储</h1><p>如果一列的值, count 很大, 但是基数不大, 可以使用 bit map. 可以很高效的压缩.<br><img src="http://aron-blog-image.oss-cn-hangzhou.aliyuncs.com/18-9-1/37827590.jpg" alt=""></p>
<h2 id="vectorized-process"><a href="#vectorized-process" class="headerlink" title="vectorized process"></a>vectorized process</h2><p>除了减少需要从磁盘加载的数据量以外, 面向列的存储布局也可以有效利用 CPU 周期. 例如 query engine 可以把一块(chunk) 的  compressed column data(为了单位信息密度更大) 放到 CPU 的 L1 cache. 前面说的按位与/或可以直接 apply 到这些 chunk 上.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://tttmelody.github.io/2018/08/22/Parquet-encoding-definitions-official/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Aron">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://gitee.com/Meldoy/image/raw/master/life/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiatao Tao's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/22/Parquet-encoding-definitions-official/" itemprop="url">Parquet encoding definitions(official)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-22T20:49:53+08:00">
                2018-08-22
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/22/Parquet-encoding-definitions-official/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/08/22/Parquet-encoding-definitions-official/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/08/22/Parquet-encoding-definitions-official/" class="leancloud_visitors" data-flag-title="Parquet encoding definitions(official)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <!--
  - Licensed to the Apache Software Foundation (ASF) under one
  - or more contributor license agreements.  See the NOTICE file
  - distributed with this work for additional information
  - regarding copyright ownership.  The ASF licenses this file
  - to you under the Apache License, Version 2.0 (the
  - "License"); you may not use this file except in compliance
  - with the License.  You may obtain a copy of the License at
  -
  -   http://www.apache.org/licenses/LICENSE-2.0
  -
  - Unless required by applicable law or agreed to in writing,
  - software distributed under the License is distributed on an
  - "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  - KIND, either express or implied.  See the License for the
  - specific language governing permissions and limitations
  - under the License.
  -->
<h1 id="Parquet-encoding-definitions"><a href="#Parquet-encoding-definitions" class="headerlink" title="Parquet encoding definitions"></a><a href="https://github.com/apache/parquet-format/blob/master/Encodings.md" target="_blank" rel="noopener">Parquet encoding definitions</a></h1><p>This file contains the specification of all supported encodings.</p>
<h3 id="Plain-PLAIN-0"><a href="#Plain-PLAIN-0" class="headerlink" title="Plain: (PLAIN = 0)"></a><a name="PLAIN"></a>Plain: (PLAIN = 0)</h3><p>Supported Types: all</p>
<p>This is the plain encoding that must be supported for types.  It is<br>intended to be the simplest encoding.  Values are encoded back to back.</p>
<p>The plain encoding is used whenever a more efficient encoding can not be used. It<br>stores the data in the following format:</p>
<ul>
<li>BOOLEAN: <a href="#RLE">Bit Packed</a>, LSB first</li>
<li>INT32: 4 bytes little endian</li>
<li>INT64: 8 bytes little endian</li>
<li>INT96: 12 bytes little endian (deprecated)</li>
<li>FLOAT: 4 bytes IEEE little endian</li>
<li>DOUBLE: 8 bytes IEEE little endian</li>
<li>BYTE_ARRAY: length in 4 bytes little endian followed by the bytes contained in the array</li>
<li>FIXED_LEN_BYTE_ARRAY: the bytes contained in the array</li>
</ul>
<p>For native types, this outputs the data as little endian. Floating<br>    point types are encoded in IEEE.</p>
<p>For the byte array type, it encodes the length as a 4 byte little<br>endian, followed by the bytes.</p>
<h3 id="Dictionary-Encoding-PLAIN-DICTIONARY-2-and-RLE-DICTIONARY-8"><a href="#Dictionary-Encoding-PLAIN-DICTIONARY-2-and-RLE-DICTIONARY-8" class="headerlink" title="Dictionary Encoding (PLAIN_DICTIONARY = 2 and RLE_DICTIONARY = 8)"></a>Dictionary Encoding (PLAIN_DICTIONARY = 2 and RLE_DICTIONARY = 8)</h3><p>The dictionary encoding builds a dictionary of values encountered in a given column. The<br>dictionary will be stored in a dictionary page per column chunk. The values are stored as integers<br>using the <a href="#RLE">RLE/Bit-Packing Hybrid</a> encoding. If the dictionary grows too big, whether in size<br>or number of distinct values, the encoding will fall back to the plain encoding. The dictionary page is<br>written first, before the data pages of the column chunk.</p>
<p>Dictionary page format: the entries in the dictionary - in dictionary order - using the <a href="#PLAIN">plain</a> encoding.</p>
<p>Data page format: the bit width used to encode the entry ids stored as 1 byte (max bit width = 32),<br>followed by the values encoded using RLE/Bit packed described above (with the given bit width).</p>
<p>Using the PLAIN_DICTIONARY enum value is deprecated in the Parquet 2.0 specification. Prefer using RLE_DICTIONARY<br>in a data page and PLAIN in a dictionary page for Parquet 2.0+ files.</p>
<h3 id="Run-Length-Encoding-Bit-Packing-Hybrid-RLE-3"><a href="#Run-Length-Encoding-Bit-Packing-Hybrid-RLE-3" class="headerlink" title="Run Length Encoding / Bit-Packing Hybrid (RLE = 3)"></a><a name="RLE"></a>Run Length Encoding / Bit-Packing Hybrid (RLE = 3)</h3><p>This encoding uses a combination of bit-packing and run length encoding to more efficiently store repeated values.</p>
<p>The grammar for this encoding looks like this, given a fixed bit-width known in advance:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">rle-bit-packed-hybrid: &lt;length&gt; &lt;encoded-data&gt;</span><br><span class="line">length := length of the &lt;encoded-data&gt; in bytes stored as 4 bytes little endian (unsigned int32)</span><br><span class="line">encoded-data := &lt;run&gt;*</span><br><span class="line">run := &lt;bit-packed-run&gt; | &lt;rle-run&gt;</span><br><span class="line">bit-packed-run := &lt;bit-packed-header&gt; &lt;bit-packed-values&gt;</span><br><span class="line">bit-packed-header := varint-encode(&lt;bit-pack-scaled-run-len&gt; &lt;&lt; 1 | 1)</span><br><span class="line">// we always bit-pack a multiple of 8 values at a time, so we only store the number of values / 8</span><br><span class="line">bit-pack-scaled-run-len := (bit-packed-run-len) / 8</span><br><span class="line">bit-packed-run-len := *see 3 below*</span><br><span class="line">bit-packed-values := *see 1 below*</span><br><span class="line">rle-run := &lt;rle-header&gt; &lt;repeated-value&gt;</span><br><span class="line">rle-header := varint-encode( (rle-run-len) &lt;&lt; 1)</span><br><span class="line">rle-run-len := *see 3 below*</span><br><span class="line">repeated-value := value that is repeated, using a fixed-width of round-up-to-next-byte(bit-width)</span><br></pre></td></tr></table></figure></p>
<ol>
<li><p>The bit-packing here is done in a different order than the one in the <a href="#BITPACKED">deprecated bit-packing</a> encoding.<br>The values are packed from the least significant bit of each byte to the most significant bit,<br>though the order of the bits in each value remains in the usual order of most significant to least<br>significant. For example, to pack the same values as the example in the deprecated encoding above:</p>
<p>The numbers 1 through 7 using bit width 3:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dec value: 0   1   2   3   4   5   6   7</span><br><span class="line">bit value: 000 001 010 011 100 101 110 111</span><br><span class="line">bit label: ABC DEF GHI JKL MNO PQR STU VWX</span><br></pre></td></tr></table></figure>
<p>would be encoded like this where spaces mark byte boundaries (3 bytes):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bit value: 10001000 11000110 11111010</span><br><span class="line">bit label: HIDEFABC RMNOJKLG VWXSTUPQ</span><br></pre></td></tr></table></figure>
<p>The reason for this packing order is to have fewer word-boundaries on little-endian hardware<br>when deserializing more than one byte at at time. This is because 4 bytes can be read into a<br>32 bit register (or 8 bytes into a 64 bit register) and values can be unpacked just by<br>shifting and ORing with a mask. (to make this optimization work on a big-endian machine,<br>you would have to use the ordering used in the <a href="#BITPACKED">deprecated bit-packing</a> encoding)</p>
</li>
<li><p>varint-encode() is ULEB-128 encoding, see <a href="https://en.wikipedia.org/wiki/LEB128" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/LEB128</a></p>
</li>
<li><p>bit-packed-run-len and rle-run-len must be in the range [1, 2<sup>31</sup> - 1].<br>This means that a Parquet implementation can always store the run length in a signed<br>32-bit integer. This length restriction was not part of the Parquet 2.5.0 and earlier<br>specifications, but longer runs were not readable by the most common Parquet<br>implementations so, in practice, were not safe for Parquet writers to emit.</p>
</li>
</ol>
<p>Note that the RLE encoding method is only supported for the following types of<br>data:</p>
<ul>
<li>Repetition and definition levels</li>
<li>Dictionary indices</li>
<li>Boolean values in data pages, as an alternative to PLAIN encoding</li>
</ul>
<h3 id="Bit-packed-Deprecated-BIT-PACKED-4"><a href="#Bit-packed-Deprecated-BIT-PACKED-4" class="headerlink" title="Bit-packed (Deprecated) (BIT_PACKED = 4)"></a><a name="BITPACKED"></a>Bit-packed (Deprecated) (BIT_PACKED = 4)</h3><p>This is a bit-packed only encoding, which is deprecated and will be replaced by the <a href="#RLE">RLE/bit-packing</a> hybrid encoding.<br>Each value is encoded back to back using a fixed width.<br>There is no padding between values (except for the last byte) which is padded with 0s.<br>For example, if the max repetition level was 3 (2 bits) and the max definition level as 3<br>(2 bits), to encode 30 values, we would have 30 * 2 = 60 bits = 8 bytes.</p>
<p>This implementation is deprecated because the <a href="#RLE">RLE/bit-packing</a> hybrid is a superset of this implementation.<br>For compatibility reasons, this implementation packs values from the most significant bit to the least significant bit,<br>which is not the same as the <a href="#RLE">RLE/bit-packing</a> hybrid.</p>
<p>For example, the numbers 1 through 7 using bit width 3:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dec value: 0   1   2   3   4   5   6   7</span><br><span class="line">bit value: 000 001 010 011 100 101 110 111</span><br><span class="line">bit label: ABC DEF GHI JKL MNO PQR STU VWX</span><br></pre></td></tr></table></figure></p>
<p>would be encoded like this where spaces mark byte boundaries (3 bytes):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bit value: 00000101 00111001 01110111</span><br><span class="line">bit label: ABCDEFGH IJKLMNOP QRSTUVWX</span><br></pre></td></tr></table></figure></p>
<p>Note that the BIT_PACKED encoding method is only supported for encoding<br>repetition and definition levels.</p>
<h3 id="Delta-Encoding-DELTA-BINARY-PACKED-5"><a href="#Delta-Encoding-DELTA-BINARY-PACKED-5" class="headerlink" title="Delta Encoding (DELTA_BINARY_PACKED = 5)"></a><a name="DELTAENC"></a>Delta Encoding (DELTA_BINARY_PACKED = 5)</h3><p>Supported Types: INT32, INT64</p>
<p>This encoding is adapted from the Binary packing described in <a href="http://arxiv.org/pdf/1209.2137v5.pdf" target="_blank" rel="noopener">“Decoding billions of integers per second through vectorization”</a> by D. Lemire and L. Boytsov</p>
<p>Delta encoding consists of a header followed by blocks of delta encoded values binary packed. Each block is made of miniblocks, each of them binary packed with its own bit width. When there are not enough values to encode a full block we pad with zeros (added to the frame of reference).<br>The header is defined as follows:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;block size in values&gt; &lt;number of miniblocks in a block&gt; &lt;total value count&gt; &lt;first value&gt;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>the block size is a multiple of 128 stored as VLQ int</li>
<li>the miniblock count per block is a diviser of the block size stored as VLQ int the number of values in the miniblock is a multiple of 32.</li>
<li>the total value count is stored as a VLQ int</li>
<li>the first value is stored as a zigzag VLQ int</li>
</ul>
<p>Each block contains<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;min delta&gt; &lt;list of bitwidths of miniblocks&gt; &lt;miniblocks&gt;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>the min delta is a VLQ int (we compute a minimum as we need positive integers for bit packing)</li>
<li>the bitwidth of each block is stored as a byte</li>
<li>each miniblock is a list of bit packed ints according to the bit width stored at the begining of the block</li>
</ul>
<p>Having multiple blocks allows us to escape values and restart from a new base value.</p>
<p>To encode each delta block, we will:</p>
<ol>
<li><p>Compute the deltas</p>
</li>
<li><p>Encode the first value as zigzag VLQ int</p>
</li>
<li><p>For each block, compute the frame of reference(minimum of the deltas) for the deltas. This guarantees<br>all deltas are positive.</p>
</li>
<li><p>encode the frame of reference delta as VLQ int followed by the delta values (minus the minimum) encoded as bit packed per miniblock.</p>
</li>
</ol>
<p>Steps 2 and 3 are skipped if the number of values in the block is 1.</p>
<h4 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h4><p>1, 2, 3, 4, 5</p>
<p>After step 1), we compute the deltas as:</p>
<p>1, 1, 1, 1</p>
<p>The minimum delta is 1 and after step 2, the deltas become</p>
<p>0, 0, 0, 0</p>
<p>The final encoded data is:</p>
<p> header:<br>8 (block size), 1 (miniblock count), 5 (value count), 1 (first value)</p>
<p> block<br>1 (minimum delta), 0 (bitwidth), (no data needed for bitwidth 0)</p>
<h4 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h4><p>7, 5, 3, 1, 2, 3, 4, 5, the deltas would be</p>
<p>-2, -2, -2, 1, 1, 1, 1</p>
<p>The minimum is -2, so the relative deltas are:</p>
<p>0, 0, 0, 3, 3, 3, 3</p>
<p>The encoded data is</p>
<p> header:<br>8 (block size), 1 (miniblock count), 8 (value count), 7 (first value)</p>
<p> block<br>-2 (minimum delta), 2 (bitwidth), 00000011111111b (0,0,0,3,3,3,3 packed on 2 bits)</p>
<h4 id="Characteristics"><a href="#Characteristics" class="headerlink" title="Characteristics"></a>Characteristics</h4><p>This encoding is similar to the <a href="#RLE">RLE/bit-packing</a> encoding. However the <a href="#RLE">RLE/bit-packing</a> encoding is specifically used when the range of ints is small over the entire page, as is true of repetition and definition levels. It uses a single bit width for the whole page.<br>The delta encoding algorithm described above stores a bit width per mini block and is less sensitive to variations in the size of encoded integers. It is also somewhat doing RLE encoding as a block containing all the same values will be bit packed to a zero bit width thus being only a header.</p>
<h3 id="Delta-length-byte-array-DELTA-LENGTH-BYTE-ARRAY-6"><a href="#Delta-length-byte-array-DELTA-LENGTH-BYTE-ARRAY-6" class="headerlink" title="Delta-length byte array: (DELTA_LENGTH_BYTE_ARRAY = 6)"></a>Delta-length byte array: (DELTA_LENGTH_BYTE_ARRAY = 6)</h3><p>Supported Types: BYTE_ARRAY</p>
<p>This encoding is always preferred over PLAIN for byte array columns.</p>
<p>For this encoding, we will take all the byte array lengths and encode them using delta<br>encoding (DELTA_BINARY_PACKED). The byte array data follows all of the length data just<br>concatenated back to back. The expected savings is from the cost of encoding the lengths<br>and possibly better compression in the data (it is no longer interleaved with the lengths).</p>
<p>The data stream looks like:</p>
<p><delta encoded="" lengths=""> <byte array="" data=""></byte></delta></p>
<p>For example, if the data was “Hello”, “World”, “Foobar”, “ABCDEF”:</p>
<p>The encoded data would be DeltaEncoding(5, 5, 6, 6) “HelloWorldFoobarABCDEF”</p>
<h3 id="Delta-Strings-DELTA-BYTE-ARRAY-7"><a href="#Delta-Strings-DELTA-BYTE-ARRAY-7" class="headerlink" title="Delta Strings: (DELTA_BYTE_ARRAY = 7)"></a>Delta Strings: (DELTA_BYTE_ARRAY = 7)</h3><p>Supported Types: BYTE_ARRAY</p>
<p>This is also known as incremental encoding or front compression: for each element in a<br>sequence of strings, store the prefix length of the previous entry plus the suffix.</p>
<p>For a longer description, see <a href="https://en.wikipedia.org/wiki/Incremental_encoding" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Incremental_encoding</a>.</p>
<p>This is stored as a sequence of delta-encoded prefix lengths (DELTA_BINARY_PACKED), followed by<br>the suffixes encoded as delta length byte arrays (DELTA_LENGTH_BYTE_ARRAY).</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://gitee.com/Meldoy/image/raw/master/life/head.jpg"
                alt="Aron" />
            
              <p class="site-author-name" itemprop="name">Aron</p>
              <p class="site-description motion-element" itemprop="description">Kyligence</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Aron</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'xUIDY0rxakumlhKmQqajlnUc-gzGzoHsz',
        appKey: 'lrqs8UwcvY6z1has9clbxJWL',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("mUXETWIxo42z09pHif0vNGo2-gzGzoHsz", "Sv2QHSHPjuj5DVnTOmO5VQIj");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  

</body>
</html>
